[
    {
        "number": 1570875555,
        "title": "Evaluating Cryptobots to perform trades on Cryptocurrency exchanges through API's access and building triggers to stream real time price of digital assets",
        "abstract": "This exploratory research is to explore use of Crypto bots to perform digital exchanges and other functions of monetary trading those allow the exchange of goods and services on a public ledger securely. In this study, we will explore payment processing through Cryptocurrency on a digital exchange. The purpose of this study is to explore design and implementation through algorithms enabling automation on multiple exchanges using API's. We will also evaluate the use of a trigger to point to a digital asset and provide the exchange value of that digital asset to user platform in real time.",
        "review": {
            "strength": [
                "The author introduces several APIs of Coinbase Pro to retrieve real time cryptocurrency related data.",
                "- Explores a relevant and current topic in the field of cryptocurrency and trading, specifically the use of crypto bots and API access for trading.\n- Provides a clear and concise abstract and introduction that outlines the purpose and scope of the research.\n- The paper discusses different aspects of crypto analysis, including technical analysis, market analysis, and regulatory analysis, and provides examples of research in each area.",
                "The paper provides a basic guide on using Python to interact with the Coinbase Pro API in terms of simple functions such as retrieving price and trade data."
            ],
            "shortcoming": [
                "- The title and contents of the paper are mismatched.\n- It is difficult to find relation between most of introduced references and what the author wants to say.\n- There is no technical content that is crucial or novel.",
                "- It lacks clear research questions or hypotheses, which could make it harder for readers to understand the purpose of the research.\n- The paper does not provide any original research or experiments, which could limit the significance of the paper.\n- The authors need to provide more detailed explanations of some of the technical concepts, as some readers might not be familiar with certain terms or technologies.\n- A conclusion or summary of the findings is totally missing, therefore making the paper harder for readers to understand the overall significance.\n- No novelty in the research, and also some of the references look like misplaced, e.g., [5]. How key exchange helps research in evaluating cryptobots.",
                "The paper describes aspects of crypto analysis but appears to lack relevant references. The title appears to be slightly misleading, as I am unable to find content that relates to \"evaluating\" Cryptobots and \"building triggers\". There does not seems to be any evaluation and the Python code simply retrieves and displays the current crypto prices."
            ],
            "comment": [
                "- The title of the paper and some titles of subsections are mismatched with the content in the paragraphs.\n- The manuscript only introduces what this work has done in the Introduction section. (No any explanation or background to understand the work and its importance)\n- There is no explanation about how the introduce references are related to the content of the paragraphs.\n- There is no conclusion and future work.\n- There are many typos and grammatical errors",
                "Overall, the paper presents an interesting topic, which is actual and can be, if written completely, helpful to many researchers in cryptocurrency exchange trading. Unfortunately, the analysis is weak and does not provide all details necessary to perform trades. The author mentioned in the abstract an exploration of the use of crypto bots to perform digital exchanges and payment processing, but there is no evidence in the paper about the details. There is only information about using API to ask for a ticker and trades on one exchange and one pair. What are the outcomes of this information? \nThe paper needs to provide more technical details, bring some novelty, and evaluate the results. It would have been helpful if the paper had provided more details on the implementation of the algorithms and triggers used to automate the exchanges if that was the purpose. Besides that, I do not find the paper beneficial for the community in its current state.",
                "The paper describes aspects of crypto analysis but appears to lack relevant references. The title appears to be slightly misleading, as I was unable to find content that relates to \"evaluating\" Cryptobots and \"building triggers\". There does not seems to be any evaluation and the Python code simply retrieves and displays the current crypto prices."
            ],
            "score": {
                "Relevance": 2.7,
                "Content and originality": 1.0,
                "Reference": 1.7,
                "Overall recommendation": 1.0,
                "Poster acceptance": 2.0
            }
        },
        "body": "I. INTRODUCTION\n\nThis study explores the programmatical\n\nimplementation of APIs to access data from crypto currency exchanges and provides an understanding of various technical and market-related concepts. In this paper, we will study and evaluate various aspects and provides the analysis of cryptocurrencies, including their underlying technology, market performance, and potential use cases. This research can include exploring python code to generate a trigger for a particular cryptocurrency to assess its security and scalability, as well as studying market data to understand trends in trading volume and price movements.\n\nII. ASPECTS OFCRYPTO ANALYSIS\n\nThe three aspects of crypto analysis are defined as below. These are interrelated and a user requires knowledge and understanding to make an informed decision, and to further improvise the trading mechanism. For instance, in [1], Ceren Kocao\u011fullar, Arthur Gervais, Benjamin Livshits developed a sample ChainBot and trained it on historical datato speed up the buy-and-hold strategy 2.4X to explore On-Chain Algorithmic Trading.\n\nA. Technology Analysis\n\nThis part of crypto analysis involves studying the\n\nunderlying technology of cryptocurrency. An\n\nimportant area of crypto analysis is the study of blockchain technology with consensus mechanism, and smart contract capabilities. In [2] Rashid, N. B. Et al. describes a proposed system for managing funds using blockchain technology.The paper discusses the potential benefits of using blockchain in fund management and presents an overview of the proposed system, which includes the use of smart contracts and\n\ntokenization. NFTs are digital tokens that represent ownership of a unique digital asset, such as a piece of art. In [3] Du, L., Kim, M., & Lee, J. discuss the emergence of Non-Fungible Token (NFT)\n\nmarketplaces and their impact on the art industry.\n\nIn [4] Akcin et al. presents a control-theoretic\n\napproach for analyzing the tokenomics of blockchain infrastructure. Blockchain being decentralized, ledger that is digitally organized, which records transaction in a secure and transparent way.\n\nIn [5] Krasnowski, Lebrun, and Martin presents a\n\nmethod for secure key exchange for voice\n\ncommunication without using side-channel\n\ninformation to provide a secure method for voice communication without the need for side-channel information. There are different structures for various blockchain systems for example, scalable systems, quantum safe systems, complex networks, and more\n\nIn [6], Vahid Heidaripour Lakhani, Leander Jehl,\n\nRinke Hendriksen, and Vero Estrada-Gali\u00f1anes realizes the incentivization of shared resources in Peer- to-peer (p2p) networks for network efficiency.\n\nB. Market Analysis, Study of Market trends and Price movements\n\nMarket Analysis involves study of market data to\n\nbe understood for identifying the trends in trading volume, price movements, and investor sentiment. In this research, \u2018python\u2019 is used as a programming language to study historical price data and make predictions about future trends.\n\nIn [7] Xu, T. A., Xu, J., & Lommers, K. compares\n\nthe valuation of decentralized finance (DeFi) projects to traditional finance (TradFi) projects using multiple and discounted cash flow analysis. Market Analysis includes technical analysis, which uses charts and other data to identify patterns in price movements, and fundamental analysis, which looks at factors such as the overall health of the economy and the surrounding regulatory bodies to assess the long-term potential of a particular digital asset. Additionally, keeping up with the fast-paced developments and continuous\n\ninnovation in the field of cryptocurrency.\n\nC. Regulatory Analysis, Legal and regulatory environment This aspect of crypto analysis involves studying the legal and regulatory environment surrounding a cryptocurrency. In [8] Kerschbaum, F., Blass, E. O., & Mahdavi, R. A. proposes a novell method to perform\n\nsecure set intersection, which is a technique used in privacy-preserving protocols for comparing two sets of data without revealing the actual data. In [9] Wickert, Baumg\u00e4rtner, Breitfelder, and Mezini presents a study on the prevalent misuse of cryptographic libraries in Python in real-world projects. There are potential impacts of laws and regulations on the adoption and use of cryptocurrency, as well as assess the risk of government intervention or crackdowns. In [10] Acar, Y. Et al. examines the usability of cryptographic Application Programming Interfaces (APIs) and how they impact the security of software systems. In [11] Daniele Friolo; Fabio Massacci; Chan Nam Ngo; Daniele Venturi analyzed the practical effects of (lack of) financial fairness when running the protocols on Bitcoin using Bloomberg\u2019s dark pool trading.\n\nIII. WHAT AREC RYPTOE XCHANGESAND WHOOWNS\n\nTHEM ?\n\nCrypto exchanges are online platform that lets users\n\nto buy, sell and trade cryptocurrencies. These exchanges act as intermediaries between buyers and sellers, matching orders and facilitating trades. Crypto exchanges typically charge a small fee for each transaction and some exchanges also charge additional fees for deposit and withdrawal of funds.\n\nOwnership of crypto exchanges vary widely.\n\nPrivate institutions to individuals or small groups of investors owns some exchanges, whereas some exchanges are owned by larger companies or financial institutions. Some crypto exchanges are also\n\ndecentralized and owned by the communities with no single entity in-charge of them. In [12], Ahmed Kosba, Andrew Miller, Elaine Shi, Zikai Wen, Charalampos Papamanthou advocated the community to adopt models when designing applications atop decentralized blockchains.\n\nBinance, Coinbase, Kraken are some well-known\n\ncrypto exchanges. Binance is based in Malta and founded by Changpeng Zhao. Coinbase is US-based exchange founded by Brian Armstrong and Fred Ehrsam and Kraken is San-Fransico-based exchange founded by Jesse Powell.\n\nCrypto exchanges, like any other businesses are\n\nsubject to laws and regulations of the location of their services those they offer. Many countries have started regulating crypto exchanges, requiring them to follow anti-money laundering (AML) and know-your- customer (KYC) regulations, meeting sustainability challenges whereas some countries have outright banned the crypto exchanges all together. In [13] Gracy, M., & Jeyavadhanam, B. R. presents a new technique called MTTBA (Multilayer Tangle-Based Architecture) to improve the energy efficiency and security of blockchain technology. In [14] Marco Alberto Javarone, Gabriele Di Antonio , Gianni Valerio Vinci , Luciano Pietronero and Carlo Gola explores the sustainability in blockchains and impact of mining of\n\ndigital assets on global energy consumption of this technology. There have been instances of hacks and user funds being stolen from the exchanges. Safety of digital assets can be ensured by keeping your own digital assets on your own hardware wallets.\n\nIV. BUILDING TICKERSTO STREAMREAL TIMEPRICES\n\nFROMCRYPTOCURRENCY EXCHANGES\n\nA. Import requests and Trades\n\nTo make an import request from a crypto\n\nexchange like Coinbase Pro using an API on Python, you can use the Coinbase Pro Python library, which is a wrapper for the Coinbase Pro RESTAPI. This library enables interaction with Coinbase Pro API using Python code.\n\nHere is an example, In Code snippet 1, is the ticker\n\nbuilt on python to display the ADA-USD crypto currency price in real time from Coinbase API.\n\nCode snippet 1: ADA-USDPrice Ticker from Coinbase Pro\n\nUsers can call other functions as well those are\n\navailable in the library to make other type of requests such as getting account balance, place an order, sell an asset and more.\n\nIt is also worth pointing out that Coinbase Pro\u2019s API\n\nis rate limited, which means that there are limits on the number of requests that can be made within a certain period. The rate limit varies based on the endpoint and the kind of request made. For instance, the rate limit for the \u2018GET/Products/{id}/candles\u2019 endpoint, which is used to retrieve historical data for a specific asset is 3 requests per second.\n\nIn case a user exceeds the rate limit, they will\n\nreceive a \u2018429 Too many Requests\u2019 errors, so a user needs to be mindful when making requests.\n\nimport requests\n\nticker =\n\nrequests.get('https://api.pro.coinbase.com/p roducts/ADA-USD/ticker').json()\n\nticker\n\n{'ask': '0.3818',\n\n'bid': '0.3817',\n\n'volume': '91853928.25',\n\n'trade_id': 89985331,\n\n'price': '0.3818',\n\n'size': '5.2',\n\n'time': '2023-01-\n\n23T00:35:25.894707Z'}\n\nB. Performing trades on Crypto Assets\n\n\n\nLatest Trade data can be retrieved on a crypto\n\nexchange with the help of API\u2019s and endpoints like \u2018get_product_trades\u2019. In Code snippet 2, is the header view of ADA-USD crypto currency trades with time stamps.\n\n\n\nCode snippet 2: ADA-USDTrade Header from Coinbase Pro\n\n\n\nC. Backtest overfitting trades on Crypto Assets\n\n\n\nBacktest overfitting in the context of cryptocurrency refers to the phenomenon where a trading strategy is tested using historical data and seems like highly profitable, when it is applied to new, unseen data, it performs poorly. In [15] Berend Jelmer Dirk Gort et al, designed trading strategies and approaches to address backtest overfitting.\n\n\n\nD. Synthetic assets, Decenteralized Finance (DeFi) Synthetic assets in the context of decentralized finance (DeFi) refer ro digital assets that are created using smart contacts on blockchain and that track the value of an underlying asset such as a traditional financial instrument, commodity, or another cryptocurrency. In [16] Abrar Rahman, Victor Shi, Matthew Ding, Elliot Choi explores a general framework for synthetic assets (DeFi). web3.py can be used to access Synthetic assets. In Code snippet 3, python is used to\n\ndemonstrate the access to synthetic assets using web3.py library. Code snippet 3: Accessing synthetic assets using web3.py Also, there might be a signing and gas fee when a user is performing trades or executing sell and buy orders.\n\nACKNOWLEDGMENT\n\nIn this research paper the gratitude and\n\nacknowledgement go to many crypto enthusiasts who are continuously expanding the awareness in the digital assets\u2019 domain. Notable acknowledgement for John Ernst Technical BUE zStack FSMMarket at IBM whose immense support drove to the completion of this successful study.\n\nREFERENCES\n\n[1] Kocao\u011fullar, C., Gervais, A., & Livshits, B. (2021). Towards\n\nPrivate On-Chain Algorithmic Trading. arXiv preprint arXiv:2109.11270.\n\n[2] Rashid, N. B., Saha, J., Prova, R. I., Tasfia, N., Shanto, M.,\n\nHuda, N., & Noor, J. (2022). Towards Devising AFund Management System Using Blockchain. arXiv preprint arXiv:2211.03613.\n\n[3] Du, L., Kim, M., & Lee, J. (2022). The Art NFTs and Their\n\nMarketplaces. arXiv preprint arXiv:2210.14942.\n\n[4] Akcin, O., Streit, R. P., Oommen, B., Vishwanath, S., &\n\nChinchali, S. (2022). AControl Theoretic Approach to Infrastructure-Centric Blockchain Tokenomics. arXiv preprint arXiv:2210.12881.\n\n[5] Krasnowski, P., Lebrun, J., & Martin, B. (2022). Exchanging\n\nKeys with Authentication and Identity Protection for Secure Voice Communication without Side-channel. arXiv preprint arXiv:2211.07186.\n\n[6] Lakhani, V. H., Jehl, L., Hendriksen, R., & Estrada-Galinanes,\n\nV. (2022, July). Fair Incentivization of Bandwidth Sharing in Decentralized Storage Networks. In 2022 IEEE 42nd\n\ntrades =\n\npd.DataFrame(requests.get('https://api.pro. coinbase.com/products/ADA- USD/trades').json())\n\ntrades.head()\n\ntime trade_id price size side\n\n0 2023-01-23T02:54:17.238165Z\n\n89992890 0.37600000\n\n1744.74000000 buy\n\n1 2023-01-23T02:54:17.238165Z\n\n89992889 0.37610000\n\n258.00000000 buy\n\n2 2023-01-23T02:54:12.396208Z\n\n89992888 0.37630000\n\n23.74000000 sell\n\n3 2023-01-23T02:54:10.633154Z\n\n89992887 0.37630000\n\n29.10000000 sell\n\n4 2023-01-23T02:54:07.448004Z\n\n89992886 0.37630000\n\n679.28000000 sell\n\n\n\n#install web3.py using pip pip install web3 #connect to an Ethereum node using web3.py from web3 import Web3 w3 = Web3(Web3.HTTPProvider(\" https://mainne t.infura.io/v3/YOUR-PROJECT-ID \")) #May call a function in the smart contract to get the current price of the synthetic asset contract_address = ' XXXXXXXXX ' contract = w3.eth.contract(address=contract_address, abi = ABI) price = contract.functions.getPrice().call() #ABI is the Application Binary Interface of the smart contract. #getPrice() is the function in the smart contract returning current price of synthetic asset.\n\nInternational Conference on Distributed Computing Systems Workshops (ICDCSW) (pp. 39-44). IEEE.\n\n[7] Xu, T. A., Xu, J., & Lommers, K. (2022). DeFi vs TradFi:\n\nValuation Using Multiples and Discounted Cash Flow. arXiv preprint arXiv:2210.16846.\n\n[8] Kerschbaum, F., Blass, E. O., & Mahdavi, R. A. (2022). Faster\n\nSecure Comparisons with Offline Phase for Efficient Private Set Intersection. arXiv preprint arXiv:2209.13913.\n\n[9] Wickert, A. K., Baumg\u00e4rtner, L., Breitfelder, F., & Mezini, M.\n\n(2021, October). Python Crypto Misuses in the Wild. In Proceedings of the 15th ACM/IEEEInternational Symposium on Empirical Software Engineering and Measurement (ESEM) (pp. 1-6).\n\n[10] Acar, Y., Backes, M., Fahl, S., Garfinkel, S., Kim, D.,\n\nMazurek, M. L., & Stransky, C. (2017, May). Comparing the usability of cryptographic apis. In 2017 IEEESymposium on Security and Privacy (SP) (pp. 154-171). IEEE.\n\n[11] Friolo, D., Massacci, F., Ngo, C. N., & Venturi, D. (2022).\n\nCryptographic and financial fairness. IEEETransactions on Information Forensics and Security, 17, 3391-3406.\n\n[12] Kosba, A., Miller, A., Shi, E., Wen, Z., & Papamanthou, C.\n\n(2016, May). Hawk: The blockchain model of cryptography and privacy-preserving smart contracts. In 2016 IEEE symposium on security and privacy (SP) (pp. 839-858). IEEE.\n\n[13] Gracy, M., & Jeyavadhanam, B. R. (2022). MTTBA-AKey\n\nContributor for Sustainable Energy Consumption Time and Space Utility for Highly Secured Crypto Transactions in Blockchain Technology. arXiv preprint arXiv:2209.13431.\n\n[14] Alberto Javarone, M., Di Antonio, G., Valerio Vinci, G.,\n\nPietronero, L., & Gola, C. (2022). Evolutionary dynamics of sustainable blockchains. Proceedings of the Royal Society A, 478(2267), 20220642.\n\n[15] Gort, B. J. D., Liu, X. Y., Sun, X., Gao, J., Chen, S., & Wang,\n\nC. D. (2022). Deep reinforcement learning for cryptocurrency trading: Practical approach to address backtest overfitting. arXiv preprint arXiv:2209.05559.\n\n[16] Rahman, A., Shi, V., Ding, M., & Choi, E. (2022).\n\nSystematization of Knowledge: Synthetic Assets, Derivatives, and On-Chain Portfolio Management. arXiv preprint arXiv:2209.09958.\n\n"
    },
    {
        "number": 1570876394,
        "title": "International Standardized Security Certification for Central Bank Digital Currency (CBDC) and Tokenization Solutions",
        "abstract": "This thesis examines a Central Banking Digital Currency (CBDC) to understand the technology, usage and implementation. It views the benefits and disadvantages of the implementation of a CBDC and understands the technology used for CBDCs. It looks at the improvement areas concerning CBDC, related to people, intercountry relations, and technology.\nThe writer determines the primary issues concerning a CBDC and explores the current regulations and certifications available for implementation in the domains that a CBDC impacts, financial, ID, and telecom. They explore the security vulnerabilities that occur due to the technology used for CBDC. They also make observations regarding the implementation of the existing controls and relating to the updates and modifications required as per the technology present today.\nThe writer presents a solution in the form of a certification focusing on the preventative measures to be taken for key technology domains and key problems that can be resolved by technology such as countering money laundering. The thesis concludes by presenting a comprehensive solution on the steps to implement the certification along with algorithms that will support the organizations in securing the environment further.",
        "review": {
            "strength": [
                "In abstract, it well explained about the CBDC\u2019s current trend and security vulnerabilities, then emphasize the importance about certification.",
                "This is not a paper but a manuscript that writes in multiple places that is basically a proposal for a graduate or undergraduate thesis submitted on September 14, 2022. Further, the concepts are na\u00efve, there is no actual research conducted, and at times the concepts are very loose to even make sense for a thesis proposal. But this is for the student's advisor to determine. The only strength is the topic (title) of this proposal, but being an expert in it, this thesis proposal doesn't even address it in a meaningful way for the work it promises to do.",
                "I think the authors made a mistake in submitting this part of thesis who considered it as a research paper.",
                "This paper examines : \n- Central Banking Digital Currency (CBDC)\n- the benefits and disadvantages of the implementation of a CBDC\n- improvement areas concerning CBDC, related to people, intercountry relations, and technology\n- etc"
            ],
            "shortcoming": [
                "- This paper looks like very little part of other paper. It only introduces that they propose some solution of CBDC certification of CBDC security, but the details are not included.\n- This paper doesn\u2019t follow the IEEE format.\n- In title, it includes Tokenization Solutions, but it doesn\u2019t introduce about tokenization solutions.",
                "This is not a paper but a manuscript that writes in multiple places that is basically a proposal for a graduate or undergraduate thesis submitted on September 14, 2022. Further, the concepts are na\u00efve, there is no actual research conducted, and at times the concepts are very loose to even make sense for a thesis proposal. But this is for the student's advisor to determine. The only strength is the topic (title) of this proposal, but being an expert in it, this thesis proposal doesn't even address it in a meaningful way for the work it promises to do.",
                "I think the authors made a mistake in submitting this part of thesis who considered it as a research paper.\nThe paper has no reference and it does not respect the IEEE format. It does not present a conclusion. The content of the abstract is different from the content of the paper (or part of the thesis).",
                "- We don't know why the author submitted this draft. Is the submission wrong?\n- It must be submitted in accordance with the paper format.\n- It looks like a plan, not a paper, and we can't get any meaningful insight."
            ],
            "comment": [
                "1. In 1.2 Motivation, it says there are introduction part, but this paper doesn\u2019t have introduction section.\n2. In 1.4.3 Certification Domains\n- Iformation -> Information\n- Capitalization is not consistent\n3. In 1.4.4 Certification Deployment, 1.4.5 Certification Colaboration\n- \u201c.\u201d is missing",
                "Unless this PDF submission is done by a mistake, please avoid submitting such manuscripts to workshops and conferences.",
                "I think the authors made a mistake in submitting this part of thesis who considered it as a research paper.\nThe paper has no reference and it does not respect the IEEE format. It does not present a conclusion. The content of the abstract is different from the content of the paper (or part of the thesis).",
                "- We don't know why the author submitted this draft. Is the submission wrong?\n- It must be submitted in accordance with the paper format.\n- It looks like a plan, not a paper, and we can't get any meaningful insight."
            ],
            "score": {
                "Relevance": 2.0,
                "Content and originality": 1.3,
                "Reference": 1.0,
                "Overall recommendation": 1.3,
                "Poster acceptance": 1.8
            }
        },
        "body": "We examine how countries and people would respond to the introduction of a new system of currency, which can perform the same tasks as cash, i.e., it can be used for transactions, storage, debt, obtaining services, or investment. We perform a deep dive into the user needs for a currency system. We peruse technological advances required for CBDC and present ways of preventing drawbacks of token-based CBDC systems. The certification supports the implementation of a minimum level of quality and security, allowing users to accept the technology and ensuring trust with them. Standardization of products by implementing the certification ensures a minimum level of interoperability. Additionally, we introduce controls to ensure Anti Money Laundering in CBDC transactions.\n\n1.4.2 Certification\n\nThrough a thorough understanding of the domains, we present controls that provide a solution for security in CBDC transactions.\n\nWe contribute to two main areas:\n\n1. Addition of security controls to currently existing domains: Utilize currently existing domains from ISO 27001, perform a thorough analysis, and add security controls to each domain relevant to today and foreseeable tomorrow\u2019s CBDC world. Example domains: Vulnerability Assessment, Access Management, Transac- tion, Authentication, Logging and Monitoring, Change Management, and Media Management\n\n2. Addition of new domains: Add domains to secure CBDC and build trust and reliability for users, such as preventing money laundering and security controls for blockchain. New domains: Decentralized Legal Smart Contract Digital Identity Verification and User Identity Management\n\n1.4.3 Certification Domains\n\nThe doimains in which security controls have been proosed on top os ISO 27001 are:\n\n\u2022 User Management \u2013 User Access Management and Iformation Access Management, User adoption, Know your customer (digital identity protection and user identity management and protection\n\n\u2022 Logging and Monitoring\n\n\u2022 Infrastructure Security \u2013 Firewall, Antivirus, Database and Data Transmission, Vulnerability Detection, Backup and Restore, Media management\n\n\u2022 Development \u2013 Secure Development, Change Management, Communication Security\n\n\u2022 Distributed Ledger \u2013 Blockchain immutability, cryptography\n\n\u2022 Currency focused protection \u2013 Anti Money Laundering, Transaction authentication, anti counterfeiting, distribution of power, bank runs, and programmability\n\n1.4.4 Certification Deployment\n\nWe coordinated with numerous companies implementing CBDC in pilot phases to under- stand the security vulnerabilities and create a certification for their prevention. We introduce a standard for CBDC security with security controls for various domains. The certification, alongside, offers a complete guide on its implementation. The guide covers information on collaborating certification bodies, auditing bodies, and the pre-audit and self-assessment questionnaire to understand the level of certification. Furthermore, we provide a process to implement the certification, making it streamlined for organizations to follow the pattern and then secure their environment\n\n1.4.5 Certification Collaboration\n\nWe coordinated with institutions across the world, finally collaborating with the below- mentioned organization for the support\n\n\u2022 BSI \u2013 BSI supports us in implementing the CBDC security regulation as a certifica- tion in Germany\n\n\u2022 BIS \u2013 BIS supports us in creating the CBDC security regulation certification. They help us trickle the certification down to other countries\u2019 central banks as well\n\n\u2022 ISACA \u2013 We collaborate with ISACA to have them as the main auditor for imple- menting the certification at different central banks. We also collaborate with them continually to eventually create a certification for people to become auditors for CBDC or to learn about CBDC.\n\n1.4.6 Algorithms for CBDC security\n\nWe also introduce two algorithms for ease of implementation and checking the implemen- tation of the certification\n\n1. Failover Mechanism \u2013 The failover mechanism algorithm is scripted to minimize the loss in case of technical problems\n\n2. Checking/Assessing the correctness of the configurations \u2013 As configurations of a system are a critical component, the time used in assessing the configurations can be reduced by using the algorithm to check the configurations.\n\n3. \u2013 Attack Mining Algorithm \u2013 An algorithm to scan the infrastructure for known attacks and to catch current attacks and store them in the repository for future control\n\n1.4.7 Cyber Criminal Protection and Attack pattern mining\n\nAdditionally to the certifications we propose a solution to integrate the list of criminals maintained by different organisations to detect attacks and also be aware of attack mining. We provide an algorithm to assist in determining an attack pattern and storing it for future."
    },
    {
        "number": 1570877956,
        "title": "Structured Pools for Tokenized Carbon Credits",
        "abstract": "Tokenized carbon credits are a growing sector of tokens traded on the blockchain via various decentralized and automated mechanisms. Because carbon credits are not fully fungible, they are not well-suited for trading via automated market makers (AMMs) and do so now with limited liquidity in various pools. This limit on the size of liquidity pools can lead to volatile pricing and unduly high price slippage on trades. To resolve this issue and enable deeper liquidity, we present a novel pooling mechanism that enables tokens which are not equivalent in value to be pooled together to back a single, fungible token. This allows for larger pools, and thus deeper liquidity, than what is currently practiced on-chain.",
        "review": {
            "strength": [
                "The paper presents the proof of the key desired properties of proposed structured poos, which authors derived from the previous work on AMMs.",
                "This paper presents a structured pooling mechanism to allow various tokens to be pooled together.",
                "1. Paper presents structured pools, which are smart contracts that are able to pool tokens without imposing a one-for-one valuation \n2. Paper derives six key properties and proved that a contract satisfying their specification also satisfies these key properties"
            ],
            "shortcoming": [
                "- Lack of related work\n- It seems paper organization needs to be improved for readability",
                "This paper lacks related works.  Please compare the proposed method with related works to show the strength and novelty.",
                "1. Paper organization is not acceptable. The structure of the paper interferes with understanding what the paper proposes. No related work section was included, and not enough background was explained.\n2. Only few references."
            ],
            "comment": [
                "- It would be nice to add more NFT trading DEX platforms or the latest research trends on semi-fungible pooling mechanisms as related works.\n- It would be good to subdivide the organization of section 2 to improve the completeness of the paper and improve readability. It is recommended to separate the background section and related work section, which describes tokenized carbon credit, etc., from section 2.",
                "Please add more related work and provide a comparison among existing results. \nPlease add limitations or cons of the proposed method.",
                "- Research on DEX for trading NFTs is currently underway. It would be nice to analyze DEXs that trade semi-fungible or non-fungible tokens and add them as related works."
            ],
            "score": {
                "Relevance": 3.0,
                "Content and originality": 3.3,
                "Reference": 2.3,
                "Overall recommendation": 3.3,
                "Poster acceptance": 3.7
            }
        },
        "body": "I. INTRODUCTION\n\nTokenized carbon credits, which are of growing relevance to voluntary carbon markets [3] [8] [9] [14], have unique metadata and are typically tokenized as non-fungible tokens (NFTs). However, this can lead to low liquidity and high price volatility, so there is a push within the industry to make carbon credits as fungible as possible [10] [13] [15]. The current solution is to pool carbon credits which have similar features, such as a specific vintage or crediting methodology, and to value each pooled token equally within the pool [15]. From a valuation perspective, this discards the differences in constituent credits. Ideally, we would increase liquidity without ignoring these differences. To that end we propose a novel pooling mechanism, called a structured pool , which pools carbon credits without ignoring their differences by valuing pooled tokens relative to each other and facilitating trades between them.\n\nII. RELATED WORK\n\nTokenized carbon credits can be pooled together in limited ways. For example, Toucan, perhaps the most prominent provider of tokenized carbon credits [14], tokenizes carbon credits from the Verra registry as NFTs on Polygon [2]. Each NFT can then be fractionalized as an ERC20 token using a TCO2 token contract. Distinct TCO2 contracts are not mutually fungible because they carry the metadata of the carbon credit they fractionalize. To achieve mutual fungibility, Toucan launched the Base Carbon Tonne (BCT) and the Nature Carbon Tonne (NCT) pools. Any TCO2 token which satisfies the acceptance criteria of one of these pools can be pooled, one-for-one, in exchange for BCT or NCT tokens, respectively. While these pools do increase token fungibility, they do so at the cost of valuing individiaul metadata, and we can go\n\nfurther by removing the required one-for-one exchange rate. Our strategy is to value pooled tokens relative to each other by enabling trading of the pooled non- or semi-fungible tokens. Non- and semi-fungible tokens are typically traded via orderbook-style DEXes which implement various types of auctions, because low liquidity makes it difficult to use market-makers [12]. Two examples are OpenSea, the NFT marketplace with the most extensive user base and sales volume [16], where one can list an NFT or sell it via a timed auction; and OBJKT, a Tezos-based NFT marketplace, where one can sell an NFT via English and Dutch auctions [1]. Even so, there is novel research in market-making for non- or semi-fungible tokens. For example, Kim et al. propose a model for market-making in NFTs which uses option contracts to achieve fair prices [11]. Eulerbeats, an art and music platform which issues algorithmically-generated NFTs, implements a form of AMM by using mathematical properties of the NFTs to determine mint and burn prices [17]. Both of these examples are able to market-make because they can derive stable prices for the non- or semi-fungible tokens being traded. We demonstrate a novel mechanism in market-making for non- or semi-fungible tokens which prices trades by leveraging the fact that tokenized carbon credits belong to a single family of tokens, so their granular metadata can help us value carbon credits relative to each other. Unlike previous work, we draw on the mechanics of commonly-used AMMs to price trades. We proceed as follows: In \u00a7III we specify the structured pool contract. In \u00a7IV we draw on previous work on AMMs to derive desirable properties of market-making contracts. We prove mathematically that a contract satisfying the specification of \u00a7III also satisfies these properties. In \u00a7V we discuss limitations to our approach, and then conclude in \u00a7VI.\n\nIII. STRUCTURED POOLS\n\nA structured pool contract has at least three entrypoints: DEPOSIT , WITHDRAW , and TRADE . The first two, DEPOSIT and WITHDRAW , are for pooling and unpooling constituent tokens, respectively, in exchange for a pool token . The exchange rate from a particular tokenized carbon credit to the pool token is called the pooling exchange rate , and is set individually for each carbon credit which can be pooled. These are also the entrypoints for, respectively, depositing and withdrawing liquidity used for trades, which are executed via the TRADE 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nentrypoint. Each of these entrypoints is governed by equations which price trades and update the pooling exchange rates, which will see shortly. The contract\u2019s storage must keep track of the family of tokens which can be pooled, each of which is called a constituent token , along with the pooling exchange rate of each token in the family. Each pooling exchange rate is assumed to be strictly positive when the contract is deployed. It must also keep track of the contract\u2019s balance of each constituent token, the address of the pool token contract, and the total number of outstanding pool tokens. A brief comment on notation. We refer to our family of constituent tokens as T , where a token t x in the family is described by its token data , which is a contract address and token ID pair. We will typically discuss trades from, e.g. t x to t y , where \u2206 x refers to the quantity traded in, \u2206 y refers to the quantity traded out, and x and y refer, respectively, to the quantity of each token held by the contract. We also write r x as the pooling exchange rate in storage for token t x . 1) Deposits: The DEPOSIT entrypoint accepts the token data of some t x from the token family and a quantity q of tokens in t x to be deposited. The pool contract checks that t x is in the token family. It then transfers q tokens of t x to itself, wich is done by calling the transfer entrypoint of the token t x , which is a standard entrypoint of token contracts. It simultaneously mints q \u2217 r x pool tokens and transfers them to the sender\u2019s wallet. This transaction is atomic, meaning that if any of the TRANSFER or MINT operations fail, the entire transaction fails. 2) Withdrawals: The WITHDRAW entrypoint accepts token data of some t x from the token family and a quantity q of pool tokens the user wishes to burn in exchange for tokens in t x . The pool contract checks that t x is in the token family, and checks that it has sufficient tokens in t x to execute the withdrawal transaction. The pool contract then transfers q pool tokens from the sender to itself and burns them by calling the BURN entrypoint, a standard entrypoint of token contracts. It simultaneously transfers q\n\nr x tokens in t x from itself to the sender\u2019s wallet. As before, the transaction is atomic, so if any of the TRANSFER or BURN operations fail, the entire transaction fails. 3) Trades: The TRADE entrypoint takes the token data of some token t x in T to be traded in, the token data of some token t y in T to be traded out, and the quantity \u2206 x to be traded. It checks that both t x and t y are in the token family, that k > 0 , and that \u2206 x > 0 . It calculates \u2206 y using formulae we will give below, and checks that it has a sufficient balance y in t y to execute the trade action. Then in an atomic transaction, the contract updates the exchange rate r x in response to the trade, transfers \u2206 x of tokens t x from the sender\u2019s wallet to itself, and transfers \u2206 y of tokens t y from itself to the sender\u2019s wallet. The specification is summarized in Figure 1. The contract prices trades by simulating trading along the curve xy = k (for some generic x and y ), where k is the total\n\n(* two auxiliary functions *) fn CALCULATE_TRADE r_x r_y delta_x k =\n\nlet l = sqrt(k / (r_x r_y)) ; l * r_x - k / (l * r_y + delta_x) ;\n\nfn UPDATE_RATE x delta_x delta_y r_x r_y =\n\n(r_x x + r_y * delta_y)/(x + delta_x);\n\n(* pseudocode of the TRADE entrypoint *) fn TRADE t_x t_y delta_x =\n\nlet delta_y = CALCULATE_TRADE\n\nr_x r_y delta_x k ;\n\nif (is_in_family t_x) && (is_in_family t_y) && (delta_x > 0) && (k > 0) && (self_balance t_y >= delta_y) then\n\n<atomic>\n\nr_x <- UPDATE_RATE\n\nx delta_x delta_y r_x r_y;\n\ntransfer (delta_x)\n\nof (t_x) from (sender) to (self) ;\n\ntransfer (delta_y)\n\nof (t_y) from (self) to (sender) ;\n\n</atomic>\n\nelse\n\nfail ;\n\nFig. 1: Pseudocode of the TRADE entrypoint function.\n\nnumber of outstanding pool tokens. A trade of \u2206 x yields \u2206 y tokens such that the following equation holds:\n\n( x + \u2206 x )( y \u2212 \u2206 y ) = k, (1)\n\ngiving\n\n\u2206 y = y \u2212 k\n\nx + \u2206 x . (2)\n\nThis is how trades are priced in the wild for liquidity pools of fungible tokens [5]. We call p s = \u2206 y\n\n\u2206 x the swap price . An important consequence to (1) is that the smaller \u2206 x is compared to k , the closer the exchange happens at a rate of p q = y\n\nx . This is because the derivative of xy = k , or f ( x ) = k\n\nx , is f \u2032 ( x ) = \u2212 k\n\nx 2 = \u2212 y\n\nx ,\n\nand the smaller \u2206 x is relative to k , the more accurately the tangent line at some ( x 0 , y 0 ) approximates the convex curve xy = k . We call p q = y\n\nx the quoted price .\n\n5 10 15 20 25 30\n\n10\n\n20\n\n30\n\nk = 50\n\n\u2206 x\n\n\u2206 s y\n\n\u2206 x\n\n\u2206 q y\n\nFig. 2: A trade of \u2206 x = 3 for \u2206 q y and \u2206 s y , respectively, at k = 50 . \u2206 q y = p q \u2206 x is the trade priced at the quoted price p q and \u2206 s y = p s \u2206 x is the trade priced at the swap price p s .\n\nThe difference p q \u2212 p s is called the price slippage [17, \u00a73.2.4]. It is important to note that p s is always less than p q because p q is calculated by moving \u2206 x along the tangent line from a starting point ( x 0 , y 0 ) representing the current state of the contract\u2019s funds available for trading, and p s is calculated by moving \u2206 x along xy = k . Since xy = k is convex, moving \u2206 x along the tangent line always results in a larger \u2206 y than moving along xy = k . See Figure 2 for a graphical illustration, where \u2206 q y is the output of a trade priced at p q and \u2206 s y is the output of a trade priced at p s . In particular, this means that\n\n\u2206 s y < p q \u2206 x (3)\n\nalways holds, since \u2206 s y = p s \u2206 x . This fact is crucial to the mechanics of how structured pools update relative prices in response to trading activity. We use the pooling exchange rates to inform quoted prices between tokens, and then simulate trades along the curve xy = k (for some generic x and y ). If the token t x pools at a rate of r x , meaning r x is the value of t x in terms of pool tokens, and the token t y pools at a rate of r y , then t x can be valued relative to t y at a rate of\n\nr x,y := r x\n\nr y . (4)\n\nIt is perhaps counterintuitive that r x is in the numerator and not the denominator of r x,y , considering that p q = y\n\nx in the generic case, but this is due to the fact that r x indicates pool tokens per t x , and we want r x,y to indicate t y valued in terms of t x . To price a trade we begin by finding \u2113 such that\n\n( \u2113r y )( \u2113r x ) = k,\n\nwhere k is the total number of outstanding pool tokens in the contract\u2019s storage. The trade then yields \u2206 s y tokens such that\n\n( \u2113r y + \u2206 x )( \u2113r x \u2212 \u2206 s y ) = k. (5)\n\nThis formula yields the quoted price of this trade as\n\np q = \u2113r x\n\n\u2113r y = r x\n\nr y = r x,y , (6)\n\nas desired. The swap price, then, is\n\np s = \u2206 s y\n\n\u2206 x (7)\n\nwhere \u2206 s y = \u2113r x \u2212 k\n\n\u2113r y + \u2206 x . (8)\n\nFor the rest of this document, we will write \u2206 s y simply as \u2206 y unless explicitly stated otherwise. After executing a trade, if we do not adjust pooling exchange rates, the pool token is now overcollateralized. We can see this because by (3),\n\nr y \u2206 y < r x \u2206 x ,\n\nso a trade deposits slightly more in terms of pool tokens ( r x \u2206 x ) than it removes ( r y \u2206 y ). Thus the sum of the value of all the constituent tokens at their current valuation is now greater than the total number of outstanding pool tokens. To avoid this, we adjust the values of the constituent tokens so that their sum at the new valuation is equal to the total number of outstanding pool tokens. In a trade t x to t y , because it is possible to deplete t y from the pool, we cannot reliably regain pooled consistency by adjusting the value of the token being traded for in the pool. We know, however, that we have a supply of t x because that was the deposited token. Thus to regain pooled consistency, we have to slightly devalue t x in relation to the rest of the pool tokens. To do so, we divide the quantity of pool tokens by its collateral in t x to get an updated exchange rate r \u2032 x as follows:\n\nr \u2032 x := r x x + r y \u2206 y\n\nx + \u2206 x . (9)\n\nEquation (9) updates the pooling exchange rate of t x so that the pool token is neither under- nor over-collateralized. Consider as an example a pool with three constituent tokens t x , t y , and t z , and pooling exchange rates r x = 2 , r y = 1 , and r z = 1 . That is, t x is valued at two pool tokens for one token, and each of t y and t z are valued at one pool token for one token. Suppose we have 10 t x , 15 t y , and 15 t z pooled, thus having 20 + 15 + 15 = 50 outstanding pool tokens. Now suppose that we trade 1 t x for slightly less than 2 t y (the quoted price would be exactly 2). Using our formulae, \u2113 = q\n\n50\n\n2 = 5 and \u2206 y \u2248 1 . 67 (slippage is high because of the small amount of liquidity). Post trade, we have in our pool 11 t x , 13.33 t y , and 15 t z , giving us in the pool the equivalent in constituent tokens as\n\n2 \u2217 11 + 1 \u2217 13 . 33 + 1 \u2217 15 = 50 . 33\n\npool tokens with our unadjusted pooling exchange rates. To rectify this, bringing the pool back down to the value of 50 pool tokens, we slightly devalue t x relative to the other tokens in the pool. We use the formula (9)\n\nr \u2032 x = # pool tokens\n\n# tokens of t x = r x x + r y \u2206 y\n\nx + \u2206 x \u2248 1 . 97 ,\n\nwhich adjusts r x so that the 11 t x are now worth about 21.67 pool tokens instead of 22. This gives us our desired\n\n1 . 97 \u2217 11 + 1 \u2217 13 . 33 + 1 \u2217 15 = 50 .\n\nAfter this update, t y is valued more in relation to t x , which makes sense because t x was sold to buy t y . One t y used to be worth half of t x , and now it is valued at r y r \u2032 x \u2248 0 . 508 .\n\nWe need to make sure that the relative price of t y didn\u2019t rise so much that if we trade back for t x , we have more in t x than we started with. If this were the case, we would have an opportunity for arbitrage within the structured pool, something we wish to avoid. The quoted price for trading our roughly 1.67 t y back to t x would give us about 0 . 508 \u2217 1 . 67 \u2248 0 . 848 , which is less than 1, as desired. We end this section with a note that in these calculations, we implicitly assumed exchange rates r x to be rational numbers by which we can multiply and divide freely so long as r x > 0 . Of course, implementations will include rounding error, and so we add to the specification that the UPDATE_RATE function return a positive number if the numerator and denominator of the quotient are positive. We also specify that the CALCULATE_TRADE function return a positive number if k , r x , r y , and \u2206 x are positive, and that \u2206 y < r x\n\nr y \u2206 x always be true for successful trades.\n\nIV. PROPERTIES OFS TRUCTUREDP OOLS\n\nThe structured pool contract is designed to imitate AMMs in how it prices trades and updates the pooling exchange rates. While AMMs such as Uniswap have been shown to exhibit desirable economic behaviors [5], it is not obvious that the structured pool contract will do the same. To that end, we draw on work by Angeris et al. [4] [5], Bartoletti et al. [6] [7], and Xu et al. [17] on AMMs and DeFi, from which we derive six properties indicative of desirable market behavior from game-theoretic and economic perspectives.\n\nProperty 1 (Demand Sensitivity) . Let t x and t y be tokens in our family with nonzero pooled liquidity and exchange rates r x , r y > 0 . In a trade t x to t y , as r x is updated to r \u2032 x , it decereases relative to r z for all z \u0338 = x , and r y strictly increases relative to r x .\n\nProof. First we prove that r \u2032 x < r x . We must prove:\n\nr \u2032 x = r x x + r y \u2206 y\n\nx + \u2206 x < r x x + r x \u2206 x\n\nx + \u2206 x = r x ( x + \u2206 x )\n\nx + \u2206 x = r x ,\n\nwhich holds if r y \u2206 y < r x \u2206 x . By (3) and (6):\n\n\u2206 y < r x\n\nr y \u2206 x = p q \u2206 x ,\n\nso r y \u2206 y < r x \u2206 x as desired. By the specification, r z remains constant for all t z \u0338 = t x under TRADE , so as r x is updated to r \u2032 x it decreases relative to r z . That r y strictly increases relative to r x is due to the fact that r \u2032 x < r x and r y stays constant.\n\nProperty 2 (Nonpathological Prices) . For a token t x in T , if there is a contract state such that r x > 0 , then r x > 0 holds for all future states of the contract.\n\nProof. We only need to show that r x > 0 implies r \u2032 x > 0 , since TRADE is the only entrypoint that updates exchange rates. Consider a contract state such that r x > 0 , and an incoming trade from t x to some t y of quantity \u2206 x > 0 . Because \u2206 y is calcluated such that\n\n( \u2113r y + \u2206 x )( \u2113r x \u2212 \u2206 y ) = k,\n\nand since r x , r y , and \u2206 x are all positive, we know that \u2206 y is positive so long as k is not zero. If k is zero, the transaction fails as we specified for the TRADE entrypoint, so we know that \u2206 y > 0 . Since r y \u2206 y < r x \u2206 x and x cannot be negative we have that\n\n0 < r y \u2206 y < r x \u2206 x < r x ( x + \u2206 x ) ,\n\nrendering the numerator of r \u2032 x ,\n\nr x x + r y \u2206 y ,\n\nalways positive. Since \u2206 x is positive and x cannot be negative, the denominator of r \u2032 x ,\n\nx + \u2206 x ,\n\nis also positive, which gives our result. Our result holds, then, so long as the UPDATE_RATE function return a positive number if the numerator and denominator of the quotient are positive, which we specified for the TRADE entrypoint.\n\nProperty 3 (Swap Rate Consistency) . Let t x be a token in our family with nonzero pooled liquidity and r x > 0 . Then for any \u2206 x > 0 there is no sequence of trades, beginning and ending with t x , such that \u2206 \u2032 x > \u2206 x , where \u2206 \u2032 x is the output quantity of the sequence of trades.\n\nProof. Consider tokens t x , t y , and t z with nonzero liquidity and with r x , r y , r z > 0 . First, we claim that the following inequality holds for all x \u2265 0 and all trades from t x to t y :\n\nr y \u2206 y \u2264 r \u2032 x \u2206 x . (10)\n\nSince r \u2032 x = r x x + r y \u2206 y\n\nx + \u2206 x , (9)\n\n(10) simplifies to\n\nr y \u2206 y ( x + \u2206 x ) \u2264 \u2206 x ( r x x + r y \u2206 y ) ,\n\nwhich in turn simplifies to\n\nr y \u2206 y x \u2264 r x \u2206 x x.\n\nSince we know that r y \u2206 y \u2264 r x \u2206 x from (3), we can see that our inequality holds for all x \u2265 0 , as desired. Now we consider sequences of trades beginning and ending with t x . For a trade t x to t x , we have our result because\n\n\u2206 \u2032 x < r x\n\nr x \u2206 x = \u2206 x\n\nby (3). Now consider a trading loop from t x to t y , and back to t x , for t y \u0338 = t x . We have our result if we can show r y r \u2032 x \u2206 y \u2264 \u2206 x\n\nis satisfied, because r y\n\nr \u2032 x \u2206 y is an upper bound on the quantity that \u2206 y can be traded for as p s < p q . This, of course, is given by (10) and the fact that r \u2032 x > 0 from Property 2. Finally, consider a trade from t x to t y , to t z , and back to t x . Similar to before we need to show that r z r \u2032 x \u2206 z \u2264 \u2206 x\n\nis satisfied. But we have from (10) that\n\nr z \u2206 z \u2264 r \u2032 y \u2206 y \u2264 r y \u2206 y \u2264 r \u2032 x \u2206 x ,\n\nas desired. This proof can be easily seen to apply to trading loops of arbitrary length, which proves our result.\n\nProperty 4 (Zero-Impact Liquidity Change) . The quoted price of trades is unaffected by calling DEPOSIT and WITHDRAW .\n\nProof. We have this result because the quoted price depends only on the pooling exchange rates, as we saw in (4), and as per the specification, only the TRADE entrypoint alters pooling exchange rates.\n\nProperty 5 (Arbitrage sensitivity) . Let t x be a token in our family with nonzero pooled liquidity and r x > 0 . If an external, demand-sensitive market prices t x differently from the structured pool, then assuming sufficient liquidity, with a sufficiently large transaction either the price of t x in the structured pool converges with the external market, or the trade depletes the pool of t x .\n\nProof. Suppose the structured pool prices a constituent token t x higher than an external market. Then an arbitrageur can buy t x elsewhere and sell them into the structured pool. Doing so devalues t x relative to the other tokens, as we have shown. Recall that 0 < r \u2032 x < r x , so to prove our result we just need to show that 0 is the greatest lower bound of r \u2032 x . Note that by definition, \u2206 y = \u2206 s y , so substituting (8)\n\n\u2206 s y = \u2113r x \u2212 k\n\n\u2113r y + \u2206 x ,\n\nr \u2032 x = r x x + r y \u2206 y\n\nx + \u2206 x = r x x + \u2113r x r y \u2212 r y k\n\n\u2113r y +\u2206 x\n\nx + \u2206 x .\n\nThen\n\nr \u2032 x < r x x + \u2113r x r y\n\nx + \u2206 x\n\nand since x , r x , r y , and \u2113 are constants for a trade, for any r , 0 < r < r x , by choosing a sufficiently large \u2206 x we can make r \u2032 x < r . Thus assuming sufficient external liquidity, we have our result. Now suppose the structured pool prices a constituent token t x lower than an external market. Then an arbitrageur can buy t x from the structured pool and sell them elsewhere. Doing so does not change r x , as per the specification. However, the external market is demand sensitive, so the price of t x will decrease on that market. Then we know that after a trade of \u2206 x = x , either the external market now prices t x lower than the structured pools contract, meaning there was some\n\n\u2206 \u2032 x < \u2206 x\n\nwhich gives our result, or the trade depletes the pool of t x , giving our result.\n\nProperty 6 (Pooled Consistency) . The following equation always holds: X\n\nt x r x x = k (11)\n\nProof. As a base case, by the specification, at the time of contract deployment k = 0 and we have no pooled liquidity, so (11) holds trivially because x = 0 for all t x . For our inductive step, consider a contract state for which (11) holds. If we call DEPOSIT , (11) holds by definition because for a deposit of d x of t x , we mint r x d x pool tokens. The same is true if we call WITHDRAW . Finally, if we call TRADE from tokens t x to t y , then there is an excess number of tokens in t x , violating (11). This excess is quantified in (9) and remedied by adjusting r x to r \u2032 x as we saw before.\n\nV. LIMITATIONS\n\nWhile we have proved that some properties of AMMs, shown to be indicative of desirable market behavior by the literature, hold for structured pools, our work has limitations. Firstly, the properties in the literature which we drew on were derived for AMMs using custom, formal models of the blockchain to justify the results, but we adapted them to our use case somewhat informally and without using a formal model of the blockchain. It is not obvious that they imply the same notions of desirable market behavior for structured pools in the same way that they apply to AMMs. In particular, Property 5, arbitrage sensitivity, is weaker than the similar properties in the literature because the pool can deplete in some constituent tokens (though not entirely through trading). This may be problematic if the value of one constituent token plummets for whatever reason, as this could cause the pool to deplete in every token but the now-devalued one. Whether this is actually an issue may depend on the specific use case and family of tokens.\n\nFinally, while these proofs are mathematical and rely on the specification, there is always a possibility of error due to incorrect assumptions or because we do not base this in an explicit and formal model of a blockchain. These results would be more reliable if this contract specification and proofs were embedded in a formal system.\n\nVI. CONCLUSION\n\nThe goal of this paper was to enable greater fungibility for tokenized carbon credits, improving on current methods which pool tokens at the expense of individual token metadata. We presented structured pools, which are able to pool tokens without imposing a one-for-one valuation. Structured pools value constituent tokens relative to each other in a dynamic way by facilitating trades between constituent tokens and updating relative prices in response to trading activity. To show that structured pools satisfy desirable properties of AMMs, we drew on previous research on AMMs and DeFi, including [4], [5], [6], [7], [17], and we derived six key properties and proved that a contract satisfying our specification also satisfies these key properties. As we pointed out in \u00a7V, for any actual implementation, these properties would ideally be formalized and proved within a formal system. This paper demonstrates that it is possible to pool tokens in a wide-ranging token family without imposing a one-for- one valuation on the constituent, pooled tokens. We hope that this will be useful to pool and trade tokenized carbon credits with deeper on-chain liquidity. While this targets tokenized caron credits on the blockchain, we conjecture that this pooling mechanism could be useful for other cases, including tokenized commodities more broadly.\n\nREFERENCES\n\n[1] Objkt.com \u2014 The largest Digital Art & Collectible marketplace on Tezos. https://www.objkt.com. Accessed March 2023.\n\n[2] Toucan Whitepaper. https://docs.toucan.earth/. Accessed March 2023. [3] UNSupports Blockchain Technology for Climate Action \u2014 UNFCCC. https://unfccc.int/news/un-supports-blockchain-technology- for-climate-action.\n\n[4] Guillermo Angeris, Akshay Agrawal, A. Evans, T. Chitra, and Stephen P. Boyd. Constant Function Market Makers: Multi-Asset Trades via Convex Optimization. 2021.\n\n[5] Guillermo Angeris, Hsien-Tang Kao, Rei Chiang, Charlie Noyes, and Tarun Chitra. An Analysis of Uniswap markets. Cryptoeconomic Systems , 0(1), April 2021. doi:10.21428/58320208.c9738e64 .\n\n[6] Massimo Bartoletti, James Hsin-yu Chiang, and Alberto Lluch Lafuente. Towards a Theory of Decentralized Finance. In Matthew Bernhard, Andrea Bracciali, Lewis Gudgeon, Thomas Haines, Ariah Klages- Mundt, Shin\u2019ichiro Matsuo, Daniel Perez, Massimiliano Sala, and Sam Werner, editors, Financial Cryptography and Data Security. FC 2021 International Workshops , Lecture Notes in Computer Science, pages 227\u2013232, Berlin, Heidelberg, 2021. Springer. doi:10.1007/ 978-3-662-63958-0_20 .\n\n[7] Massimo Bartoletti, James Hsin-yu Chiang, and Alberto Lluch- Lafuente. ATheory of Automated Market Makers in DeFi. In Ferruccio Damiani and Ornela Dardha, editors, Coordination Models and Languages , Lecture Notes in Computer Science, pages 168\u2013187, Cham, 2021. Springer International Publishing. doi:10.1007/ 978-3-030-78142-2_11 .\n\n[8] Andres Diaz-Valdivia and Marta Poblet. Governance of ReFi Ecosystem and the Integrity of Voluntary Carbon Markets as a Common Resource, November 2022. doi:10.2139/ssrn.4286167 .\n\n[9] Xiaoqun Dong, Rachel Chi Kiu Mok, Durreh Tabassum, Pierre Guigon, Eduardo Ferreira, Chandra Shekhar Sinha, Neeraj Prasad, Joe Madden, Tom Baumann, Jason Libersky, Eamonn McCormick, and Jefferson Cohen. Blockchain and emerging digital technologies for enhancing post-2020 climate markets. https://tinyurl.com/bdz5wczb.\n\n[10] Gregor Dorfleitner, Franziska Muck, and Isabel Scheckenbach. Blockchain applications for climate protection: A global empirical investigation. Renewable and Sustainable Energy Reviews , 149:111378, October 2021. doi:10.1016/j.rser.2021.111378 .\n\n[11] Kristof Lommers, Jack Kim, and Mohamed Baioumy. Market Making in NFTs. Available at SSRN 4226987 , 2022.\n\n[12] Matthieu Nadini, Laura Alessandretti, Flavio Di Giacinto, Mauro Martino, Luca Maria Aiello, and Andrea Baronchelli. Mapping the NFT revolution: Market trends, trade networks, and visual features. Sci Rep , 11(1):20902, October 2021. doi:10.1038/ s41598-021-00053-8 .\n\n[13] Eric Nowak. Voluntary Carbon Markets. https://tinyurl.com/k8sbhemf, March 2022.\n\n[14] Adam Sipthorpe, Sabine Brink, Tyler Van Leeuwen, and Iain Staffell. Blockchain solutions for carbon markets are nearing maturity. One Earth , 5(7):779\u2013791, July 2022. doi:10.1016/j.oneear.2022. 06.004 .\n\n[15] Derek Sorensen. Tokenized carbon credits. Preprint , 2023. URL: https: //derekhsorensen.com/docs/sorensen-tokenized-carbon-credits.pdf.\n\n[16] Bryan White, Aniket Mahanti, and Kalpdrum Passi. Characterizing the OpenSea NFTMarketplace. In Companion Proceedings of the Web Conference 2022 , WWW \u201922, pages 488\u2013496, New York, NY, USA, August 2022. Association for Computing Machinery. doi:10.1145/ 3487553.3524629 .\n\n[17] Jiahua Xu, Krzysztof Paruch, Simon Cousaert, and Yebo Feng. SoK: Decentralized Exchanges (DEX) with Automated Market Maker (AMM) Protocols. ACMComput. Surv. , 55(11):238:1\u2013238:50, February 2023. doi:10.1145/3570639 ."
    },
    {
        "number": 1570878432,
        "title": "Secure Arbitrage Trades Between Centralized and Decentralized Exchanges",
        "abstract": "This paper discusses both the architectural and\nconceptual differences between centralized and decentralized exchanges,\nwith a particular focus on what these two aspects mean\nfor combining these exchanges in arbitrage transactions. An\narchitectural approach that allows centralized and decentralized\nexchanges to be combined in smart contract-based arbitrage\ntransactions is then presented, and the notion of \"flash\"-like\ntransactions is introduced in this context. Then, an example implementation\nis presented that proves that \"flash\"-like arbitrage\ntransactions between different types of transactions are possible\nbased on this architecture. After a discussion of the advantages\nof the presented approach with respect to risk management, an\nevaluation of the presented example implementation is described.",
        "review": {
            "strength": [
                "This paper discusses both the architectural and conceptual differences between centralized and decentralized exchanges, with a particular focus on what these two aspects mean for combining these exchanges in arbitrage transactions.",
                "This paper is organized, and the idea is clear. An example is provided to demonstrate the feasibility of the design.",
                "Timely topic.\nThe paper presents a thorough review of the current literature on topic of high-frequency trading.\nThe paper offers a clear argument and proposes a solution to the problem of arbitrage between Cex and Dex, however financial part of this is still missing.",
                "1. Paper suggests an architecture that is relatively easy to apply to any centralized exchange by introducing liquidity pools, which would make them immediately accessible to the strategies described in this paper."
            ],
            "shortcoming": [
                "- It\u2019s hard to find novelty or originality\n- No related works and future works\n- Low quality of presentation in figure and source code",
                "There is little technical contribution found in this paper. There is little technical contribution found in this paper. There is little technical contribution found in this paper.",
                "Needs more related work to arbitrage.\nNeeds more technical details and results on evaluation, at least gas costs and performance analysis.\nSecurity analysis is missing.\nThe paper could benefit from more examples or case studies to support the proposed solution and to illustrate the real-world impact of the problem.",
                "1. It is difficult to see that the architecture presented in the paper is a new idea, and it is interpreted that arbitrage trading was simply tested using an existing service(WX.network) that already reflected the proposed architecture. Therefore, it is difficult to find high contribution and novelty\n2. Careful proofreading is required"
            ],
            "comment": [
                "- It is difficult to see that the idea presented in the thesis has a high degree of because it seems to be nothing more than an experiment of arbitrage trading through currently open services (WX.network).\n- Since future work is not included, it would be better to specify future research direction in detail.",
                "This paper proposes an architecture to allow smart contract based arbitrage transactions to interact with both centralized and decentralized exchanged systems (CEX and DEX). There is an implementation example to demonstrate the possibility of conducting arbitrage under the proposed architecture. \nThis paper also demonstrates that the arbitrage transaction can be \"flash\"-like, which means that it can be done in one transaction. \n\n The idea of combining CEX and DEX is good. However, there can be more discussions around what would be the impacts of such integration.  For example, if the DEX and CEX are supported by the same liquidity pool, would transactions in DEX affect the transactions (e.g. prices) in CEX? \nAs mentioned in the paper, the underlying models of CEX and DEX are different. How would market behavior change after the combination?  Besides, is there any previous work on combining CEX and DEX?\n\nArbitrage in \"flash\"-style transaction is the focus of the paper. There are many previous works studying flash loan based attacks and finding the best attack vector, which are not mentioned in this paper. \nThe strategies to find the \"favorable path\", page 4, are not discussed. In section V, the risk factors are analyzed on the side of users performing the arbitrage. Are there any potential risks on the exchange protocols (CEX and DEX)?\n\nMinor error:\nFigure 1, \"smart contract\" label is not clear to see and please fix the red underlines in the figure.",
                "Overall, the paper provides a comprehensive analysis of the differences between centralized and decentralized exchanges and proposes an innovative approach for connecting them in arbitrage transactions. The example implementation presented in the paper demonstrates the feasibility of this approach and the advantages it offers in terms of risk management. The paper is well-written and provides a valuable contribution to the field of decentralized finance.",
                "- It is recommended to improve the completeness of the paper by analyzing the source code and modifying the figure of architecture. In particular, the red underline shown in the figure representing the architecture does not seem appropriate."
            ],
            "score": {
                "Relevance": 3.0,
                "Content and originality": 2.0,
                "Reference": 2.5,
                "Overall recommendation": 2.0,
                "Poster acceptance": 3.5
            }
        },
        "body": "I. INTRODUCTION\n\nThe field of decentralized finance has become increasingly important since the introduction of Bitcoin [1]. Here, there are numerous platforms where providers make products available to customers who can invest their money accordingly without having to relinquish control over their financial resources. An important component of these platforms are exchanges that allow users to trade various assets. So-called liquidity pools for decentralized exchanges have existed in this area for some time. However, there are also initial approaches to offer these also for order book-based, and thus centralized, exchanges. Trading behavior on these exchanges differs fundamentally from that on decentralized exchanges, which are generally structured according to the automated market maker approach. To improve the comprehensibility of this article, the relevant terms must first be clarified. The main technical topic is an ar- chitecture that enables decentralized and centralized exchanges to be connected using smart contracts. As an example, flash arbitrage trades are performed here between these two types of exchanges. While such flash arbitrage trades between DEXs are already common, it has not yet been possible to perform flash arbitrage trades between order book-based exchanges, between order book-based and AMM-based exchanges, or in combination with flash loans. The most important concept that needs to be understood for the presented approach is the concept of \u201dflash\u201d transactions. Probably the first appearance of the term \u201dflash\u201d in this context is due to the flash loans used for a form of attack on the\n\nEthereum network using the concept of flash loans introduced by the Marble protocol. The basic idea is to borrow some tokens on a lending platform, do something with those tokens, and pay back the loan in the same transaction in which it was taken. This concept is not limited to lending, but can be extended to anything that can be done on decentralized finance platforms. Therefore, the \u201dflash\u201d concept as used in this article refers to a series of operations performed in a single transaction.\n\nII. STATE OFTHE ART\n\nFor the two exchange types: centralized and decentralized [6], trust and trading algorithms differ. Centralized exchanges usually use order book approach with bid submissions, con- tinuous matching and trades settled, while decentralized ones act according to the AMM model. Decentralized exchanges use liquidity pools where asset ratio determines price. Asset purchase decreases asset quantity in the pool, changing asset relationship and price. Integration difficulties cause manual execution of arbitrage trades on decentralized exchanges. Concept of arbitrage trades [7], [8] is crucial to this article. It uses different exchange prices for asset profit. Triangular arbitrage is possible but not covered. Arbitrage applies to traditional markets and high-frequency trading strategies. It en- sures price equality across exchanges with potentially different architectures and strategies without harming the markets. A new decentralized finance technique, flashloans [5], can reduce certain action risks. Flashloans involve taking out an immediately repaid loan, increasing action certainty. Interest payments aren\u2019t required and loans must be repaid in the same block or transaction.\n\nIII. ARCHITECTURE\n\nTo combine centralized and decentralized exchanges in a \u201dflash\u201d style, both types must be available via a smart contract. Typically, the problem is that decentralized exchanges are easily accessible via smart contracts (since they are usually implemented as smart contracts themselves), but centralized exchanges are not accessible in the same way via smart contracts. Additional liquidity pools can be used beyond their main function of providing liquidity by providing liquidity to the order books of the central exchange. This liquidity 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\ncan then be used by different market making strategies, e.g., a grid trading strategy. In such an architecture (see Fig.\n\nFig. 1. Architecture that allows to combine centralized and decentralized xchange \u201dflash\u201d style\n\n1), the central exchange would continue to be available via web services, e.g., to traditional trading bots or users acting through a website, while at the same time a smart contract could add and remove liquidity for trading pairs on the central exchange. Liquidity pool liquidity could be used to fuel traditional market making strategies, such as the grid trading strategy, thereby increasing the liquidity of the central exchange\u2019s order books. If the liquidity pool enables one-way provision and withdrawal of liquidity, a smart contract can exchange one token for another by adding liquidity to the corresponding liquidity pool in the token to be sold and withdrawing liquidity from the same pool in the token to be bought. This type of trade helps the liquidity pool maintain the relationship between the tokens in the pool and the market price of the corresponding tokens.\n\nIV. IMPLEMENTATION\n\nAs described in section III, the main idea of combining cen- tralized and decentralized exchanges in smart contracts is to provide liquidity pools for central exchanges. This requirement is relatively easy to implement and does not require additional functionality on the part of centralized exchanges, but can simply be added to existing structures. Various market making strategies [2], [3] allow effective use of the additional liquidity provided by the pool. The only strict requirement that must be ensured is that the liquidity can be provided and withdrawn unilaterally, which can be implemented through the pathway protocol as described in [4].\n\nV. RISK PERSPECTIVE\n\nThe \u201dflash\u201d execution of processes such as arbitrage trading described above is particularly interesting from a risk perspec- tive. Good arguments for this include:\n\n\u2022 One transaction via a smart contract executes all actions or none, preventing unintended actions. If one action fails, all previous actions are undone. For instance, a successful buy but a failed sell would undo the buy.\n\n\u2022 Single transaction ensures no interference. Conditions checked directly, trade executed safely with smart con- tract ensuring profit certainty.\n\n\u2022 \u201dFlash\u201d transactions reduce platform trust. High fees risk trade unprofitability, and validity checks in smart contracts fail. Withholding transfers poses similar issues.\n\nVI. EVALUATION\n\nIn order to implement the trading strategy of flash arbitrage trades described above, we first implemented a smart con- tract, since the transactions should be done in \u201dflash\u201d style. Afterwards a small Python script was implemented to actually test the implemented smart contract. The successful execution, with a positive outcome, evaluated that the above described is possible. It is important to stress here that this evaluation was not performed in some lab setting, but on real world exchanges.\n\nVII. OUTLOOK ANDF UTUREW ORK\n\nDeFi is like \u201dmoney legos\u201d where products and strategies combine. This method can join flash loans for flash loan arbitrage trades with AMM and order book-based exchanges. Trustless lending platform use eliminates the need for trust. Combining technologies, platforms, and strategies executed \u201dflash\u201d style makes sense. Easily apply the presented archi- tecture (invented and implemented on WX.network) to any centralized exchange by adding liquidity pools. This makes them usable with described strategies.\n\nREFERENCES\n\n[1] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash system. Decentral- ized Business Review: 21260. (2008)\n\n[2] Y. Xiong, T. Yamada, T. Terano. Exploring Market Making Strategy for High Frequency Trading: An Agent-Based Approach. In: Takayasu, H., Ito, N., Noda, I., Takayasu, M. (eds) Proceedings of the International Conference on Social Modeling and Simulation, plus Econophysics Colloquium 2014. Springer Proceedings in Complexity. Springer, Cham. (2015)\n\n[3] Y. Xiong, T. Yamada and T. Terano, Comparison of different market making strategies for high frequency traders, 2015 Winter Simulation Conference (WSC) (2015) pp. 324-335.\n\n[4] M. Jansen, I. Sapranidi, A. Pupyshev. Proofs and Limitations of the Pathway Protocol. J. Prieto et al. (Eds.): BLOCKCHAIN 2022, LNNS 595, pp. 1\u201310, (2023)\n\n[5] D. Wang, W. Siwei, L. Ziling Lin, Y. Xingliang, H. Zhou, K. Ren. Towards a first step to understand flash loan and its applications in defi ecosystem. In Proceedings of the Ninth International Workshop on Security in Blockchain and Cloud Computing, pp. 23-28. (2021)\n\n[6] A. Barbon, A. Ranaldo. On The Quality Of Cryptocurrency Mar- kets: Centralized Versus Decentralized Exchanges. ARXIV.2112.07386 (2021)\n\n[7] E. Davila, D. Daniel, C. Graves, C. Cecilia Parlatore. The Value of Arbitrage. No. w29744. National Bureau of Economic Research. (2022)\n\n[8] A. Shleifer, R. W. Vishny. The limits of arbitrage. The Journal of finance 52, no. 1: 35-55. (1997)"
    },
    {
        "number": 1570879619,
        "title": "The Web3 Financial De-Revolution: Mapping the Impact of Centralization on Exchange Implosion and Decentralization as a Survival Mechanism",
        "abstract": "A growing body of research suggests that decentralization is the next step in organizational evolution. However, models on how Web3 organizations live, survive, and die remain overly simplified. We develop a theoretical framework for understanding the survival and failure of Web3 organizations through the lens of institutional theory. A brief analysis of four centralized financial exchanges (Celsius, FTX, Voyager, Gemini Earn) and six decentralized financial exchanges (UniSwap, MakerDAO, Aave, Lido, Quickswap and Curve) are presented as support for this theoretical model. Additionally, a preliminary avenue for further research is offered: We argue that isomorphism encourages Web3 financial entities to become more centralized and that the organizational hybridity generated from centralization decreases the survival rates of Web3 organizations. We recommend that Web3 financial organizations retain decentralization and mitigate isomorphism by integrating polycentrism.",
        "review": {
            "strength": [
                "- Paper develops a theoretical framework for understanding the survival and failure of Web3 organizations through the lens of institutional theory.\n- Background and references to understand the paper are appropriate.",
                "This paper seems to be well written in terms of the paper composition and content especially in proposed theoretical framework.",
                "This paper proposes a theoretical framework for the development of decentralized organizations, DAOs.\nIt also presents an analysis of existing decentralized exchanges and centralized exchanges and the results of the analysis on centralization.",
                "1. Paper proposes a theoretical framework for understanding the survival and failure of web3 organizations through the lens of institutional theory.\n2. Paper presents appropriate and sufficient background information for understanding the overall mechanism."
            ],
            "shortcoming": [
                "- Low contribution. Although the paper presents the mechanisms of isomorphism and polycentricity that affect Web3 organization hybridity, it only describes general concepts and ultimately does not provide a convincing evaluation of how they affect the survival of web3 organizations.\n- The input data do not fully explain what the paper suggests. Experimental data is not convincing enough of what the framework is trying to explain. In particular, no answers were given for Rq2 and Rq3.\n- The analysis presented in Section 6 does not seem reasonable.",
                "1. The contribution of the paper should be clearly presented. \n2. In Figure 1, it is not clear and difficult to understand. It needs to be more explained.",
                "A framework has been proposed, but no picture of the system architecture of the framework exists.\nThere is a lack of research on existing frameworks that measure the degree of decentralization.",
                "1. It is hard to find a high contribution. The paper tries to analyze the survival of web3 organizations using isomorphism and polycentrism, but what the paper suggests is somewhat general.\n2. The answers to the three questions presented at the beginning of the dissertation were not sufficiently presented, and the analysis of the evaluation felt inappropriate. It is not reasonable to predict the survival of an exchange using ownership alone."
            ],
            "comment": [
                "-It does not seem reasonable to discuss the survival of web3 only with the degree of ownership concentration without discussing the actual reason for the bankruptcy of the exchange.\n- The web3 survival mechanism is explained, but it does not seem appropriate to compare CEX and DEX, not between web3 platforms.\n- It is necessary to establish an accurate concept of \u201cWeb3 financial exchange\u201d.\n- Insufficient evidence has been presented for the assertion that the Gemini exchange will go bankrupt in the near future based on the ownership concentration level.",
                "In this paper, author proposed a  theoretical framework for understanding the survival and failure of Web3 organizations through the lens of institutional theory\nThey also analyze both centralized / decentralized financial exchanges and  presented as support for their proposed theoretical model\n\nThis paper seems to be well written in terms of the paper composition and content especially in proposed theoretical framework.\n\nHowever, there are some parts that need revision in this paper.\n\n1. The contribution of the paper should be clearly presented. \n2. In Figure 1, it is not clear and difficult to understand. It needs to be more explained.\n\nIt is likely to be a better paper if you revise these parts.",
                "Comment (1) Please add a figure of system architecture\nComment (2) Research existing frameworks for measuring the degree of decentralization and tabulate the differences, advantages, and limitations of the proposed structure.",
                "- It is difficult to understand why it is compared to CEX to explain the Web3 financial exchange. It is necessary to redefine the comparison target. \n- Two minor corrections are commented out. \n1. \u201cTheratical\u201d should be fixed to \u201cTheoretical\u201d in the title of Section 2\n2. Remove duplicated \u201cthat\u201d in 2-B"
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 2.0,
                "Reference": 2.5,
                "Overall recommendation": 2.5,
                "Poster acceptance": 3.0
            }
        },
        "body": "I. INTRODUCTION\n\nScholars have studied blockchain smart contracts, how decentralized networks, and permissionless ledger systems operate in Web3 [1]. However, while a significant amount of time and resources has been spent investigating Web3 technology, there has not been sufficient research on how Web3 organizations adapt, change, and react to institutional pressures, or what role polycentrism may play in mitigating these pressures. We argue that this omission in the literature is significant and noteworthy for two reasons.\n\nFirst, Web3 organizations are built within institutionalized Web2 spaces. Typically, for example, to access a Web3 platform, a user will need a web browser such as Google Chrome or the Google search engine. This embeddedness within Web2 environments inherently subjects Web3 decentralization to forces of institutional centralization. Attributing partly to the nascency of Web3, research on the effect that Web2 has on Web3 organizational change remains unexplored.\n\nSecond, Web3 organizations are commonly configured to be decentralized and permissionless by distributing decision-making controls to nodes [2]. This decentralized distribution of control and decision- making between groups of actors fosters polycentrism, where the decision-making in each organizational network exists across multiple decision centres.\n\nWe, therefore, argue that analysing how Web3 organizations navigate institutional environments must consider the impact of polycentrism.\n\nAdditionally, because Web3 organizations are built on, and interact with, many blockchain systems, polycentrism is often nested. Ostrom (2005) defines nested spaces where \u201call rules are nested in another set of rules that define how the first set of rules can be changed\u201d [3]. AWeb3 organization may be highly decentralized and polycentric and reliant on Ethereum to operate, which is also decentralized and polycentric. In this way, the configuration of the Ethereum network act as a first-order set of rules and changing Ethereum\u2019s rules impact how subsequent sets of rules within Ethereum-based Web3 organization operate.\n\nWe have developed a theoretical model that focuses on the nuances of isomorphism and polycentrism in Web3 exchanges. AWeb3 exchange is a service provider that facilitates the trade of cryptocurrencies for other modes of value, including fiat money or other cryptocurrencies. The research demonstrated in this paper draws on archival data to engage in a brief, but illustrative comparative analysis of our model as applied to Web3 exchanges. We argue that our theoretical model can be applied to these case studies to answer three key research questions:\n\nRQ1: How does isomorphism condition the organizational hybridity of Web3 financial exchanges?\n\nRQ2: What is the impact of polycentrism on isomorphism and organizational hybridity rates in Web3 organizations?\n\nRQ3: What is the impact of nested polycentrism on isomorphism and organizational hybridity in Web3 organizations?\n\nII. THEORETICALFOUNDATION\n\nA. Institutionalism\n\nIn 1977, Meyer and Rowan suggested that organizations were subjected, and conformed, to a set of 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n\n\n\n\nsocietal pressures that arose from entrenched practices and structures [4]. In addition, Meyer and Rowan argued that organizations adopted these practices without considering whether they should adopt the norm in question. This homogenization process was coined as institutional isomorphism \u2013 which refers to the process by which heterogeneous organizations become similar over time due to institutional pressures. Tolbert and Zucker (1983) further developed institutional theory by pointing out that in a free market, organizations align themselves with institutional norms under the assumption that adopting normative practices will yield competitive advantages [5].\n\nDiMaggio and Powell (1983) argued that three primary mechanisms underpin isomorphism: coercive, mimetic, and normative [6]. These three mechanisms work to create recursive dynamics that \u201ctrap\u201d organizations. We can conceptualize this trap or cage as a process whereby: (1) institutional structures are created through a set of practices that are thought to deliver a competitive advantage; (2) the existence of these norms then constrain organizations within a given ecosystem; and (3) the norms are reproduced. In essence, institutional theory is predicated on the assumption that within a given organizational environment, there is a homeostatic baseline to which organizations will inevitably be drawn to conform [7].\n\nIn recent years, critics have argued that traditional institutional theory fails to account for competitive advantages sustained via deviations from the norm. New institutionalism addresses this critique by incorporating change dynamics [8]. For example, the notion that change is random, and thus, the competitive advantages sustained through deviations are exogenous to isomorphic pressures. Though this has left new institutional theorists unsatisfied, notably, in the field of emerging technologies where deviations from the norm and change are prevalent [9] [10]; the question of how new organizational forms sustain themselves over time remains unanswered [11].\n\nAnswering the growing unease around institutional theories' applicability in the 21 st century, Greenwood and colleagues (2014) called for a \u201crethinking\u201d of institutional theory [12]. They argue that it is only by beginning with the hypothesis that organizations may differ based on context, that we can subject institutional theory to falsification tests and establish the theory boundary conditions. We adopt a polycentric theoretical lens, subjecting institutional theory to falsification tests and establishing boundaries for how institutional theory may be applied to Web3 organizations.\n\nB. Organizational Hybridity\n\nOrganizational hybridity is \u201cthe combination of\n\nidentities, forms, logics, or other core elements that would conventionally not go together\u201d [13]. Organizational hybridity and the maintenance of multiple logics can fuel novelty [14] [15] and increase organizational legitimacy [16] [17] [18]. However, hybridity also generates significant challenges.\n\nConflicting logics can generate unsolvable internal conflicts [19]. For social enterprises, both internal and external conflicts can develop that threaten\n\norganizational survival [20]. In fact, Tracey and colleagues (2011) argue that where organizations do not adapt in response to conflict generated by hybridity, they risk failure [21]. Organizational hybridity may develop in Web3 organizations when the ethos of\n\ndecentralization come into conflict with profit- maximization interests of large shareholders [22].\n\nC. Polycentrism\n\nWhere an organization faces two or more isomorphic pressures, institutional duality can develop, forcing the organization to maintain legitimacy in multiple spaces concurrently [23]. A classic example occurs when a multinational corporation is forced to meet the expectations of its home country as well as the host country where a subsidiary is located [24]. The isomorphic pressure experienced at home often conflicts with the institutional settings of the host [25].\n\nPolycentrism develops in an organization when decision-making power emanates from multiple centres, each operating with limited autonomy. However, it is important to note that while multinational corporations can exhibit polycentrism, they are often monocentric in nature. A monocentric system is \u201ca single decision structure that has an ultimate monopoly over the legitimate exercise of coercive capabilities\u201d [26]. Centralized exchanges tend to exhibit monocentric, but with limited polycentric characteristics similar to Web2 corporations. Decentralized exchanges, in contrast, tend to exhibit polycentrism.\n\nPolycentrism becomes increasingly complex as hierarchies develop between polycentric decision nodes. Where one polycentric system relies on the proper functioning of a second polycentric system, we consider this system nested within one another [27]. Polycentrism in Web3 begins with permissionless blockchains that distribute control over nodes, becoming complex as layers of decentralization are stacked on top of one another. For example, Ethereum is a layer-1 blockchain; Polygon is a layer-2 blockchain built on top of Ethereum; Quickswap is an exchange built on Polygon, which interacts with various other protocols, each hosting its nested polycentric systems.\n\n\n\n\n\nIII. TOWARDSA WEB 3 THEORETICALFRAMEWORK\n\nWe suggest that isomorphism exerts pressure on Web3 organizations to centralize via (1) executive rule design; (2) regulation; and (3) ownership. We expect that these three isomorphic pressures lead to higher levels of centralization, and that this centralization generates organizational hybridity. Given that decentralization is fundamental to the Web3 ethos [28], we expect that the hybridity created via the conflicting logics of centralization and decentralization will significantly decrease firm survival over time. We conceptualize this framework in Fig. 1 below.\n\n\n\nFig. 1. Shows how isomorphism and multiplicty of decision centers exert forces of centralization and polycentricity. Consequently, the contradictions between the Web3 ethos of decentralization and profit maximization by means of centralziation deepens.\n\nWe further argue that polycentrism will negatively moderate the strength that isomorphic pressures exert on Web3 organizations, such that the more nested polycentric decision nodes are within an organization, the stronger the moderation and the higher the rate of organizational survival. We suggest that polycentrism can be measured via (1) distributed rule design; (2) autonomous decision-making layers; and (3) collective ecosystem goals.\n\nIV. CENTRALIZATION\n\nA. Executive Rule Design\n\nWe define executive rule design as the top-down incorporation of normative legacy rules and practices that are imported into Web3 organizations by organizational leadership. This management structure is common practice. We classify executive rule design as a normative isomorphic force, pressuring decentralized Web3 organizations to centralize.\n\nB. Regulation\n\nWe define regulation as the imposition of laws and policies on a Web3 organization that are not readily identifiable or certain but are enforceable. For example, the SEC guidance on whether a non-fungible token is a security or not remains remarkably ambiguous, allowing\n\nthe SEC to purport to have oversight over all non- fungible tokens until such a time that the SEC deems the token in question to not be a security [29]. We propose that the ambiguous nature of the SEC\u2019s guidance may be viewed as more coercive than one of regulatory certainty, because it encourages Web3 companies to mimic established \u201csafe\u201d practices.\n\nC. Ownership\n\nResearch indicates that higher levels of ownership concentration may mitigate the risk of bankruptcy [30] [31]. In the U.S., there is a tendency for share ownership to concentrate in the hands of a small number of holders [32]. We identify this trend of ownership concentration as a mimetic isomorphic force, exerting pressure on decentralized ownership to centralize.\n\nV. POLYCENTRICITY\n\nA. Distributed Rule Design\n\nIn opposition to centralized power structures within companies is what we define as distributed rule design, which functions similar to a holacracy. Van De Kemp (2014) defines holacracy as \u201ca governance framework for organizations which radically replaces some of the practices we have used to craft our organizations in the past century: (1) the top-down hierarchy and (2) the need for management. It promises a lean and adaptable organization, highly effective, distributed authority\u201d [33].\n\nB. Autonomous Decision-Making Layers\n\nAn autonomous decision-making layer is governed by a smart contract, ensuring that a pre-determined action that will result from a set of binary conditions. This layer operates irrespective of outside interference. Once an autonomous decision layer is deployed, it is impossible to be subjected to isomorphic forces.\n\nC. Collective Ecosystem Goals\n\nThe third polycentric mechanism we identify are\n\ncollective ecosystem goals. This can be the elimination of a negative externality that is in the interest of the common good [34]. Voshmgir argues that Web3 architecture inherently leverages a\n\n\u201ccollectively maintained universal state.\u201d Evidence of collective ecosystem goal can be found by analyzing the number of governance proposals that are voted on in a Web3 organization.\n\nVI. PRELIMINARY EVIDENCE\n\nOur model allows for data inputted to define the complexity of the conclusion drawn. For example, we may preliminarily examine RQ1 (How does isomorphism condition the evolution of Web3\n\n\n\n\n\nexchanges?) by limiting the data and analysis to ownership and whether there is a relationship between the level of centralization of ownership and exchange survival. The below two tables breakdown ownership concentration in decentralized and centralized exchanges. The data is current as of December 31, 2022 and sourced from Coinmarketcap .\n\nDecentralized Exchanges (DEXes)\n\nUni swap Maker DAO\n\nQuick Swap Aave Lid o Cur ve Avg\n\nTotal Addresses 364,8 11 500,16 4\n\n5,041 149, 480 25, 947 88,5 58 n/a\n\nTop 10 Holders 52.6 % 28.8% 98.1% 58.6 % 53.0 % 78.2 % 60.7 %\n\nTop 20 Holders 61.6 % 37.0% 98.5% 67.0 % 67.6 % 86.5 % 69.7 %\n\nTop 50 Holders 74.3 % 49.4% 98.8% 78.5 % 83.0 % 91.6 % 79.2 %\n\nTop 100 Holders 84.3 % 58.8% 98.9% 84.0 % 91.2 % 94.6 % 85.3 %\n\nData procured on December 31, 2022 from Coinmarketcap\n\nFig. 2. Total number of addresses and percentage of token supply the top wallets of each respective DEXes have ownership over\n\nCentralized Exchanges (CEXes)\n\nCelsius FTXVoyager Gemini Avg\n\nTotal Addresses 31,588 25,874 6,033 10,155 n/a\n\nTop 10 Holders 92.0% 94.3% 89.9% 96.3% 93.1%\n\nTop 20 Holders 95.8% 97.0% 96.4% 97.5% 96.7%\n\nTop 50 Holders 98.0% 98.8% 98.0% 98.7% 98.4%\n\nTop 100 Holders 98.7% 99.2% 98.5% 99.5% 99.0%\n\nData procured on December 31, 2022 from Coinmarketcap\n\nFig. 3. Total number of addresses and percentage of token supply the top wallets of each respective CEXes have ownership over\n\nThe \u201ctop 10 holders\u201d of tokens across the six CEXes in Fig. 3 have an average of 93.1% of the total token supply, compared to that 59.4% of DEXes in Fig. 2. On July 5, 2022 Voyager filed for bankruptcy, on July 14, 2022 Celsius declared bankruptcy, on November 11, 2022 FTX filed for bankruptcy. While Gemini has not filed for bankruptcy, given Gemini\n\nownership concentration level and its consistency with the CEXes that have gone bankrupts, we likewise draw caution to Gemini\u2019s long-term capacity to honour its creditors. The table above indicates a significant relationship between the degree of ownership centralization and the financial health of a Web3 exchange. We note that where an exchange has a higher percentage of top 10 holders, there is a higher probability of the exchange collapsing and declaring bankruptcy. Comparatively speaking, the DEXes analyzed above are not subject to noteworthy bankruptcy speculation. In fact, the DEX\u2019es appear healthy, for example, on October 13, 2022 Uniswap raised $165M at an all-time high valuation [35]. In fact, there has only been one large, DEX that has collapsed to-date: May 2022, Terra Luna. Interestingly, Terra Luna\u2019s collapse has been attributed due to \u201cinappropriate decentralised finance frameworks\u201d [36]. In the future research, we intend to input additional data into our theoretical model to test additional conditions where isomorphic forces negatively impact Web3 firm survival, and to assess the extent that decentralization can mitigate this negative impact. This may shed further light on why DEXes have higher survival rates than CEXes.\n\nVII. CONCLUSION\n\nRetrospectively, the contribution of this paper is the illustration of how isomorphic pressures and organizational hybridity manifest and affect the survivability of Web3 exchanges. While particular attention is paid to exchanges, the theoretical framework proposed can be generalizable across Web3 organizations. Testing each component of the model with data is beyond the scope of this paper, and the isomorphic pressures and polycentric mechanisms we identify are not intended to be exhaustive. However, in terms of ownership concentration, there seems to be a significant relationship between the degree of centralization and the health of exchanges. We expect that inputting further data into the model will answer questions like: Why is Quickswap able to remain financially healthy and retain a decentralized status in the face of a high ownership concentration?\n\nREFERENCES\n\n[1] Bernabe, J. B., Canovas, J. L., Hernandez-Ramos, J. L., Moreno, R. T., & Skarmeta, A. (2019). Privacy-preserving solutions for blockchain: Review and challenges. IEEEAccess, 7, 164908- 164940.\n\n[2] Momtaz, P. P. (2022). Some very simple economics of web3 and the metaverse. Available at SSRN.\n\n\n\n\n\n[3] Ostrom, E. (2005). Doing institutional analysis digging deeper than markets and hierarchies. In Handbook of new institutional economics (pp. 819-848). Springer, Boston, MA.\n\n[4] Meyer, J. W., & Rowan, B. (1977). Institutionalized organizations: Formal structure as myth and ceremony. American journal of sociology, 83(2), 340-363.\n\n[5] Tolbert, P. S., & Zucker, L. G. (1983). Institutional sources of change in the formal structure of organizations: The diffusion of civil service reform, 1880-1935. Administrative science quarterly, 22-39.\n\n[6] DiMaggio P. J. 1988 \u201cInterest and agency in institutional theory.\u201d In Zucker L. G. (ed.), Institutional Patterns and Organizations: Culture and Environment : 3\u201322. Cambridge, MA: Ballinger.\n\n[7] Weick, K. E. (1995). What theory is not, theorizing is. Administrative science quarterly, 40(3), 385-390.\n\n[8] Greenwood, Royston, & Hinnings, C. R. (1996). \u201cUnderstanding radical organizational change: bringing together the old and new institutionalism,\u201d Academy of Management Review, 21, 1022\u2013 1054.\n\n[9] Geenwood, R., Suddaby, R., & Hinings, C. R. (2002). Theorizing change: The role of professional associations in the transformation of institutionalized fields. Academy of management journal, 45(1), 58-80.\n\n[10] Suddaby, R., & Greenwood, R. (2001). Colonizing knowledge: Commodification as a dynamic of jurisdictional expansion in professional service firms. Human relations, 54(7), 933-953.\n\n[11] Tracey, P., Phillips, N., & Jarvis, O. (2011). Bridging institutional entrepreneurship and the creation of new organizational forms: A multilevel model. Organization science, 22(1), 60-80.\n\n[12] Kodeih F. & Greenwood R. (2014). \u201cResponding to institutional complexity: The role of identity.\u201d Organization Studies, 35: 7\u2013 39.\n\n[13] Smith, W. K., & Besharov, M. L. (2019). Bowing before dual gods: How structured flexibility sustains organizational hybridity. Administrative Science Quarterly, 64(1), 1-44.\n\n[14] DiMaggio P. J. 1988 \u201cInterest and agency in institutional theory.\u201d In Zucker L. G. (ed.), Institutional Patterns and Organizations: Culture and Environment: 3\u201322. Cambridge, MA: Ballinger.\n\n[15] Hsu G., Negro G., & Peretti F. (2012). \u201cHybrids in Hollywood: A study of the production and performance of genre-spanning films.\u201d Industrial and Corporate Change, 21: 1427\u20131450.\n\n[16] Smets M., Morris T., & Greenwood R. (2012). \u201cFrom practice to field: A multilevel model of practice-driven institutional change.\u201d Academy of Management Journal, 55, 877\u2013904.\n\n[17] Dunn M. B. & Jones C. (2010). \u201cInstitutional logics and institutional pluralism: The contestation of care and science logics in medical education, 1967\u20132005.\u201d Administrative Science Quarterly, 55: 114\u2013149.\n\n[18] Kodeih F. & Greenwood R. (2014). \u201cResponding to institutional complexity: The role of identity.\u201d Organization Studies , 35: 7\u2013 39.\n\n[19] Battilana J., & Dorado S. (2010). \u201cBuilding sustainable hybrid organizations: The case of commercial microfinance organizations.\u201d Academy of Management Journal, 53: 1419\u2013 1440.\n\n[20] Pache A. C., Santos F. M. (2013). \u201cInside the hybrid organization: Selective coupling as a response to competing\n\ninstitutional logics.\u201d Academy of Management Journal, 56, 972\u2013 1001.\n\n[21] Tracey, P., Phillips, N., & Jarvis, O. (2011). Bridging institutional entrepreneurship and the creation of new organizational forms: A multilevel model. Organization science, 22(1), 60-80.\n\n[22] Schreckinger, B. (n.d.). Legal fight over ownership of Web3 heats up. POLITICO. Retrieved December 31, 2022, from https://www.politico.com/news/2022/12/19/legal-fight-web3- ownership-crypto-00074629\n\n[23] Kostova, T., & Roth, K. (2002). Adoption of an organizational\n\npractice by subsidiaries of multinational corporations:\n\nInstitutional and relational effects. Academy of management journal , 45 (1), 215-233.\n\n[24] D\u00f6rrenb\u00e4cher, C., & Geppert, M. (2006). Micro-politics and\n\nconflicts in multinational corporations: Current debates, re- framing, and contributions of this special issue. Journal of International Management , 12 (3), 251-265.\n\n[25] Ferner, A., Almond, P., & Colling, T. (2005). Institutional theory and the cross-national transfer of employment policy: The case of \u2018workforce diversity\u2019in US multinationals. Journal of International Business Studies, 36(3), 304-321.\n\n[26] Ostrom, E. (1972). \u201cMetropolitan Reform: Propositions Derived\n\nfrom Two Traditions. Social Science Quarterly, 53, 474\u2013 493.\n\n[27] Sproule-Jones, M. (1993). Governments at Work: Canadian Par- liamentary Federalism and Its Public Policy Effects.\n\n[28] Chaffer, T. J., & Goldston, J. (2022). On the Existential Basis of\n\nSelf-Sovereign Identity and Soulbound Tokens: An Examination of the \u201cSelf\u201d in the Age of Web3. Journal of Strategic Innovation and Sustainability Vol, 17(3), 1.\n\n[29] Baker, H. G., & Wang, K. (2022, December 22). SEC v. LBRY,\n\nInc.: Federal Court finds LBRY's crypto token as a security. Lexology. Retrieved December 31, 2022, from\n\nhttps://www.lexology.com/library/detail.aspx?g=1dbe74c9- 4ae3-4a0f-bc45-cad756d1f079\n\n[30] Kim, J. (2019). Ownership concentration and institutional\n\nquality: Do they affect corporate bankruptcy risk?. Asia\u2010Pacific Journal of Financial Studies, 48(4), 531-560.\n\n[31] Kim, J. (2020). Determinants of Corporate Bankruptcy: Evidence\n\nfrom Chaebol and Non\u2010Chaebol Firms in Korea. Asian economic journal, 34(3), 275-300.\n\n[32] Holderness, C. G. (2009). The myth of diffuse ownership in the\n\nUnited States. The Review of Financial Studies, 22(4), 1377- 1408\n\n[33] Van De Kamp, P. (2014). Holacracy\u2013A radical approach to\n\norganizational design. Elements of the Software Development Process-Influences on Project Success and Failure. University of Amsterdam, 13-26.\n\n[34] Voshmgir, S. (2020). Token economy: How the Web3 reinvents\n\nthe internet (Vol. 2). Token Kitchen.\n\n[35] Singh, M. (2022, October 13). UNISWAP labs valued at $1.66\n\nbillion in $165 million new funding. TechCrunch. Retrieved December 31, 2022, from\n\nhttps://techcrunch.com/2022/10/13/uniswap-labs-raises-165- million-in-new-funding/\n\n[36] Briola, A., Vidal-Tom\u00e1s, D., Wang, Y., & Aste, T. (2023).\n\nAnatomy of a Stablecoin\u2019s failure: The Terra-Luna case. Finance Research Letters, 51, 103358.\n\n"
    },
    {
        "number": 1570880512,
        "title": "Staking Pools with Arbitrary Stake Distribution",
        "abstract": "On certain blockchains that use the proof-of-stake consensus mechanism, agents who validate transactions can set up pools that allow other agents to delegate their stake to earn higher returns. We study a version of the standard staking pool formation game in the presence of malicious agents, with an arbitrary distribution of stakes of honest agents. We establish existence and uniqueness of equilibria, how blockchain security can be maximized and how a leverage constraint impacts the functioning of the blockchain.",
        "review": {
            "strength": [
                "1. This paper explains the assumptions and proofs in detail.\n2. Corollaries are clearly explained with figures",
                "Using the Gaussian theorem, the author described how rewards are distributed in \"PoS.\" The model is mathematically elaborated.",
                "The paper proposes a game theoretical approach to analyze proof-of-stake (PoS) strategy for honest and malicious agents, where the stakes for both types of agents are modeled by a random variable bounded by a constant. The reward is defined by a formula that includes a delegated stakes function and a parameter lambda between 0 and 1. Using this setup, the authors introduce a game theoretical formulation for staking pool formation and define a threshold equilibrium where agents are indifferent to running a pool or delegating. The authors prove a theorem that establishes a lambda threshold that must be met for this equilibrium to be achieved, which depends on the number of honest and malicious agents. The authors also explore the lambda threshold for a uniform distribution of stakes.",
                "This paper shows a game of staking pool formation when stakes of honest agents are distributed arbitrarily\non some interval."
            ],
            "shortcoming": [
                "1. Analysis of security seems too obvious and impractical\n2. There are many notations but they are not well-organized\n3. The contents are too short",
                "The paper's analysis and literature review are inadequate. There is an appendix that has been added to the paper, but it could be smaller and the paper's length could be decreased.",
                "In the end, the authors provide a condensed presentation of their numerical results, with many parameter choices lacking justification. Overall, the paper leans heavily towards theoretical analysis and may not align entirely with the scope of the workshop.",
                "Real-world-based implementation or node distribution approachs is insufficient.\nLacks related works."
            ],
            "comment": [
                "1. It would be better to organize the notations\n2. Maximizing \u03bb for maximizing reward and security seems too obvious and make \u03bb=1 is impractical\n3. Excluding the Appendix, the contents are too short \n4. Consider to analyze lower bound on \u03bb not only in uniform stake distribution\n5. Consider to add more explanation about Fig. 1 and 2",
                "S. No. \tSection\t     Review\n1.\t\tSection 3\t     Write full form of \u201ccdf\u201d and \u201cpdf\u201d.\n2.\t\tSection 3\t     Define all symbols used like \u201cs,\u201d.\n3.\t\tSection 4      The Latin symbol \"G\" stands for game. Definition 1 has a different \"G.\" Are the two notably different?\n4.\t\tSection 4.A, Def:1 \tDefine r*(equation)\n5.\t\tReferences  Literature survey is in adequate, add some more references.",
                "The paper is well-written but could benefit from a few improvements. First, a table listing all the notations would enhance readability. Second, the authors could discuss the stake distribution more thoroughly, as it is an important factor that could affect the results. For example, heavy-tailed distributions might have different thresholds than the distributions analyzed by the authors. Third, it is not clear how one would know the number of malicious players beforehand. A potential application of this work from my point of interest would be a threshold for M rather than for lambda. Fourth, the authors introduce delegated stakes (d) as a function of s but use it as a constant throughout the paper. It would be helpful to clarify this inconsistency. Fifth, the authors could explain why they defined the split reward in the way they did. Finally, the justification for removing idle agents from the analysis is not entirely clear.",
                "Please add more related work and provide a table to show the differences between that research and this research."
            ],
            "score": {
                "Relevance": 2.4,
                "Content and originality": 2.6,
                "Reference": 2.2,
                "Overall recommendation": 2.6,
                "Poster acceptance": 3.2
            }
        },
        "body": "I. INTRODUCTION\n\nThe study of consensus protocols other than proof-of-work, the protocol used in Bitcoin [1], is a major field of research. Since the recent transition 1 of Ethereum from proof-of-work to proof-of-stake (PoS), research on PoS has become much more important. Most blockchains of the current generation, based on proof-of-stake, allow staking. With staking, agents interested in validating transactions are allowed to open a pool, so that others can delegate their stake to it for some time. Staking can be of financial interest to both\u2014pool owners and delegators. Pool owners may obtain larger fractions of the expected returns when they validate transactions and delegators who are not interested in validating transactions can obtain an additional income on their token holdings. On the reverse, their stakes are blocked and cannot be used for other purposes during the time of commitment. While staking is attractive from the financial side, it may be risky for blockchain security. In particular, malicious agents may run pools and may attract a large share of stakes by providing attractive financial returns to delegators. With a large share of stakes in the validation process, they could disrupt the blockchain, either by blocking validation of transactions or by trying to double-spend their tokens. In this paper we study a game of staking pool formation when stakes of honest agents are distributed arbitrarily on some interval. In particular, we present existence and uniqueness of equilibria. The paper is organized as follows. The next section briefly discusses related literature. Section III introduces the model. In Section IV, we analyze the staking pool formation game. Section V concludes. Proofs are in the appendix.\n\n*We would like to thank Akaki Mamageishvili and Hans Gersbach for helpful comments. 1 Also known as \u201cThe Merge\u201d.\n\nII. RELATED LITERATURE Staking pools are implemented in several blockchains like Cardano [2], Polkadot [3], Solana [4], Tezos [5] and Con- cordium [6]. They are studied in [7] and [8]. [7] use a mechanism design approach to study staking pools. [8] study a game-theoretic model where costs of honest agents come from a distribution and stakes are equal for all honest agents. This paper studies a variant of the game introduced in [8]. In particular, stakes come from an arbitrary distribution and we fix the cost of running a pool. An exhaustive discussion of related literature on staking pools can be found in [8].\n\nIII. MODEL There is a continuum of honest agents of measure H and a continuum of malicious agents of measure M < H . Honest agents incur cost 2 c > 0 from running a pool. Stakes of honest agents are modeled by a random variable with cdf G and pdf g with support on [0 , \u00af s ] for some \u00af s > 0 and let \u00b5 be the mean of the distribution. Each malicious agent has an initial stake of s M \u2208 [0 , \u00af s ] . If an honest agent with stake s runs a pool, s/he will receive d = d ( s ) delegated stakes where d is a function of s . There is a total reward R > 0 which is distributed evenly among all pools. The strategy set for honest agents consists of three strategies. Either run a pool, delegate, or stay idle. Hence, we can divide honest agents into three groups\u2014 those who run pools, those who delegate, and those who stay idle. We can write H = P + D + I , where P is the measure of honest agents who run pools, D is the measure of honest agents who delegate and I is the measure of honest agents who stay idle. Malicious agents always run pools, as they want to attract many delegators. 3\n\nIn total, we thus have a measure of P + M pools (or agents that run a pool). We assume that the total reward is split evenly across pools 4 . Hence, the reward per pool r is given by\n\nr = R\n\nP + M .\n\nLet \u03bb \u2208 [0 , 1] . For a pool owner with stake s , the pool reward r is split between the pool owner and the delegators as follows 5 :\n\n2 Costs are hardware costs and setting up a validator node, for instance. 3 If malicious agents choose to delegate, then there is a chance that their stake goes to some honest pool. In this case a malicious agent cannot be called \u201cmalicious\u201d anymore. 4 In the pools itself, the reward is distributed as follows: The pool owner receives an extra reward. The remaining reward is distributed to the pool owner and delegators according to the stakes. The alternative and today more common distribution is described in [9].\n\n5 The reward is split as follows: r \u0010 \u03bb s\n\ns + d + (1 \u2212 \u03bb s\n\ns + d )[ s\n\ns + d + d\n\ns + d ] \u0011 , where the underlined part goes to the pool owner with stake s . 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n\u2022 The pool owner receives\n\nr (1 + \u03bb ) s\n\ns + d \u2212 r\u03bb \u0012 s\n\ns + d\n\n\u0013 2 . (1)\n\n\u2022 The delegators with delegated stake d receive\n\nr \u0012 1 \u2212 \u03bb s\n\ns + d\n\n\u0013 d\n\ns + d . (2)\n\nThe per-unit reward to delegators is therefore r \u0010 1 \u2212 \u03bb s\n\ns + d \u0011 1\n\ns + d . Because of the way the rewards are split in a pool, honest agents with a large stake are incentivized to open a pool, as they receive an extra \u03bb share of reward compared to the case when they delegate.\n\nIV. STAKING POOL FORMATION GAME We consider the following game, denoted by G , which consists of four stages: Stage 0: The blockchain designer sets parameter \u03bb . Stage 1: Agents decide whether to form a staking pool or not (both honest and malicious agents). Stage 2: Agents who did not register for a staking pool decide whether to delegate their stake to some staking pool or to remain idle. Stage 3: The blockchain runs, validation takes place (or not), and rewards are distributed. From the reward distribution above, it is clear that delegation weakly dominates staying idle, as delegators can expect some non-zero reward. Hence, we write H = P + D .\n\nA. Equilibrium Concept We focus on perfect Bayesian equilibria in which all agents take optimal decisions whether to form pools or to delegate and in which they correctly expect the returns from these decisions. Furthermore, we focus on equilibria that are of threshold-type. We continue with the definition of threshold equilibria.\n\nDefinition 1 (Threshold Equilibrium) . A stake level s \u2217 is a threshold equilibrium if an agent with stake level s \u2217 is indifferent between running a pool and delegating. Agents with stake s < s \u2217 will delegate and agents with stake s > s \u2217 will run a pool.\n\nThe threshold equilibrium can be seen as the minimum requirement of stakes to open a pool 6 . Furthermore, in the threshold equilibrium, we have P = (1 \u2212 G ( s \u2217 )) H and D = G ( s \u2217 ) H . We write r \u2217 = R\n\n(1 \u2212 G ( s \u2217 )) H + M .\n\nB. Equilibrium Characterization In this section, we characterize equilibria. Such equilibria are characterized by the following two conditions: (i) An agents with threshold stake level s \u2217 has to be indif- ferent between forming a pool and delegating. (ii) Delegators are indifferent across all pool which receive delegators. That is, the return per stake for a delegator has to be the same across all pools who receive delegators.\n\n6 For Ethereum, the minimum stake requirement is 32 ETH. For the Concordium blockchain, it is 14000 CCD.\n\nC. Equilibrium Analysis\n\nIn this section, we start by stating our main existence and uniqueness result.\n\nTheorem 1. For c small enough 7 , there exists a unique threshold equilibrium to the game G , if and only if\n\n\u03bb > ( H + Ms M )2 c (1 \u2212 c\n\n\u00af r )\n\n\u00af r \u00af sM \u0012 1 + q\n\n1 \u2212 s M\n\n\u00af s 4 c (1 \u2212 c\n\n\u00af r )\n\n\u00af r\n\n\u0013 , (3)\n\nwhere \u00af r = R\n\nM 8 .\n\nTheorem 1 states that if the cost of running a pool is low enough and \u03bb is high enough, there exists a unique threshold equilibrium such that honest agents with stake lower than the threshold will delegate and all others will run a pool. Variable \u03bb is a design variable that the designer of a blockchain needs to set. If \u03bb is chosen to low, i.e. not satisfying the condition in the theorem, there is no threshold equilibrium. In order to have high security, we need many honest agents to run a pool. There is one major difference to the results in [8]. In their model, there are honest agents with zero cost of running a pool. In our model, there is a fixed non-zero cost for all honest agents. Hence, a solution to the indifference condition might not always exist. We can only guarantee a solution if the cost is low enough. The next section studies security of the blockchain.\n\nD. Maximal Security\n\nWe define security as the share of honest pool runners, that is, the more honest agents run a pool the higher the security. To attract pool running, rewards from being a pool runner must compensate the cost c .\n\nProposition 1. Security is maximized for \u03bb = 1 .\n\nProposition 1 states that if \u03bb = 1 , most of honest agents will run a pool, since higher \u03bb means higher reward for the pool owner.\n\nE. Leverage Constraint\n\nIn this section, we introduce a leverage constraint. First note that the leverage \u03c1 is given as follows: A pool running agent with stake s can receive d ( s ) delegated stakes where d ( s ) = \u03c1s, \u03c1 > 0 . For 0 \u2264 \u03bb \u2264 1 , the distribution of rewards as given in Equations (1) and (2) is now given by the following:\n\n\u2022 A pool owner with stake s receives\n\nr (1 + \u03bb ) 1\n\n\u03c1 + 1 \u2212 r\u03bb 1\n\n( \u03c1 + 1) 2 .\n\n\u2022 Delegators with delegated stake d receive\n\nr (1 \u2212 \u03bb 1\n\n\u03c1 + 1 ) \u03c1\n\n\u03c1 + 1 .\n\nThe per-unit amount to delegators is r (1 \u2212 \u03bb 1\n\n\u03c1 +1 ) 1\n\ns ( \u03c1 +1) .\n\n7 In the proof, we see what condition c has to satisfy. 8 Scaling H, M, R by some factor \u00b5 does not affect the lower bound (3).\n\nWe denote game G with the leverage constraint as G \u03c1 . Next, we state our result.\n\nTheorem 2. There exists a unique equilibrium to the game G \u03c1 if and only if \u03c1 < H\n\ns MM , c \u2264 r\n\n\u03c1 +1 and \u03bb = c\n\nr ( \u03c1 + 1) .\n\nV. CONCLUSION\n\nWe provided conditions for the existence and uniqueness of equilibria in the staking pool formation game. We further showed how security is maximized and what impact a leverage constraint can have. Our paper allows further research on how to optimally design rewards for a PoS blockchain. This is left for future research.\n\nAPPENDIX\n\nProof of Theorem 1. Our equilibrium analysis relies on two conditions. First, we have the indifference equation for an agent to be indifferent between running a pool and delegating. Second, we require that delegators have to be indifferent across all pools, that is, the per-unit amount for delegators needs to be constant across all pools. Suppose that an agent with stake s \u2217 is indifferent between running a pool and delegating. Then, we can state the two indifference conditions as follows: (i) For an agent with stake s \u2217 we have the indifference condition:\n\nE [ return of pool running ] \u2212 c = E [ return of delegation ] . (4) (ii) Delegators have to be indifferent across all pools:\n\nr \u2217 \u0012 1 \u2212 \u03bb s\n\ns + d\n\n\u0013 1\n\ns + d = K (5)\n\nfor some constant K . Condition (5) can be reformulated, so that we obtain an equation for d ( s ) . We write,\n\nd ( s ) = r \u2217\n\n2 K \u2212 s + r \u2217\n\n2 K\n\nr\n\n1 \u2212 s 4 K\u03bb\n\nr \u2217 . (6)\n\nAt this point, we still do not know what K has to be and hence how we should compute d ( s ) . For all s \u2208 [ s \u2217 , \u00af s ] and for all malicious pools, the d ( s ) should aggregate to the total measure of delegators D = G ( s \u2217 ) H . That is, we have the following condition:\n\nHZ \u00af s\n\ns \u2217 g ( s ) d ( s ) ds + d ( s M ) M = G ( s \u2217 ) H. (7)\n\nFor Equation (4), we have\n\nr \u2217 (1 + \u03bb ) s \u2217\n\ns \u2217 + d ( s \u2217 ) \u2212 r \u2217 \u03bb \u0012 s \u2217\n\ns \u2217 + d ( s \u2217 )\n\n\u0013 2 \u2212 c\n\n= r \u2217 \u0012 1 \u2212 \u03bb s \u2217\n\ns \u2217 + d ( s \u2217 )\n\n\u0013 1\n\ns \u2217 + d ( s \u2217 ) s \u2217 , (8)\n\nwhich can be simplified to\n\nr \u2217 \u03bb s \u2217\n\ns \u2217 + d ( s \u2217 ) \u2212 c = 0 . (9)\n\nWe can reformulate Equation (9), such that we have an expression for d ( s \u2217 ) , namely,\n\nd ( s \u2217 ) = r \u2217 \u03bbs \u2217\n\nc \u2212 s \u2217 . (10)\n\nSince Equation (5) holds for all s , it holds especially for s \u2217 , and we can write the following:\n\nr \u2217 \u0012 1 \u2212 \u03bb s \u2217\n\ns \u2217 + d ( s \u2217 )\n\n\u0013 1\n\ns \u2217 + d ( s \u2217 ) = K. (11)\n\nNow we make use of Equation (10) and replace it in Equation (11) to obtain K = \u0010 1 \u2212 c\n\nr \u2217\n\n\u0011 c\n\n\u03bbs \u2217 .\n\nNow we substitute K in Equation (6) by the latter expression and obtain\n\nd ( s ) = r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 ) \u2212 s + r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 )\n\nr\n\n1 \u2212 s\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217 .\n\n(12) Note that in this equation we do not have a dependence on K anymore. We see that a pool owner with stake s will receive d ( s ) delegates stakes. Having Equation (12), we can substitute d ( s ) in Equation (7) and solve for the threshold equilibrium s \u2217 , that is, we need to solve the following:\n\nHZ \u00af s\n\ns \u2217 g ( s ) d ( s ) ds + d ( s M ) M\n\n= HZ \u00af s\n\ns \u2217 g ( s )\n\n\uf8ee\n\n\uf8f0 r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 ) \u2212 s + r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 )\n\ns\n\n1 \u2212 s\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217\n\n\uf8f9\n\n\uf8fb ds\n\n+\n\n\uf8ee\n\n\uf8f0 r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 ) \u2212 s M + r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 )\n\ns\n\n1 \u2212 s M\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217\n\n\uf8f9\n\n\uf8fb M\n\n= H r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 ) (1 \u2212 G ( s \u2217 )) \u2212 HZ \u00af s\n\ns \u2217 g ( s ) sds\n\n+ H r \u2217 \u03bbs \u2217\n\n2 c (1 \u2212 c\n\nr \u2217 )\n\nZ \u00af s\n\ns \u2217 g ( s )\n\ns\n\n1 \u2212 s\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217 ds\n\n+ r \u2217 \u03bbs \u2217 M\n\n2 c (1 \u2212 c\n\nr \u2217 ) \u2212 Ms M + r \u2217 \u03bbs \u2217 M\n\n2 c (1 \u2212 c\n\nr \u2217 )\n\ns\n\n1 \u2212 s M\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217\n\n= G ( s \u2217 ) H.\n\nFor s \u2217 = 0 , the left-hand side (lhs) is \u2212 H\u00b5 \u2212 Ms M whereas the right-hand side (rhs) is 0 . To have a solution we need that for s \u2217 = \u00af s , the lhs has to be larger than the rhs. Since the expression on the lhs is continuous, there must be an equilibrium. Therefore, for s \u2217 = \u00af s , we have the condition\n\n\u03bb \u00af r \u00af sM\n\n2 c (1 \u2212 c\n\n\u00af r )\n\n\n\n1 +\n\nr\n\n1 \u2212 s M\n\n\u00af s 4 c (1 \u2212 c\n\n\u00af r )\n\n\u00af r\n\n!\n\n\u2212 Ms M > H,\n\nor equivalently,\n\n\u03bb > ( H + Ms M )2 c (1 \u2212 c\n\n\u00af r )\n\n\u00af r \u00af sM \u0012 1 + q\n\n1 \u2212 s M\n\n\u00af s 4 c (1 \u2212 c\n\n\u00af r )\n\n\u00af r\n\n\u0013 , (13)\n\nwhere \u00af r = R\n\nM is the reward per pool if there are no honest pools (i.e. s \u2217 = \u00af s ). To ensure that we have a solution of the equilibrium equation, the terms in the square roots in the\n\nequilibrium condition need to be non-negative, that is, we have the following condition on c :\n\n1 \u2212 \u00af s\n\ns \u2217 4 c (1 \u2212 c\n\nr \u2217 )\n\nr \u2217 \u2265 0 ,\n\nor equivalently,\n\nr \u2217 c \u2212 c 2 \u2264 s \u2217 r \u2217 2\n\n4\u00af s .\n\nTo establish uniqueness, suppose that \u03bb satisfies Equation (13). As shown above, if we focus on threshold equilibria, there exists a unique equilibrium characterized with the stake level s \u2217 . Suppose that an equilibrium exists which is not of the threshold type. Without loss of generality, assume two stake levels s 1 and s 2 , with s 2 > s 1 , and with the following property. An agent with stake s 1 will run a pool, while an agent with stake s 2 will delegate. Hence, for the first agent, it must hold that the expected return from running a pool is higher than the expected return from delegating, i.e.\n\nr \u2217 (1 + \u03bb ) s 1\n\ns 1 + d ( s 1 ) \u2212 r \u2217 \u03bb ( s 1\n\ns 1 + d ( s 1 ) ) 2 \u2212 c\n\n> r \u2217 (1 \u2212 \u03bb s 1\n\ns 1 + d ( s 1 ) ) s 1\n\ns 1 + d ( s 1 ) ,\n\nwhich can be simplified to,\n\nr \u2217 \u03bb s 1\n\ns 1 + d ( s 1 ) \u2212 c > 0 .\n\nSimilarly, for the second agent, we must have the opposite inequality, that is,\n\nr \u2217 \u03bb s 2\n\ns 2 + d ( s 2 ) \u2212 c < 0 .\n\nTogether, the two equations imply that s 1 d ( s 2 ) > s 2 d ( s 1 ) , which contradicts the assumption that s 2 > s 1 , since d ( s ) is decreasing in s .\n\nProof of Proposition 1. A pool running agent with stake s will receive reward\n\nr (1 + \u03bb ) s\n\ns + d ( s ) \u2212 r\u03bb ( s\n\ns + d ( s ) ) 2 ,\n\nwhere d ( s ) is given by Equation (12). We can calculate for which value of \u03bb this is maximized. First we note that the first-order condition is the following:\n\n0 = 1\n\n\u03bb 2 ( sr\n\nA \u2212 s 2 r\n\nA 2 ) ,\n\nwhere A is some constant term independent of \u03bb . We see immediately that this equation has no solution, that is, the reward is either increasing or decreasing. For \u03bb = 0 , the reward is rs\n\ns + d ( s ) , whereas for \u03bb = 1 , the reward is\n\n2 rs\n\ns + d ( s ) \u2212 r ( s\n\ns + d ( s ) ) 2 .\n\nClearly, for \u03bb = 1 , the reward is larger. Hence, the reward is increasing in \u03bb and so the maximum reward from pool running is achieved at \u03bb = 1 . With \u03bb = 1 , the reward is the highest- possible and the most honest agents will run pools, which increases the security.\n\nProof of Theorem 2. We proceed similarly to the proof of Theorem 1. Suppose that an agent with stake s \u2217 is indifferent between running a pool and delegating. Then, we have two conditions, as follows: (i) For an agent with stake s \u2217 we have the indifference condition\n\nE [ return of pool owner ] \u2212 c = E [ return of delegation ] .\n\n(ii) Stakes are delegated in such a way so that all pool are saturated with maximum capacity s ( \u03c1 + 1) . The d ( s ) for all s \u2208 [ s \u2217 , \u00af s ] should aggregate to D (= G ( s \u2217 ) H ) , i.e.,\n\nHZ \u00af s\n\ns \u2217 g ( s ) d ( s ) ds + d ( s M ) M = G ( s \u2217 ) H.\n\nThis equation can be reformulated as\n\n\u03c1 ( HZ \u00af s\n\ns \u2217 g ( s ) sds + s MM ) = G ( s \u2217 ) H.\n\nFor s \u2217 = 0 , the lhs is positive while the rhs is 0. To have an equilibrium, it is necessary that for s \u2217 = \u00af s , the rhs is larger than the lhs, which is\n\n\u03c1 < H\n\ns MM .\n\nThe indifference Equation (i) for an agent with stake s \u2217 is the following:\n\nr (1 + \u03bb ) 1\n\n\u03c1 + 1 \u2212 r\u03bb 1\n\n( \u03c1 + 1) 2 \u2212 c = r (1 \u2212 \u03bb 1\n\n\u03c1 + 1 ) 1\n\n\u03c1 + 1\n\nand can be simplified to r\u03bb \u2212 c ( \u03c1 + 1) = 0 , or equivalently, \u03bb ( \u03c1 ) = c\n\nr ( \u03c1 +1) . To ensure \u03bb \u2264 1 , we have the condition that c \u2264 r\n\n\u03c1 +1 .\n\nREFERENCES\n\n[1] S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d https://bitcoin.org/bitcoin.pdf , 03 2008. [2] A. Kiayias, A. Russell, B. David, and R. Oliynykov, \u201cOuroboros: A provably secure proof-of-stake blockchain protocol,\u201d in Advances in Cryptology - CRYPTO 2017 - 37th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 20-24, 2017, Proceedings, Part I (J. Katz and H. Shacham, eds.), vol. 10401 of Lecture Notes in Computer Science , pp. 357\u2013388, Springer, 2017. [3] G. Wood, \u201cPolkadot: Vision for a heterogeneous multi-chain framework,\u201d https://polkadot.network/PolkaDotPaper.pdf , 2016. [4] A. Yakovenko, \u201cSolana: A new architecture for a high performance blockchain v0.8.13,\u201d https://solana.com/solana-whitepaper.pdf , 2017. [5] L. Goodman, \u201cTezos \u2013 Self-amending crypto-ledger,\u201d White Paper , 2014. [6] I. Damg\u02daard, H. Gersbach, U. Maurer, J. B. Nielsen, C. Orlandi, and T. P. Pedersen, \u201cConcordium white paper,\u201d 2020. [7] L. Br\u00a8unjes, A. Kiayias, E. Koutsoupias, and A.-P. Stouka, \u201cReward sharing schemes for stake pools,\u201d in 2020 IEEEEuropean Symposium on Security and Privacy (EuroS&P), Virtual Event, September 7-11, 2020 , pp. 256\u2013275, 2020. [8] H. Gersbach, A. Mamageishvili, and M. Schneider, \u201cStaking pools on blockchains,\u201d ArXiv , vol. 2203.05838, 2022. [9] H. Gersbach, A. Mamageishvili, and M. Schneider, \u201cA market design approach to staking on blockchains,\u201d mimeo , 2023."
    },
    {
        "number": 1570880524,
        "title": "Unlocking the Potential of Time Tokenization for Inclusive Decentralized Marketplaces and Services",
        "abstract": "We propose a modern approach for time tokenization in Decentralized Finance (DeFi), where investors can create value from time simply by waiting for its passage, as the concept suggests, and exchange it on an open first-tier market. Our solution, the TIME token, is an Ethereum Request for Comments 20 (ERC-20) token developed using Solidity. With the potential to become a well-established asset, it can improve the current state of DeFi and time tokenization in terms of system design.",
        "review": {
            "strength": [
                "- It is clear how this work is different from previous work related to time tokenization.\n- Nice presentation to easily understand the work.",
                "This paper proposes an approach to tokenize time.",
                "I was unable to determine the strengths of the paper.",
                "The idea of time tokenization shows promise in enhancing the efficiency of blockchain systems by reducing the computational load required for mining. By incorporating time as a critical factor in the tokenization process, it may be possible to optimize blockchain transactions and improve the overall performance of the system."
            ],
            "shortcoming": [
                "- It is not clear how TIME token maintains its value while it is being minted infinitely.\n- Equations for fee calculation are not clear. How are equation (3) and (4) derived?",
                "Tokenisation of time is not a new idea as discussed in the relation work. The paper lacks technical details to describe the actual design of the TIME token.",
                "- The problem that the paper was trying to solve is not clear\n- The algorithm of the smart contract is not clear. The authors should provide pseudocode. \n- The evaluation page [citation 7] was not accessible\n- The use cases of TIME token are not clear\n- Need proper security and economic analysis of the token",
                "The abstract does not effectively communicate the purpose of the research, which makes it difficult for readers to understand the significance of the work. Additionally, the literature review is not well-organized, and it is unclear which sources are being cited for each aspect of the research.\nFurthermore, the research presented in the paper is not particularly novel, as it does not offer a significant advancement in the field. The references used in the paper are also lacking, as basic online links are not considered best practice for scholarly research.\nThe paper doesn't have a diagram of the model, especially when it comes to time tokenization, which would help explain how the model works. Also, the model is not explained well enough, which could make it hard for other people to do the same research.\n\nThe selection of the bi block is also unclear, and should be more thoroughly explained to readers. Overall, the paper does not read like a research article, and there is room for improvement in its structure, organization, and content."
            ],
            "comment": [
                "- How does TIME token maintain its value? Users only pay an activation fee once but the system mints TIME infinitely as time passed.\n- In equation (3) and (4), why do fees are increased as expected time to drain the native crypto\u2019s balance of LP decreases? This may disturb to attract new users.\n- There is no future work",
                "The technical detail (architecture, mechanism) is not sufficiently/clearly presented. It is difficult to understand how the tokenization scheme is implemented and the novelty compared with the existing projects on time tokenization. \n\nFor example: \nWhat is the meaning of \u201cenable an address to generate TIME\u201d?\nHow is this enabling implemented in the smart contract? \nHow are the different smart contracts designed, e.g. mining(), fee(), wining()?\nHow can the TIME token be used in an application? (besides the very high level introduction of the usage in the Use Case section) It would be better to give more specific descriptions of the advantages of tokenising time and usage scenarios.",
                "- The problem that the paper was trying to solve is not clear\n- The algorithm of the smart contract is not clear. The authors should provide pseudocode. \n- The evaluation page [citation 7] was not accessible\n- The use cases of TIME token are not clear\n- Need proper security and economic analysis of the token",
                "After reviewing the paper, there are several areas where improvements can be made.\n\nFirstly, the abstract is not properly drafted and does not fulfill its purpose of providing a brief summary of the paper's key findings and contributions. It should be revised to accurately reflect the content of the paper.\n\nSecondly, the literature survey is not properly classified.\n\nThirdly, the work presented in the paper is not particularly novel.\n\nFourthly, the reference section could be improved by avoiding the use of basic online links, which is not considered a good practice in academic writing.\n\nFifthly, a diagram should be added to explain the model's time tokenization process.\n\nSixthly, the model itself is not adequately explained, and further details should be provided to help readers understand its implementation.\n\nOverall, the paper does not appear to be structured like a research article, and there is room for improvement in several areas."
            ],
            "score": {
                "Relevance": 2.5,
                "Content and originality": 1.3,
                "Reference": 2.3,
                "Overall recommendation": 1.3,
                "Poster acceptance": 2.3
            }
        },
        "body": "I. INTRODUCTION\n\nTime is a valuable resource, both for its use and manage- ment. It is essential for calculating interest, releasing assets, setting conditions, pricing, and more. In situations where all other resources are abundant, time presents itself as a constraint that can be challenging to manage. We propose a practical approach to time tokenization that allows anyone to handle time in a tangible form. The idea of turning time into a tokenized asset is not new, but we noticed that existing approaches lack proper mechanisms for value creation while maintaining public openness. Our approach recognizes that the tokenized time, like any other asset, should be accessible to anyone while also being scarce and limited to prevent excessive inflation and preserve its core value. Why tokenize time? It is a valid question, and one we aim to answer. But, we can pose another: why not? Time is a finite resource like any other, and the primary function of a token is to capture the economic value within an ecosystem [1]. So, why not capture the value of time in a tokenized form? In a world where everything can and is being tokenized [2]\u2013[6], proposing an open, fair, egalitarian, and accessible environment for the pricing, trading, and offering of time by any interested party is something that aligns with today\u2019s expectations. The real challenge lies in turning time into a tangible asset. Everyone receives and consumes the same amount of time every day, so how can it be treated and measured like cash or cryptocurrency? Can time really be considered money? These are the questions we aim to answer with our approach to time tokenization. We present TIME, a smart contract developed to manage time as an Ethereum Request for Comments 20 (ERC-20) token. This smart contract regulates asset production and con- trols stakeholder engagement in a sustainable manner, and also offers a decentralized public market for the token. The code is simple, open, independent, not upgradeable (immutable), and\n\nlacks an administrator, ensuring that all parties interact equally with the contract. This paper only covers the functions of the smart contract. A preliminary evaluation of the proposal can be conducted through a Web3 page we have developed, although it lacks some minor features. The test smart contract has been de- ployed on Polygon Mumbai and Binance Smart Chain Testnet networks, but the source code is not publicly accessible at this time. The evaluation page can be accessed at [7]. At the end of this paper, we delve further into the potential of time tokenization by outlining several practical use cases that can be explored by any tokenized time solution. Our aim is to not only present the community with a foundational framework for managing time in a tokenized manner, but also to offer an improved understanding of the concept and its potential applications. Whether viewed as a starting point for further research and development, or as an innovative solution in its own right, our hope is that our TIME token will spark new ideas and creative solutions for the management and utilization of time in the Decentralized Finance (DeFi) space.\n\nII. LITERATURE REVIEW\n\nTo the best of our knowledge, our approach to time tok- enization is unique in the current literature. However, we have identified a few similar proposals that are worth mentioning. The authors of [8] have developed a platform known as ChronoBank that connects freelancers and employers through blockchain technology. To enter the system, users must first purchase governance tokens (TIME) from a private crowdsale. Once inside the system, they can create and trade Labor Hour Tokens (LHT), which serve as the means of exchange for labor hours. While the proposal offers an innovative solution for the labor market, it restricts access to the system only to those who have acquired the governance tokens and limits its use case to just the exchange of labor hours. In [9] the authors propose the creation of value from time tokenization using the Income Per Minute (IPM) token. The Timers application is designed to manage user interactions and system evolution. The total supply of IPM tokens gets started with a fixed value and capped at an initial crowdsale. The remaining tokens, representing time earnings, are created through the Token Verification Minting (TVM) system, which serves as proof of value creation. The TVM is divided into two stages: in the first stage, tokens are proportionally distributed to holders on a daily basis, similar to a staking system, but only minted when claimed based on the number of new users entering and setting up the Timers app. In the second stage,\n\nIPM tokens are minted based on user engagement on the platform, including social activities and similar. Despite the interesting economic model, it is still dependent on the initial crowdsale and the value of time to be created is initially shared based on the size of the initial IPM acquisition, which is not fair from the perspective of equal access to time for all. Additionally, it relies on social engagement from the application.\n\nIII. PROPOSED SYSTEM\n\nWe propose an Ethereum Virtual Machine (EVM) based smart contract, written in Solidity and compliant with the ERC-20 standard. It aims to tokenize time, expressed in terms of numbered blocks, and provide a market for its exchange on the network. Each token unit represents a registered block, counted from a starting point by an enabled address, and can be traded freely within the contract by any interested party. Any address can be enabled as a block counter, provided that the necessary fees for the protocol are paid. This section is structured as follows: we first describe the tokenomics, which outlines the operation of the smart contract and how it can be interacted with. Next, we present our open and decentralized alternative local market, designed to facilitate the exchange of tokens and the functions that can be called by investors. Finally, we demonstrate how the fees for token production are dynamically calculated.\n\nA. TIMEToken Features\n\nThe TIME token operates as follows: ( i ) to participate in the system, a user activates his Externally Owned Account (EOA) address or the address of a smart contract deployed for the same purpose to start producing or \u201cmining\u201d TIME units; ( ii ) once an address is activated, it has the ability to mint TIME for itself based on the number of registered blocks that have passed since activation or since the last time the mint function was called. To enable an address to generate TIME, the user must pay a fee to the smart contract by calling either the enableMining() or enableMiningWithTimeToken() function. The first function requires payment with the underlying network\u2019s native cryptocurrency, while the second requires payment only with TIME token units. The exact fee amount can be determined in advance by querying the contract. The fees collected will be used as initial liquidity to establish the proposed market, which consists of the TIME token and the underlying network\u2019s native cryptocurrency (e.g., TIME/ETH, TIME/MATIC). The activation fee for an address in the contract serves two crucial purposes: first, to prevent inflation of the total supply by deterring any potential abuse of the system through automated scripts that could generate an excessive amount of the token. By requiring a fee, the scarcity of the token is maintained, as only participants who are willing to pay the fee will be able to generate it; and second, to provide initial\n\nliquidity for trading by using the fees collected to create a residual market for the token to be exchanged with. Suppose someone wants to start producing TIME for an address he controls. The first step is to call the fee() function from the desired address ( msg.sender ) to determine the cost of registering the enableMining() function. A similar pro- cess is used with the enableMiningWithTimeToken() function, where the feeInTime() function is called instead. It is important to note that fees paid only with TIME tokens are burned and do not re-enter the market, whereas fees paid with the native cryptocurrency are added to the internal pool. Once the address has been enabled, the participant can call the mining() function to start producing TIME tokens. As an example, if the address was enabled at block number 11000 and the mining() function was called and registered at block number 12000 by the same address, the smart contract will mint 1000 TIME for that msg.sender address. This amount is calculated based on the difference of elapsed blocks between activation and call. The process is illustrated in Figure 1. Additionally, the same function also mints a supplementary amount of TIME, equivalent to 1% of the newly created tokens (10 TIME in this case), for the block.coinbase address, which is responsible for registering both the transaction and block. This incentivizes other participants to join the ecosys- tem and ensures its sustainability in the long term.\n\nFig. 1. Illustration of the TIMEMining Process across Registered Blocks.\n\nAfter enabling an address, the participant can continuously mint TIME tokens at any block, with no call limitations, as the minted amount will always correspond to the number of blocks passed since the last mining() function call, neither more nor less. This means that an individual has the same \u201cmining power\u201d as an automated script with the same purpose. All participants must wait for a set number of blocks to be registered before they can produce a desired amount of TIME. It is important to note that the TIME smart contract does not take into account the timestamp information (from the block.timestamp global variable) as block miners can manipulate this information for their own benefit, potentially earning more tokens [10]. Finally, we emphasize that the block count system is exclu- sively assigned and maintained per address on the network. This means that each address operates independently with their own block count information, without any interference from other addresses. As a result, each participant with an enabled address essentially has their own personal time, which can be tokenized and used for trading purposes within the network.\n\nThis allows for a fair and equal opportunity for all participants to generate TIME tokens and participate in the network.\n\nB. Alternative Decentralized Market\n\nThe TIME token smart contract also offers basic functions of an Automatic Market Maker (AMM), acting as a simple Decentralized Exchange (DEX) for the TIME/ETH trading pair. If the smart contract is deployed on another blockchain, the trading pair would be TIME/native cryptocurrency of that network. Investors seeking to purchase TIME can do so by sending the native cryptocurrency directly to the contract address or by calling the saveTime() { value: ethAmount } function and specifying the desired ethAmount . On the other hand, investors who already own TIME can exchange it for native cryptocurrency by calling the spendTime(timeAmount) function or by sending TIME tokens to the contract address and specifying the desired timeAmount . The exchange rate is calculated automatically using the same Constant Function Market Maker logic as Uniswap V2: x \u00b7 y = k [11]. Additionally, the current market rate can be easily obtained by calling either the swapPriceNative(amountNative) or swapPriceTime(amountTime) function. The former provides the rate in terms of the underlying network\u2019s native cryptocurrency, while the latter gives the rate in terms of TIME tokens. Our contract runs the AMM as a business, by featuring a 2% fee on each swap transaction that is split into four equal parts. The first part is added to the local Liquidity Pool (LP) to foment growth as more transactions occur, the second part goes to the development team\u2019s static address, the third part is transferred to the miner/validator responsible for registering the transaction, and the fourth part is distributed proportionally among all TIME token holders, fostering community engage- ment and incentivizing all participants. It is important to note that if the network does not provide a block.coinbase address, the third part of the fee will go to the development team. Token holders can claim their share of the fees by calling the withdrawShare() function. The fourth portion of fees is exclusively for TIME token holders in native cryptocurrency. TIME-paid fees for this portion are burned, not shared with the public. Initially, the local AMMLP is established with TIME tokens and a fixed amount of native cryptocurrency from the fee paid when the first address is enabled. The goal of this internal LP is to provide liquidity for the contract from the start. To keep the local LP growing, we have also added two dona- tion functions, donateEth() { value: ethAmount } and donateTime(timeAmount) , where anyone can donate native cryptocurrency or TIME tokens to the project without receiving anything in return.\n\nC. Dynamic Fee Calculation\n\nOur approach to onboarding new stakeholders is conserva- tive. Entry into the system is contingent upon payment of a fee,\n\nwhich must be set at a value that balances the need to prevent rapid inflation of the economy and the desire to attract users. Our fee structure is as follows:\n\nt i = T\n\nb i \u2212 b 0 (1)\n\nb 0 is the block number of the first block registered when the TIME token smart contract was deployed. b i is the block number at the i -th selected timeframe , and T is the total number of TIME tokens mined. The average mining rate of TIME tokens, represented by t i , is calculated to determine the speed at which they are being produced (TIME per block). As mentioned at the end of the section III-B, the system creates an internal LP with some initial given amount of TIME. We define TLP as the number of TIME tokens exclusively belonging to the internal LP of the contract, and NLP as the native cryptocurrency balance of the LP. These tokens and funds are used exclusively for the purpose of facilitating trades on the decentralized exchange within the smart contract. Thus, our objective is to prevent the depletion of NLP . To achieve this, we have established a metric that calculates the number of blocks b LP required to exhaust NLP , taking into account the current value of the average mining rate of TIME tokens, t i , and using the proper unit conversion factor, c () .\n\nb LP = c ( NLP )\n\nt i (2)\n\nWith b LP representing the estimated number of blocks required ( expected time ) to drain the LP, we can determine a fair fee value. By setting a basic reference value for the initial fee, called FT for TIME tokens and FN for native cryptocurrency, we establish a waiting period for investors to activate a new address. The fee functions, fee() f N and feeInTime() f T are calculated as follows:\n\nf N = ( FN \u00b7 FT )\n\nb LP (3)\n\nf T = FT 2\n\nb LP (4)\n\nAs a result, the fees are dynamically linked to the speed of token production, meaning that if there is an increase in the number of addresses minting TIME tokens, it will become more costly to onboard new addresses, and vice versa. Additionally, the fee values continue to evolve even if there is no token production.\n\nIV. USE CASES\n\nIn this section, we outline the potential applications of the TIME token or any other tokenized time solutions proposed in the DeFi space. The following list is not exhaustive, but rather serves to highlight some of the key use cases:\n\n\u2022 Time as a financially significant metric: the notion that \u201ctime is money\u201d is more tangible than ever as people can now use time as a unit of measurement with real economic and financial impact.\n\n\u2022 Tokenized Time-based Markets: the tokenization of time allows for its proper exchange and utilization as a valu- able metric in a decentralized environment. This opens up new possibilities for time-based markets. We provide some examples next.\n\n\u2022 Labor Hour Markets: the negotiation of terms between workers and employers can be based on labor hours calculated in TIME tokens. It is crucial to properly convert TIME into an understandable unit, considering it is measured in blocks, to accurately reflect the time spent working.\n\n\u2022 Streamlining of Receivables and Payment of Dues: tok- enized time presents an opportunity to revolutionize the way we approach receivables and payment of arrears. Whether you are eager to receive rewards from a staking contract or you have taken a loan with a deferred payment date, you can now advance or settle the agreement by utilizing a portion of your TIME tokens. This eliminates the need to wait for the predetermined conditions or assets to be released after the agreement has been signed. Tokenized time opens up new possibilities for managing and optimizing agreements, especially when it comes to the anticipation or settlement of receivables and payment of debts. By using TIME tokens, parties can expedite the release of assets or meet future conditions in advance, as they can be generated through waiting. This allows for greater flexibility and control in the fulfillment of contractual obligations, as opposed to simply waiting for conditions to be met after an agreement is signed.\n\n\u2022 Time-Backed Assets and Derivatives: by leveraging the concept of tokenized time, DeFi platforms, both central- ized and decentralized, have the potential to create sta- blecoins and derivatives collateralized by time, opening up new opportunities for growth and innovation in the financial sector.\n\n\u2022 Universal Basic Income (UBI) through Tokenized Time: The idea that everyone has time could pave the way for a UBI based on tokenized time. With enough market demand and sufficient liquidity, it becomes possible to create a UBI through the mining of TIME tokens. This innovative approach to basic income could bring a new level of financial stability and security to individuals and communities.\n\n\u2022 Utility token: even if it has a low market value, it can still be leveraged for a variety of utility purposes. From providing credit to serving as a currency for reward or loyalty programs, TIME tokens can have multiple applications across various platforms.\n\nOur proposal of tokenizing time presents a vast array of possibilities for implementation beyond the examples listed. With the emergence of a financially significant time metric, we envision new and innovative use cases that have yet to be explored. The potential of a time tokenization system is immense, and its widespread use in a digitized society holds exciting implications for the future.\n\nV. CONCLUSION\n\nIn conclusion, our proposal for time tokenization has the potential to revolutionize the way we view and manage time as a valuable asset in the market. With a wide range of potential use cases, from labor hour markets to universal basic income and beyond, tokenized time has the potential to greatly impact and improve many aspects of our increasingly digitized society. As a finite and irreplaceable resource, properly tok- enizing time has the potential to greatly increase its utility and value, providing new and exciting opportunities for individuals and organizations alike. With the growth and acceptance of decentralized finance, we believe that time tokens have the potential to play a significant role in shaping the financial future. By fully realizing the potential of tokenized time, we can unlock new levels of efficiency and effectiveness, transforming time from a mere commodity into a highly coveted asset.\n\nREFERENCES\n\n[1] L. J. Tan, \u201cEconomics and Math of Token Engineering and DeFi: Fundamentals of Token Economics,\u201d Economics Design , 2020.\n\n[2] M. Zheng and P. Sandner, \u201cAsset Tokenization of Real Estate in Europe,\u201d in Blockchains and the Token Economy . Springer, 2022, pp. 179\u2013211.\n\n[3] R. Heines, C. Dick, C. Pohle, and R. Jung, \u201cThe Tokenization of Everything: Towards a Framework for Understanding the Potentials of Tokenized Assets,\u201d in PACIS , 2021, p. 40.\n\n[4] J. Roth, F. Sch\u00a8ar, and A. Sch\u00a8opfer, \u201cThe Tokenization of Assets: Using Blockchains for Equity Crowdfunding,\u201d in Theories of Change . Springer, 2021, pp. 329\u2013350.\n\n[5] \u201cTokenization of Everything is a Matter of Time,\u201d 2021. [Online]. Available: https://eblockchainconvention.com/tokenization-of- everything-is-a-matter-of-time\n\n[6] G. Sazandrishvili, \u201cAsset Tokenization in Plain English,\u201d Journal of Corporate Accounting & Finance , vol. 31, no. 2, pp. 68\u201373, 2020.\n\n[7] \u201cTIMEToken - Web3 Platform,\u201d 2023. [Online]. Available: https://cutt.ly/994rgb3\n\n[8] \u201cChronoBank - Revolutionary Platform for Crypto Assets Management (Whitepaper),\u201d 2017. [On- line]. Available: https://files.chrono.tech/uploads/files/Chronobank WP- yjqutik07g1fcl.pdf\n\n[9] \u201cTIMERS - Transforming Human Time Into Real Value (Whitepaper),\u201d 2019. [Online]. Available: https://timers.network/synopsis\n\n[10] A. Mense and M. Flatscher, \u201cSecurity Vulnerabilities in Ethereum Smart Contracts,\u201d in Proceedings of the 20th International Conference on Information Integration and Web-based Applications & Services , 2018, pp. 375\u2013380.\n\n[11] H. Adams, N. Zinsmeister, and D. Robinson, \u201cUniswap v2 Core (Whitepaper),\u201d 2020. [Online]. Available: https://uniswap.org/whitepaper.pdf"
    },
    {
        "number": 1570880692,
        "title": "Hephaistos: A Management System for Massive Order Book Data from Multiple Centralized Crypto Exchanges with an Internal Unified Order Book",
        "abstract": "Offers to buy and sell cryptocurrencies on exchanges are collected in an order book as pairs of amount and price provided with a timestamp.\nContrary to tick data, which only reflects the last transaction price on an exchange, the order book reflects the market's actual price information and the available volume.\nUntil now, no system has been presented that can capture many different order books across several markets.\nThis paper presents Hephaistos, a system for processing, harmonizing, and storing massive spot order book data from 22 centralized crypto exchanges and 55 currency pairs.\nAfter collecting the data, Hephaistos aggregates several order books in a so-called Unified Order Book, which is the foundation for a Smart Order Routing algorithm.\nAs a result an order is splitted across several exchanges, which results in a better execution price.\nAs component of a high-frequency trading system, Hephaistos captures 32 % of the total daily spot trading volume.\nWe provide examples with data from two exchanges that show that the Smart Order Routing algorithm significantly reduces the slippage.",
        "review": {
            "strength": [
                "- This paper presents Hephaistos, a system for processing and storing massive order book data from various centralized crypto exchanges and 55 currency pairs.\nLack of recent related works.\\",
                "The article is dedicated to the model of an aggregated orderbook from centralized Crypto Exchanges (CEX), as well as the possible implementation of the Smart Order Routing algorithm and a system for sending orders to multiple orderbook CEX to achieve better order execution prices through aggregated liquidity.",
                "Like the authors claim, it looks like the first of its kinds (at lease publicly known): A order book collection system for multiple cryptocurrency exchanges (big data for coin order book). \n\nHowever, I do aware of HFT firms do this for backtesting and etc (privately).",
                "In this paper, we developed Hephaistos based on Apache Kafka to process, harmonize and store large amount of spot order data. Hephaistos collected 22 cryptocurrency exchanges and 55 currency pairs, and using the collected data and the Smart Order Routing Algorithm, produced experimental results that reduced slippage."
            ],
            "shortcoming": [
                "- Lack of recent related works. \n- Detailed future work should be presented.\n- The proposed scheme is similar to the CEX aggregator. In order for the paper to have high novelty, it is necessary to add a reference to the existing CEX aggregator and analyze the service. Additionally, it is necessary to emphasize how the framework presented in this paper differs from existing services.",
                "The topic is relatively new for the crypto markets, but the concept of aggregating liquidity and building an aggregated orderbook for a single asset from different exchanges is well researched for traditional financial markets. For example, the American stock market is fragmented across more than 15 trading venues, and the task of placing a large order optimally to be as close as possible to the National Bid and Offer Price (NBBO) is studied by institutional players as well as retail traders. Examples of implementing the construction of a combined order book both in real-time and in historical mode can be seen in Bookmap.com, which is a standalone retail service but is also available to Charles Schwab broker clients.",
                "Collecting a large volume of order book is fairly reasonable for starter. I am not quite sure the validity of unified order book at this point. The massive order book data itself has a good contribution. \n\nIf it's operational, it would be more convincing to release some samples of the collected order book (not everything, even for a little bit).\n\nWriting to DB for streaming/high-frequency updates is not a desirable approach in real-time algorithmic trading or even for backtesting. However, I do understand that the magnitude of dataset left the authors no other choice. \n\nThe use of python should be a concern for latency issue.",
                "The results presented as contributions are incomplete.\n  - It was applied to 32% of the total daily spot trading volume (22 exchanges and 55 currency pairs), but there are no experimental results (In the experimental results, there are only 3 exchanges and bitcoin data.) to verify this.\n  - It is said that a detailed explanation of the implementation was given, but reliability is low because there is no explanation of the collected data format and results of the process in progress."
            ],
            "comment": [
                "- In order for the paper to have high novelty, it is necessary to add a reference to the existing CEX aggregator and analyze the service. Additionally, it is necessary to emphasize how the framework presented in this paper differs from existing services. SwissBorg (https://join.swissborg.com/), LXC Terminal (https://www.lcx.com/terminal/) are examples. \n- Some grammar errors should be fixed.",
                "The constructed model is correct, and potential improvements could be focused on the following specific issues for crypto markets:\n* The lack of clear symbology and reference data for naming assets traded on CEX (manual mapping of symbols is required to build unified liquidity).\n* In the proposed architecture, it seems reasonable to use redundant connections to CEX due to the imperfection of websocket APIs and possible data loss. In production systems, connections to the Binance exchange, for example, usually use three independent connections with geo-redundancy and an additional module for obtaining a reference final orderbook feed to minimize possible data loss.\n* When building a trading strategy based on the proposed SOR algorithm, it is necessary to take into account that there is no centralized clearing in the current crypto market, which requires holding assets for trading on each of the platforms used. This leads to reduced capital turnover and should be taken into account when evaluating effectiveness.",
                "Async streaming session may lose some updates due to delay in writing to DB. Especially you do this for multiple sessions under limited cores and network device. And I am also wondering, these streaming sessions often are just hanging (connected but not receiving anything, even for proper ping-pong instruction), how did you manage to deal with 25 exchanges and 50 pairs? In my experience, it was hard to differentiate the proper update intervals from not receiving anything. \n\nDistribution of cpu cores could have an impact on accurate recording of order book updates. Irregular/uncontrolled switching between the cores will have a negative impact on the data validity. I would like to know a little details of your hardware (# of cores) and os to collect for your data.\n\nThe realtime storage to DB is a relatively slow approach to store order book (e.g., in tens of millisecond for DB write) while preserving the data integrity for trading purpose. It would be nice in future to discuss the validity of collected order book. Often longer delay between order book updates may not be very useful while backtesting. \n\nAlong with the order book, it is necessary to collect the tick data (transaction records with the timestamp and side) for high-frequency trading purpose. To my knowledge, HFT industry uses strategy to processing multiple order books from different exchanges (assigning these order books as independent and dependent variables accordingly).\n\nSOR, aggregating multiple order books into one, may come hand in observing the market trend or long-term portfolio strategy. It's doubtful that it will have an impact in high-frequency trading. \n\nIt involves a large packet processing from multiple streaming sessions, why not considering approach using special hardware, like solarflare or dpdk? Maintaining the arrival order is crucial for trade strategy.",
                "- As mentioned as a shortcomings, since the explanation of the implementation results(collected data format, kafka topic, etc.) and the contents of the experiments are insufficient.\nif additional experiments are added, the degree of completion of the paper will increase.\n- In addition, there may be errors in sentences other than typos in subheadings of related work(C. Applications reyling on order book data), so it is necessary to review the overall paper."
            ],
            "score": {
                "Relevance": 2.6,
                "Content and originality": 2.8,
                "Reference": 2.8,
                "Overall recommendation": 3.0,
                "Poster acceptance": 3.4
            }
        },
        "body": "1 XUExponential University, Potsdam, Germany 2 Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam, Germany 3 ESCPBusiness School, Berlin, Germany mail@roberthenker.com, janolevollmer@web.de, mbick@escp.eu { daniel.atzberger, willy.scheibel, juergen.doellner } @hpi.uni-potsdam.de\n\nAbstract \u2014Offers to buy and sell cryptocurrencies on exchanges are collected in an order book as pairs of amount and price provided with a timestamp. Contrary to tick data, which only reflects the last transaction price on an exchange, the order book reflects the market\u2019s actual price information and the available volume. Until now, no system has been presented that can capture many different order books across several markets. This paper presents Hephaistos, a system for processing, harmonizing, and storing massive spot order book data from 22 centralized crypto exchanges and 55 currency pairs. After collecting the data, Hephaistos aggregates several order books in a so-called Unified Order Book, which is the foundation for a Smart Order Routing algorithm. As a result an order is splitted across several exchanges, which results in a better execution price. As component of a high-frequency trading system, Hephaistos captures 32 % of the total daily spot trading volume. We provide examples with data from two exchanges that show that the Smart Order Routing algorithm significantly reduces the slippage. Index Terms \u2014Cryptocurrencies, Centralized Exchanges, Order Book Data, Big Data, Stream Processing\n\nI. INTRODUCTION\n\nSince the launch of the first and most famous cryptocurrency, Bitcoin, more than 9 000 other cryptocurrencies have been created that can be traded on more than 240 specialized crypto exchanges [1]. In contrast to the frequently used closing prices, so-called tick data, which reflect the price at which the last transaction was executed in the past, order book data also make available the prices at which buyers and sellers would now buy and sell, but whose orders have not yet been executed due to a lack of matching complementary orders and will not necessarily have to be executed in the future [2]. The order book totals the volumes of all existing buy and sell orders at a given price and compares the totals sorted by amount as supply and demand. Besides fiat currencies such as EUR and USD, other cryptocurrencies can be used for trading a cryptocurrency, thus resulting in a variety of pairings. The exchange maps the currently available price from the offered, so-called maker orders, lowest selling price and the highest\n\nbuying price. If a buyer, so-called taker orders, buys equal to or higher than the lowest offered selling price or places an order equal to or lower than the highest offered buying price, the crypto exchange forms a transaction from the highest possible matching volume of the maker and taker orders. This transaction\u2019s price is then added as the latest tick to the tick data. In illiquid market phases or in the case of larger transactions, close observation of the order book is necessary, as the actual price available in the order book may deviate significantly from the last tick price [3]. Order Book Data is an example of Big Data using a taxonomy following Jin et al. [4]:\n\nVolume: The collected order books within three years are stored as a multivariate dataset with a total size of 55TB.\n\nVelocity: At liquid exchanges, an order book has an update frequency of only a couple of milliseconds.\n\nVeracity: Order book entries sometimes contain non-sensible entries that have to be detected and filtered.\n\nVariety: Some exchanges provide additional data besides the amount and price in an order book, e.g., notional volume, time of entry, time of last change, or order type.\n\nValue: Knowledge of historical order book data is necessary for evaluating quantitative investment strategies in back- tests [5], analyzing market structures [3], [6], or locating fraud activities [7], [8].\n\nThese characteristics of order book data cause, among other factors, a high level of technical complexity in their processing, storing, and analysis. To the best of our knowledge, there is no free service that provides real-time access to order books across several exchanges in a unified data scheme. Therefore our goal was to design and implement a customized solution. In this paper, we present the design and technical imple- mentation of a system, named Hephaistos , that collects data from the order books of multiple exchanges by accessing their respective public APIs. After checking each entry in the order book for errors, the accepted entries are stored in a uniform multivariate data scheme. In a further step the single order books are aggregated in a single Unified Order Book 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n(UOB). By applying a Smart Order Routing (SOR) algorithm, an incoming order is split across several exchanges to achieve a better execution price. To summarize, our work makes the following contributions:\n\n1) We built a fully working system that is integrated in a high-frequency trading system, which captures 32 % of the total daily spot trading volume.\n\n2) We present design considerations and details on its implementation.\n\n3) We present a UOB that aggregates the collected data within a single data structure, which allows the application of a SOR algorithm to reduce slippage. The remainder of this work is structured as follows: In Section II we present existing works for mining financial data for the cryptocurrency domain. The concept of our system, our data base scheme, and implementation details are described in Section III. As an use case for storing order books across several exchanges, we present a SOR algorithm together with an example for reducing slippage in Section IV. Our results are discussed in Section V. We conclude this work and point out directions for future work in Section VI.\n\nII. RELATED WORK\n\nOur consideration of the related work comprises three parts. First, we present papers that ignore order books and include only tick data in their considerations. However, different studies show that liquidity is a crucial aspect when investing in any asset, particulary in digital assets or cryptocurrencies, thus requiring knowledge about order book data [3]. We then proceed with a presentation of existing solutions for crawling order book data from crypto exchanges, and finally present different applications that rely on order book data.\n\nA. Applications relying on tick data\n\nMost related work focusses on tick data when analyzing cryptocurrencies. Ho et al. studied trading strategies for 23 cryptocurrencies, that are derived from candlestick patterns [9]. Their analysis is limited to aggregated daily price data and only requires the past opening, closing, high, and low prices, but ignores intraday price fluctuation. McNally et al. trained recurrent neural networks for price prediction based on histori- cal daily closing prices and compared them with the classical ARIMA model for time series analysis [10]. Another popular research direction is the combination of tick data with text data obtained from Twitter for predicting price movements [11], [12]. None of the presented methods considers the underlying order book in their studies. Accordingly, only explicit costs are taken into account in backtests, e.g., trading fees of the exchanges or clearing fees, whereas implicit costs are neglected. However, considering the order book is indispensable, espe- cially in the operational implementation of a trading strategy, since dealing with the slippage effect during the execution of an order is a challenge. The slippage effect occurs when one sell/buy order is executed against multiple buy/sell orders in the order book. As a result, the effective price where the\n\nresulting trades were executed deviate significantly from the initially assumed price. A study on the impact of implicit costs measured by several liquidity measures for different crypto exchanges is provided by Angerer et al. [3]. To adress this issue, we propose a SOR algorithm that reduces the implicit costs, which is a common technique in traditional financial markets [13].\n\nB. Existing systems\n\nExisting work on analysis and visualization of crypto data is limited to a small amount of data at a time, usually comprising only one currency pair and collected within a short time period such as one year. Moreover, the papers do not present any software implementation capable of managing order book data as Big Data. An exception is made by Dilbagi, who presents a hybrid persisted cloud approach for collecting order book data from Binance [14]. Another system architecture for collecting order book data from crypto exchanges using a GPU-accelerated processing pipeline, was proposed by Burj \u00b4 an and Gyires-T \u00b4 oth [15]. Their system collects data from Coinbase and stores the data for further analysis using neural networks. Our work goes further and collects order book data from more than one exchange and several currency pairs. This extension requires a more advanced system for processing, harmonizing, and storing the data. In our work, we therefore focus on the development of an infrastructure that is capable of creating a comprehensive data basis of order books for many cryptocurrency pairs from multiple exchanges over a long period of time that enables downstream analyses. To the best of our knowledge, we are the first to present a work in that direction.\n\nC. Applications reyling on order book data\n\nPuljiz et al. presented a work for detecting fraud activities in the cryptocurrency domain [6]. Their work relies on the order book of the BTC/USD pair collected at one exchange within 300 hours. In their work, the authors apply a continuous-time stochastic model to investigate the dynamics underlying an order book. A main result of their work was the evidence of widespread use of frontrunning, which is one among various market manipulation techniques [7], [16]. Front running refers to exploiting insider information in securities transactions by a stockbroker. It is assumed, for example, that the insider first buys these securities for his own portfolio before placing a large buy order to profit from the price increase of the subsequent order. Besides fraud detection, the analysis of quantitative trading strategies is a relevant application relying on order book data. Raheman et al. presented a market-making strategy that uses multiple independent agents, each with different strategies [5]. Their strategy increased returns in backtests on two order books and in a real-world setting.\n\nIII. ARCHITECTURE\n\nFigure 1 outlines the components of our system and their distribution across servers. The order book reconstruction and\n\nExchange A\n\nExchange B\n\nExchange C\n\nExchange D\n\n...\n\nOrder Book Reconstruction\n\nOrder Book Reconstruction\n\nOrder Book Reconstruction\n\nOrder Book Reconstruction\n\n...\n\nWebsocket\n\nWebsocket\n\nWebsocket\n\nWebsocket\n\nMessage Broker\n\nUnified Order Book Builder\n\nUnified Order Book\n\nArchiver\n\n. . .\n\nDatabase\n\n...\n\nFig. 1. System overview with the different components, instances, and their distribution across servers (grey rectangles).\n\narchiving components are implemented in Python and we use two independent PostgreSQL databases on separate servers for redundancy.\n\nA. Order Book Reconstruction Most exchanges offer a Websocket or FIXAPI to receive updates to the order book incrementally. The typical process starts with receiving or fetching a snapshot of the complete order book and then subscribing to a stream of incremental updates, where each update contains only the price levels that have changed since the preceding update. Three update cases can occur: (1) add a new price level, (2) change the volume of an existing price level, (3) delete a price level, though often the same representation of a ( price, volume ) -tuple is used for all three cases with a volume of 0 denoting the deletion of a level. It is up to the client to correctly reconstruct the order book from the stream of incremental updates by applying each update to their local state and ensure their local order book is fully in- sync with the source exchange\u2019s order book. There are different options to verify the integrity of the reconstructed order book, whose availability differ by exchange: Update timestamps are the most basic variant and allow verifying that updates have at least been received in the correct order.\n\nUpdate sequence numbers can be considered extension of update timestamps and are expected to be strictly incre- mental, thus additionally allow the detection of missing updates.\n\nChecksums are the most comprehensive approach that not only allows verifying the correct receiving of updates, but also the correctness of the reconstructed order book. They are computed over the first n levels of the order book after applying the respective update. Our system applies all three integrity checks as far as provided by the different exchanges. The reconstruction compo- nent of our system encapsulates all exchange-specific message parsing and API behavior, such as the handling of maximum order book depth, where some exchanges send explicit deletions for levels that exceed the maximum depth due to intermediately inserted levels, while others rely on the client to discover this. The reconstruction component outputs streams of fully reconstructed order book snapshots in a harmonized format. Our system runs one or more reconstruction processes per connected exchange to distribute the computational workload\n\nover multiple CPU cores, all of which feed the resulting snapshots into a central message broker.\n\nB. Message Broker\n\nWe introduced a central Apache Kafka message broker following the publisher-subscriber model to allow flexible scaling-out and distribution across servers on both ends. This avoids n:m connections between publishers (order book reconstruction) and subscribers (such as archiving) as well as having to perform the reconstruction of the same order book multiple times in different processes. Kafka offers low- enough end-to-end latency as well as an intermediate storage with guaranteed message ordering, which can act as cache and bridge load spikes as well as outages of the database and archiving services, thus ensuring completeness of the archived data. We use separate Kafka topics for each trading pair on each exchanges to allow consumers to selectively subscribe to required markets only, thus reducing the overall message load on the broker as well as the consumer.\n\nC. Archiving\n\nWe archive all received order book data without any aggregation or reduction for later analysis. The archiving component subscribes to all Kafka topics and encodes the received data into the database storage format described in section III-D , which involves deriving incremental changes again from the stream of snapshots in order to reduce the required storage space. The archiver keeps the current state in memory and only outputs a new database entry once a level has been removed or replaced and thus the valid until timestamp is know. This reduces the number of write operations to the database and ensures consistency compared to saving every level as soon as it arrives and filling in the valid until timestamp later. The disadvantage of this approach is that it can take considerable time until the full snapshot for a particular point in time is available in the database as levels further down in the order book change less frequently. The resulting table rows are committed in batches to reduce the transaction processing overhead in the database. Together with each batch, the archiving service stores the latest message id whose data is included in the batch for every Kafka topic in the same transaction. This ensures that in the event of a crash or restart, the archiving service can find the exact place in the order book stream where the archiving needs to continue without any data loss or integrity violations.\n\nv: 5.5 v: 3.2 v: 0.4\n\nv: 0.1\n\nv: 2.0\n\nv: 0.76 v: 1.0 v: 0.5 v: 3.3\n\nv: 2.67 v: 2.54 v: 0.32\n\nv: 1.43 v: 0.62\n\nvalid from valid until\n\nv: 0.02\n\nSnapshot at t x\n\nTime\n\nPrice Level\n\n19995\n\n19996\n\n19997\n\n19998\n\n19999\n\n20000\n\nv: volume\n\nFig. 2. Conceptual visualization of order book level changes over time.\n\nThe workload of the archiving can be easily distributed over multiple processes along different Kafka topics since encoding and database writes for different streams do not conflict.\n\nD. Database Storage\n\nOur database storage concept combines three aspects to maximize space efficiency while maintaining acceptable speed for typical workloads. Validity Timestamps: Figure 2 shows a contrived example of an order book and the changes to its levels over time. Each entry for a specific price level has a specific volume and exists for a specific timeframe until it is either replaced with an entry of a different volume or deleted. We denote the lifetime of such an entry using two timestamps: valid from for when an entry first enters the order book and valid until for when the entry is replaced or removed. The complete snapshot of the order book at any point in time t x consists of all entries with valid from \u2264 t x and valid until > t x . The key idea to our storage format is to store each entry as a separate row including the valid until timestamp. This allows directly fetching the order book snapshot for any point in time without requiring a starting snapshot and replaying incremental updates as received by the exchanges while maintaining the space efficiency compared to storing full order book snapshots after every update. Table Partitioning: Based on observations of use cases and queries run on the data, we determined that the majority of queries involve data from only small subset of markets (most often just one) and never merge bids and asks. This allows the use of table partitioning to reduce the query response time [17]. When using magnetic hard disks, the disk response time is a major factor in the total time required to filter a large table. To reduce the amount of data that needs to be searched and therefore loaded from disk, we use completely separate tables for bids and asks. Each of these two tables further uses Postgres\u2019 built-in table partitioning mechanism to physically store data from different markets at separate locations on the disk. Queries can directly access the required partition or use the parent table with a filter for the market, in which case the query planner automatically determines the appropriate partition(s). In both cases, the amount of data that needs to be loaded from disk is drastically reduced, thus reducing the query response time accordingly. In addition, this speeds up sequential accesses\n\nof specific tables (such as occurs when exporting data for a timerange or replaying it during backtesting) even further due to the improved spatial locality on disk. BRINIndexes: The search for a particular point in time or timerange using the valid from and valid until fields is a common filter criterion in our queries. While it is possible to use traditional b-tree indexes to accelerate the search of a table for a particular value, they generally require as much disk space as the target column(s) since they need to contain the value of every row and thus exhibit a considerable space overhead for tables with a few columns but many rows. Due to the way the archiver works, the tables are effectively insert-only tables, i.e., data is only ever inserted, but never modified or deleted. Further, on a large scale view, the order of rows inserted into the tables and thus their order on disk correlates with the valid from and valid until timestamps. The Block Range Index (BRIN) index is a highly specialized index for exactly such cases where the target column correlates with the order on disk [18]. It divides the set of table rows into blocks and stores the value range (minimum and maximum) for the target columns in every block. The lookup consist of a linear search of block summaries for blocks whose value range covers the value in question, followed by linear searches of every block found for the exact matches. This type of index provides sufficient speed-up for our use case with minimal space overhead for storing the index data.\n\nE. Unified Order Book Builder\n\nThe key idea of a UOB is that it includes price levels and the related volumes from several exchanges that list a given pair. Each price level of the UOB includes the exchange it originated from in addition to price and volume. If multiple exchanges offer the same price level, they are not aggregated but included separately to allow subsequent separation again. The UOB thus diverges from traditional representations in that it is only monotonically in/decreasing, but not strictly monotonically, i.e., if two different exchanges contain two levels with the same price they will occur as separate entries within the UOB. An example of the UOB originating from two order books is shown in Table I. The building of the UOB is a separate component. It is implemented as a stream processor, i.e., a separate process receives individual order book updates from Kafka, builds the UOB, and feeds the result back into Kafka. This has the advantage that the calculation is done only once, and multiple engine instances may use the same result. However, it has the drawback that it results in higher latency and overall computation effort if only one instance uses the result\n\nIV. SMART ORDER ROUTING\n\nIn illiquid market phases or when placing large orders, several levels of the order book are required for execution. The associated implicit costs lead to a higher average purchase or lower average selling price. In the following, we present a SOR algorithm that splits an order and distributes it across multiple exchanges to minimize the implicit costs. The SOR\n\nTABLEI FIRST TENLEVELS OFTHE ASKSIDE OFTWO ORDERBOOK SNAPSHOTS FROMCEXIO ANDKraken TOGETHERWITH THERESULTING UOB.\n\nCEXIOKraken Unified Order Book Price Volume Price Volume Price Volume Exchange\n\n20 078.3 $ 0.001 BTC 20 092.6 $ 0.004 BTC 20 078.3 $ 0.001 BTCCEXIO 20 132.3 $ 0.410 BTC 20 098.9 $ 0.647 BTC 20 092.6 $ 0.004 BTCKraken 20 132.4 $ 0.573 BTC 20 105.2 $ 0.619 BTC 20 098.9 $ 0.647 BTCKraken 20 132.6 $ 0.900 BTC 20 115.3 $ 0.486 BTC 20 105.2 $ 0.619 BTCKraken 20 137.7 $ 0.498 BTC 20 136.2 $ 0.400 BTC 20 115.3 $ 0.486 BTCKraken 20 187.9 $ 1.000 BTC 20 191.0 $ 5.289 BTC 20 132.3 $ 0.410 BTCCEXIO 20 321.9 $ 0.148 BTC 20 200.9 $ 0.124 BTC 20 132.4 $ 0.573 BTCCEXIO 20 322.0 $ 2.000 BTC 20 228.8 $ 0.100 BTC 20 132.6 $ 0.900 BTCCEXIO 20 500.0 $ 0.250 BTC 20 238.1 $ 0.003 BTC 20 136.2 $ 0.400 BTCKraken 20 966.4 $ 0.001 BTC 20 254.8 $ 0.001 BTC 20 137.7 $ 0.498 BTCCEXIO\n\nFig. 3. Procedure of the SORAlgorithm. An order might require several levels in an order book to be executed. The blue boxes group the required levels within a single order book that belong to such a trade. The orange boxes indicate the levels of the splitted order.\n\nalgorithm follows three steps as shown in Figure 3. First, the UOB is created for the exchanges under consideration. Secondly, the splitted orders are computed by considering the UOB. In the third step, the single orders are executed on the single exchanges. To illustrate the effectiveness of our approach, we consider the concrete example from Table I. In Table II the average buy prices and the slippage, i.e., the relative distance to the first order book level, are summarized. By construction, the SOR algorithm consistently achieves the lowest average price. The difference to the respective price on one of the two alternative exchanges increases with growing investment volume and amounts to up to 0.38 % . The UOB also has the smallest best ask price, which means that for small investment volumes, the slippage on a single exchange, specifically Kraken in this case, is smaller. However, from an investment volume of 3.0 BTC , the relative slippage in the UOB is the smallest. The difference\n\nincreases with growing investment volumes, For an investment of 5.0 BTC , the implied cost is 158 % higher on CEXIO and 28 % higher on Kraken. It is worth mentioning that we are only looking at two exchanges here. With a growing number, the reduction of the slippage effect by the SOR can be expected to increase significantly.\n\nV. RESULTS & DISCUSSION\n\nThe Hephaistos system is tailored to handle order book data from several crypto exchanges and is effective regarding this approach with the current setup. Currently, it collects the order books of 22 exchanges and 55 currency pairs, representing 1 210 individual markets (unique pairs per exchange). Accord- ing to CoinMarketCap those markets represent 32 % of the total daily spot trading volume.In September 2022 alone, the 1 210 unique markets generated 32 043 446 130 price updates, which corresponds to 1.7 TB additional storage volume in the system. However, the trading of traditional assets, e.g., stocks, and alternative assets, e.g., commodities or energy, is also organized via order books. Providing this data is an essential part of the business model of traditional exchange operators. An extension of Hephaistos to more liquid markets will have impact regarding the scalability of the architecture and the adaptability to other exchanges and their APIs. Scalability: Regarding scalability, the processing of a larger trade throughput is required. Using parallelization across multiple CPUs, the system can scale up on order book reconstruction accordingly. Archiving only requires the addition of more storage. Extensibility to other Exchanges: The respective ex- changes allow access to the order books of the respective markets via an API interface. These APIs are handled using corresponding new implementations of order book reconstruc- tions and therefore do not require any architectural changes. Although each exchange can communicate more data in their order book updates, we don\u2019t expect data structure mismatches with our unified storage scheme.\n\nVI. CONCLUSIONS\n\nCentralized exchanges enable the trading of cryptocurrencies. Buy and sell orders are managed in the order book and thus\n\nTABLEII AVERAGE PRICEFOR BUYINGONE BITCOIN FORDIFFERENT ORDERVOLUMES . THE SLIPPAGEMEASURES THERELATIVE DISTANCEBETWEEN THERESULTING AVERAGEPRICE ANDTHE FIRSTLEVEL INTHE RESPECTIVEORDER BOOK .\n\nCEXIOKraken Unified Order Book Volume Avg. Price Slippage Avg. Price Slippage Avg. Price Slippage\n\n0.5 BTC 20 132.21 $ 0.27 % 20 098.85 $ 0.03 % 20 098.80 $ 0.10 % 1.0 BTC 20 132.31 $ 0.27 % 20 101.07 $ 0.04 % 20 101.05 $ 0.11 % 1.5 BTC 20 132.41 $ 0.27 % 20 104.00 $ 0.05 % 20 103.97 $ 0.13 % 2.0 BTC 20 132.75 $ 0.27 % 20 109.37 $ 0.08 % 20 108.87 $ 0.15 % 2.5 BTC 20 136.10 $ 0.29 % 20 122.28 $ 0.15 % 20 113.57 $ 0.18 % 3.0 BTC 20 144.74 $ 0.33 % 20 133.73 $ 0.20 % 20 116.73 $ 0.19 % 3.5 BTC 20 155.42 $ 0.38 % 20 141.91 $ 0.25 % 20 119.00 $ 0.20 % 4.0 BTC 20 176.25 $ 0.48 % 20 148.05 $ 0.28 % 20 121.02 $ 0.21 % 4.5 BTC 20 192.44 $ 0.57 % 20 152.82 $ 0.30 % 20 122.86 $ 0.22 % 5.0 BTC 20 205.40 $ 0.63 % 20 156.64 $ 0.32 % 20 128.98 $ 0.25 %\n\nform the basis for price formation. The retrieval of order book data across multiple exchanges and currency pairs, poses great challenges for its technical implementation. To overcome these challenges, we developed Hephaistos, a system and infrastructure for processing, harmonizing, and storing massive order book data. The system is able to reconstruct an order book in real time and allows to archive this data in an UOB. As one possible application of the UOB, we presented a SOR algorithm to execute one order across multiple marketplaces resulting in multiple transactions to counteract the slippage effect and thus achieving a better execution price. Our next step is to investigate to what extent the use of the SOR helps to improve the return on quantitative investment strategies. For this purpose, simple trading strategies, e.g., based on chart signals, will be simulated. In this context, the necessity of knowledge of the order book can also be demonstrated. One of the observations on the UOB is that a negative spread might occur, i.e., the best ask price can be lower than the best bid price on another exchange. Such a situation offers an arbitrage opportunity in which an asset can be bought on one exchange and simultaneously sold on another exchange with profit. It is necessary to investigate to what extent the market data show such theoretical opportunities and if these can be actually exploited. Another possible direction for future work is to apply existing approaches relying on order book data, e.g., fraud detection, on a larger dataset. Also, a comparison to the state of UOB and SOR in traditional financial markets, e.g. in terms of technical architecture, data throughput, and latency, would be beneficial.\n\nREFERENCES\n\n[1] CoinMarketCap. Top cryptocurrency spot exchanges. 2023. URL : coin- marketcap.com/rankings/exchanges/.\n\n[2] Martin DGould, Mason APorter, Stacy Williams, Mark McDonald, Daniel JFenn, and Sam DHowison. Limit order books. Quantitative Finance , 13(11):1709\u20131742, 2013.\n\n[3] Martin Angerer, Marius Gramlich, and Michael Hanke. Order book liquidity on crypto exchanges. In Proceedings of the 3rd Crypto Asset Lab Conference , CAL \u201921. Crypto Asset Lab, 2021.\n\n[4] Xiaolong Jin, Benjamin WWah, Xueqi Cheng, and Yuanzhuo Wang. Significance and challenges of big data research. Big Data Research , 2(2):59\u201364, 2015.\n\n[5] Ali Raheman, Anton Kolonin, Ben Goertzel, Gergely Hegyk \u00a8 ozi, and Ikram Ansari. Architecture of automated crypto-finance agent. In Proceedings of the International Symposium on Knowledge, Ontology, and Theory , KNOTH \u201921, pages 10\u201314. IEEE, 2021.\n\n[6] Mate Puljiz, Stjepan Begu \u02c7 sic, and Zvonko Kostanjcar. Market microstruc- ture and order book dynamics in cryptocurrency exchanges. pre-print, URL : www.bib.irb.hr/952865, 2018.\n\n[7] Felix Eigelshoven, Andre Ullrich, and Douglas AParry. Cryptocurrency market manipulation: A systematic literature review. In Proceedings of the International Conference on Information Systems , ICIS \u201921. AIS, 2021.\n\n[8] Friedhelm Victor and Andrea Marie Weintraud. Detecting and quantifying wash trading on decentralized cryptocurrency exchanges. In Proceedings of the Web Conference 2021 , WWW \u201921, pages 23\u201332. ACM, 2021.\n\n[9] Kin-Hon Ho, Tse-Tin Chan, Haoyuan Pan, and Chin Li. Do candlestick patterns work in cryptocurrency trading? In Proceedings of the International Conference on Big Data , BigData \u201921, pages 4566\u20134569. IEEE, 2021.\n\n[10] Sean McNally, Jason Roche, and Simon Caton. Predicting the price of bitcoin using machine learning. In Proceedings of the 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing , PDP \u201918, pages 339\u2013343. IEEE, 2018.\n\n[11] Jethin Abraham, Daniel Higdon, John Nelson, and Juan Ibarra. Cryp- tocurrency price prediction using tweet volumes and sentiment analysis. SMUData Science Review , 1(3), 2018.\n\n[12] Shubhankar Mohapatra, Nauman Ahmed, and Paulo Alencar. KryptoOr- acle: A real-time cryptocurrency price prediction platform using twitter sentiments. In Proceedings of the International Conference on Big Data , BigData \u201919, pages 5544\u20135551. IEEE, 2019.\n\n[13] Xiaoyun Wang and Tu Lai Huan. Bnp paribas: Equity smart order router. Electionic Projects Collection , 2010.\n\n[14] Arsh Dilbagi. Infrastructure and techniques to collect data and detect market manipulation on crypto-exchanges. Master\u2019s thesis, Operations Research and Financial Engineering, Princeton University, New Jersey, USA, 2021.\n\n[15] Viktor Burj \u00b4 an and B \u00b4 alint Gyires-T \u00b4 oth. Gpu accelerated data preparation for limit order book modeling. In International Conference on Machine Learning, Optimization, and Data Science , pages 385\u2013397. Springer, 2020.\n\n[16] Massimo Bartoletti, Barbara Pes, and Sergio Serusi. Data mining for detecting bitcoin ponzi schemes. In Proceedings of the Crypto Valley Conference on Blockchain Technology , CVCBT \u201918, pages 75\u201384. IEEE, 2018.\n\n[17] PostgreSQL. Documentation table partitioning. 2023. URL : postgresql.org/docs/12/ddl-partitioning.html.\n\n[18] PostgreSQL. Documentation brin indexes. 2023. URL : www.postgresql.org/docs/12/brin.html."
    },
    {
        "number": 1570880713,
        "title": "Examining Liquidity of Exchanges and Assets and the Impact of External Events in Centralized Crypto Markets: A 2022 Study",
        "abstract": "Most cryptocurrencies are bought and sold on centralized exchanges that manage supply and demand via an order book. Besides trading fees, the high liquidity of a market is the most relevant reason for choosing one exchange over the other. However, as the different liquidity measures rely on the order book, external events that cause people to sell or buy a cryptocurrency can significantly impact a market's liquidity. To investigate the effect of external events on liquidity, we measure various liquidity measures for nine different order books comprising three currency pairs across three exchanges covering the entire year 2022. The resulting multivariate time series is then analyzed using different correlations.\nFrom the results, we can infer that as a cryptocurrency's market capitalization and the exchange's trading volume increases, so does its liquidity. At the same time, only a moderate correlation of liquidity between exchanges can be observed. Furthermore, our statistical observations show that external events, particularly the events around FTX and the Terra Luna crash, caused significant changes in liquidity. However, depending on the exchange's size and the cryptocurrency's market cap, the liquidity took a shorter or longer time to recover.",
        "review": {
            "strength": [
                "1. This paper is well-organized and the topic is important for crypto exchanges.\n2. This paper presents detailed experiment results with tables and figures.",
                "The topic is timely and interesting. \nThe problem is well-motivated in the manuscript, however, the reader must accept that there is a problem. \nThe study is on a one-year dataset.",
                "The paper examines the liquidity of cryptocurrency exchanges and the impact of external events. It is very well written and the structure of the paper flows nicely. The authors have provided a sufficient background to the problem and review of the relevant literature. The research questions are addressed with relevant results and discussed well.",
                "This study investigates the influence of external events on liquidity in the cryptocurrency market. It collects data from three exchanges and currency pairs, and analyzes the correlation between trading volume and liquidity through the collected data.\n\nStrengths of the paper is that it collected long-term data for a year and studied the correlation between external events and liquidity changes."
            ],
            "shortcoming": [
                "1. This paper emphasizes the impact of external events but few were considered and they are briefly addressed in the paper.\n2. There are little explanation why this paper considers such measures and exchanges",
                "The paper does not provide a clear framework or methodology for evaluating the effectiveness of the proposed solution, which could limit its usefulness for additional research.\nEvaluation and testing are very simplistic indeed there are not really any results or experimental analyses in the paper. More comprehensive testing and evaluation use cases are needed.\nThere is a lack of methodological content in the paper.\nThere are only a few details on the data which is really needed to understand the format of data and make the replication easier.",
                "The paper does not have any significant shortcomings. However, while most of the cited papers are relevant to crypto markets, the paper should also reference other relevant literature relating to liquidity and the impact of external events in traditional financial markets.",
                "When the results of the correlation presented through the experiment in the paper are shown, it is judged that the result value for the correlation is insufficient.\nAlso, I think it is common for prices to fluctuate due to external events in the cryptocurrency market, just as in general or stock markets, so I'm not sure if studying correlations would be effective. For example, when the value of the dollar and the US stock market were hit, the value of cryptocurrencies also decreased."
            ],
            "comment": [
                "1. It would be better to introduce more about VWAP and XLM such as their strengths and weakness.\n2. Why VWAP and XLM is adopted for measurement?\n3. Why HitBTC and CEXIO is chosen for experiment even though there are many exchanges?\n4. There are some typos\n- Equation 5, \ud835\udc43_(\ud835\udc4e\ud835\udc60\ud835\udc58, \ud835\udc3f)^\ud835\udc49\ud835\udc4a\ud835\udc34\ud835\udc43 -> \ud835\udc43_(\ud835\udc4f\ud835\udc56\ud835\udc51, \ud835\udc3f)^\ud835\udc49\ud835\udc4a\ud835\udc34\ud835\udc43\n- Section IV, \u201cBitBTC\u201d -> \u201cHitBTC\u201d\n- Section V, B, \u201cFor an investment of 100 000 USDT, it would be 25.7\u201d -> \u201cFor an investment of 100 000 USDT, it would be 2.57\u201d",
                "The study focuses on liquidity in the cryptocurrency market and seeks to answer several key questions. Firstly, it examines the development of market liquidity over the past year, using several measures of liquidity to evaluate the depth, breadth, and resiliency of liquidity across different trading venues and assets. Secondly, it investigates whether liquidity is independent of asset class or exchange, measuring the correlation of liquidity between assets and trading venues. Finally, it examines whether there are any noticeable changes in liquidity throughout the year. As a topic, it is actual, however, the study could be improved by involving more related works and studies looking to examine the liquidity, providing more technical and methodological details on evaluation and implementation, and also  bringing more novelty in terms of widening knowledge in the research community.",
                "While most of the cited papers are relevant to crypto markets, the paper should also reference other relevant literature relating to liquidity and the impact of external events in traditional financial markets.",
                "I think it is a valuable paper for conducting research by collecting data for a long period of one year and deriving some meaningful experimental results through the collected data.\n- In algorithm (5), It is necessary to correct the error written as VWAP ask - VWAP ask and review the overall paper to make sure there are no error such as typo.\n- Additionally, it would be nice if the blog information or website information in the references could be replaced with other papers or reliable reference."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 3.0,
                "Reference": 3.0,
                "Overall recommendation": 3.0,
                "Poster acceptance": 3.5
            }
        },
        "body": "1 Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam, Germany 2 XUExponential University, Potsdam, Germany { adrian.jobst, daniel.atzberger, willy.scheibel, juergen.doellner } @hpi.uni-potsdam.de mail@roberthenker.com, janolevollmer@web.de\n\nAbstract \u2014Most cryptocurrencies are bought and sold on cen- tralized exchanges that manage supply and demand via an order book. Besides trading fees, the high liquidity of a market is the most relevant reason for choosing one exchange over the other. However, as the different liquidity measures rely on the order book, external events that cause people to sell or buy a cryptocurrency can signi\ufb01cantly impact a market\u2019s liquidity. To investigate the effect of external events on liquidity, we measure various liquidity measures for nine different order books comprising three currency pairs across three exchanges covering the entire year 2022. The resulting multivariate time series is then analyzed using different correlations. From the results, we can infer that as a cryptocurrency\u2019s market capitalization and the exchange\u2019s trading volume increases, so does its liquidity. At the same time, only a moderate correlation of liquidity between exchanges can be observed. Furthermore, our statistical observations show that external events, particularly the events around FTX and the Terra Luna crash, caused signi\ufb01cant changes in liquidity. However, depending on the exchange\u2019s size and the cryptocurrency\u2019s market cap, the liquidity took a shorter or longer time to recover. Index Terms \u2014Cryptocurrencies, Centralized Exchanges, Or- der Book Data, Liquidity\n\nI. INTRODUCTION\n\nCryptocurrencies are digital assets that use strong encryption to map \ufb01nancial transactions and digitally verify transfers [1]. In the past decade, cryptocurrencies emerged as a relevant asset class for both retail and professional investors [2]. This is due to several reasons. On the one hand, their high volatility offers numerous opportunities for quantitative investment strategies and trading. On the other hand, cryptocurrencies are seen as an alternative to traditional \ufb01at currencies and thus serve within a portfolio to spread risk. Especially large asset management companies are increasingly confronted with the demand for novel products from their clients. This led, for example, to the launch of new indices that describe the development of the market capitalization of a set of cryptocurrencies and Exchange Traded Funds (ETFs) that make accessible to investors [3]. Cryptocurrencies can either be traded on a centralized or decentralized exchange [4]. In centralized exchanges, e.g.,\n\nBinance , Coinbase , or Kraken , a third-party provider monitors all transactions and acts as an intermediary between buyer and seller. In decentralized exchanges, e.g., PancakeSwap , Sushiswap , or Venus , transactions are settled via smart contracts, which makes a third party irrelevant. The larger part is traded on centralized exchanges, where supply and demand are managed via an order book. An order book contains all open buy and sells orders and arranges them in levels [5]. In the case of a buy order (bid), this arrangement is made in descending order with the price, and in the case of a sell order (ask), in ascending order with the price. If a sell order and a buy order meet, i.e., they agree on a price for a cryptocurrency, a trade takes place, and their orders are removed from the order book. With respect to return, the associated costs for trading cryptocurrencies are the main reason for choosing an exchange. Besides the low transaction fees, the exchange should provide high liquidity, as otherwise, the average price achieved may deviate too much from the initially assumed price. Especially when investing larger volumes that correspond to several levels in the order book, such price differences strongly impact the achieved return. Various liquidity measures have been developed to quantify this effect, each requiring an order book as input. Market phases with signi\ufb01cant changes in order books thus lead to a change in liquidity and thus directly in\ufb02uence the costs of trading. While existing work has measured the liquidity of various currency pairs on different exchanges, no work exists that dedicately includes external events in its considerations. However, such events are often the cause of increased trading volume. In this paper, we want to investigate the effect of external events on the liquidity of currency pairs on centralized crypto exchanges. For this purpose, we investigate the order books of three currency pairs, BTC/USDT, ETH/USDT, and LTC/USDT, from three exchanges, namely Binance , HitBtc , and CEXIO , that cover the entire year 2022. As relevant events, we consider the incidents around FTX [6] and Terra Luna [7]. By surveying various measures of liquidity, we generate a multidimensional time series that captures different aspects of liquidity of nine different order books in \ufb01ve minute intervalls. By statistical investigations, we adress the following questions through a quantitative approach: 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nRQ1 What are the measures\u2019 similarities or differences, and how should liquidity be measured?\n\nRQ2 How does liquidity differ between different assets on different exchanges?\n\nRQ3 Is the liquidity of different assets or exchanges indepen- dent of each other?\n\nRQ4 Are there noticeable changes in liquidity over the course of 2022?\n\nThe remaining part of this work is structured as follows: Section II presents existing works that measure the liquidity of crypto exchanges. The different measures for liquidity used in our study are formalized in Section III. In Section IV we give details about the data collected within the year 2022, before we present the results in Section V. We discuss our results and threats to validity in Section VI. A conclusion and directions for future work are given in Section VII.\n\nII. RELATED WORK\n\nA formal consideration of implicit costs arising from the structure of an order book is made using so-called liquidity measures [8]. One example of a primary liquidity measure is the spread, i.e., the difference between the best ask price and the best bid price. Especially for retail investors, whose trades mostly rely on the \ufb01rst few levels of the order book, the spread is the most relevant measure [9]. Dyhrberg et al. used data from three U.S. crypto exchanges to examine the extent to which Bitcoin is suitable for retail investors [10]. In their study, they were able to determine from the trading activities that a large part of the activities originates from retail investors. By measuring the spread of the order books, it was shown that the costs incurred are meager and even lower than those of traditional exchanges. A more detailled study on emerging implicit costs for cryptocurrency trading, was presented by Angerer et al. [11]. In their work the authors measured several liquidity measures for a large set of target and base currencies based on a publicly available order book data set of four exchanges of 273 days, which are observed in 5-minute intervals. Their results con\ufb01rmed the results of Dyhrberg and Foley, but also showed that the slippage effect can have a large impact for trading larger volumes. The slippage effect means that the execution of an order requires several orders on the opposite side, which leads to a distortion of the average price achieved. In many cases the costs caused by the slippage effect are signi\ufb01cantly higher than the explicit costs [9]. The authors found several characteristics that indicate a small slippage effect. For example, exchanges that offer fewer currency pairs and allow investing through \ufb01at currencies instead of \ufb01at-pegged stablecoins provide higher liquidity in terms of slippage. Although the various liquidity measures capture implicit costs in investing, they are not necessarily correlated. For a discussion of which measures are particularly relevant and suitable for different questions, see [8], [12]. In particular, the authors suggest which measures should be applied during phases of high and low volatility.\n\nIn a later work, Brauneis et al. compared the liquidity of three order books, where Bitcoin is traded against USD, with broader \ufb01nancial markets, e.g., foreign exchange markets [13]. Their results indicate that the liquidity on crypto exchanges is unrelated to broader \ufb01nancial markets, but rather related to the activity on the blockchain and exchange-speci\ufb01c attributes. Our work builds on existing work but differs from existing work in two critical ways. First, we consider the most extended period of all studies. Second, no work exists that examines changes in liquidity throughout external events.\n\nIII. MEASURES FORL IQUIDITY\n\nBesides explicit costs, e.g., exchange fees or taxes, implicit costs in\ufb02uence the pro\ufb01t/loss of an investor when trading cryptocurrencies. In liquid markets, these implicit costs are low. Various measures for quantifying liquidity exist, usually requiring information about individual trades or the order book [8], [14]. In this section, we introduce the liquidity measures that are used in our experiments, which are order book based as the exchanges of our interest only offer access to order book data. Our notation is similar to that used in the work of Angerer et al. [11]. The order book contains all open ask and bid offers for buying and selling a target currency, e.g., Bitcoin or Ether, using a quote currency, e.g., Tether. In our considerations, we always refer to Tether as the quote currency. All buy orders are sorted into levels given as pairs ( P l , Q l ) , where P l denotes the price for the target currency in the quote currency and Q l denotes the quantity measured in target currency units for the ask and bide side, respectively. The best ask price P best ask refers to the lowest-priced sell order, and the best bid price P best bid refers to the highest-priced bid order. The average\n\nP mid = P best ask + P best bid\n\n2 (1)\n\nbetween the best ask price P best ask and the best bid price P best bid is called the mid-price and is usually referred to as the \u201cprice\u201d of a target currency. The difference\n\nSpread = P best ask \u2212 P best bid (2)\n\nis called the spread of the order book. In a perfect liquid market with Spread = 0 , P mid would be the price for selling and buying the target currency. To compare liquidity across different target currencies, one usually considers the relative spread given by\n\nRelative Spread = Spread\n\nP mid (3)\n\nThe relative spread is the most crucial liquidity measure for retail investors, who usually place small orders. However, when placing large orders requiring more levels in the order book to be traded against, the order book depth has to be considered. When placing larger orders, the average price paid for the target currency might signi\ufb01cantly differ from the mid-price. The volume-weighted average price (VWAP), is another liquidity\n\nmeasure that quanti\ufb01es the expected price for the bid and ask sides respectively\n\nPVWAP L =\n\nLP\n\nl =1 P l \u00b7 Q l\n\nLP\n\nl =1 Q l\n\n. (4)\n\nThe spread of the VWAP and its normalized spread is de\ufb01ned analogously as before, i.e.,\n\nRel. Spread VWAPL = Spread VWAPL\n\nP mid = PVWAP ask, L \u2212 PVWAP bid, L\n\nP mid (5)\n\nAs a further measure for liquidity, we adopt the Xetra Liquid- ity Measure (XLM) used within the Deutsche B \u00a8 orse Group [9]. The XLM is based on the idea that liquidity corresponds to implicit costs. Given a buy order of volume vol in target currency units, the order requires ( P 1 , \u02dc Q ask , 1 ) , . . . , ( P n , \u02dc Q ask ,n ) sell orders to be traded against. It is important to note that \u02dc Q ask , 1 = Q ask , 1 for i < n and \u02dc Q ask ,n \u2264 Q ask ,n . The implicit costs are then given by the sum of a liquidity premium and the adverse price movement, in the formula:\n\nXLM buy ( vol ) =\n\nn X\n\ni =1 P i \u00b7 \u02dc Q ask ,i \u2212 P mid \u00b7 vol . (6)\n\nAnalogously the XLM for the sell side is de\ufb01ned. The sum of the sell and buy side is usually referred to as the XLM, i.e.,\n\nXLM ( vol ) = XLM buy ( vol ) + XLM sell ( vol ) (7)\n\nIV. DATA\n\nDaily market capitalization and trading volume data are from CoinMarketCap 1 . To make our exploratory data analysis more illustrative, we select three assets. Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC). We choose these assets because they are popular, and have high availability but still differ drastically in terms of market capitalization. According to CoinMarketCap, the market capitalization of Bitcoin is about 67 times higher than that of Litecoin. Liquidity measures are calculated on order book snapshots, we retrieve these from the APIs of three selected exchanges, Binance 2 , HitBtc 3 and CEXIO 4 . Binance was chosen because it has the highest trading volume of all exchanges and should therefore be the most liquid. HitBtc\u2019s trading volume is still among the higher ones, but it is about 16 times lower than Binance\u2019s. CEXIO\u2019s trading volume is about 289 times lower than HitBtc\u2019s, which is drastically lower than Binance\u2019s, so it serves as an example of an exchange that is presumably less liquid. Exchanges usually offer different quote currencies in which the asset can be traded. We chose Tether (USDT) as the quote currency on all three exchanges because it is usually the same as the USD rate. This, and the single quote currency, makes comparison easier.\n\n1 https://coinmarketcap.com/ 2 https://www.binance.com 3 https://hitbtc.com 4 https://cex.io\n\nWe calculate all liquidity measures based on order book snapshots at \ufb01ve-minute intervals, so there should be 105 120 observations per trading pair, for a total of 946 080. There may be missing values if there is no snapshot at a given time or if one side of the order book is missing, which was the case 7 407 times ( < 1 % ). Invalid observations may also occur because the data retrieved from the exchange\u2019s API may be non-sensible or errors may have occurred during data storage. This is the case, for example, when the spread is negative, which occurred 3 724 times ( < 1 % ). A more detailed breakdown is shown in Table I.\n\nV. RESULTS\n\nWe calculated all VWAP measures on an order book depth of 5, 10, 25 and 50 levels. As a value of 1 for the VWAP equals the spread, and the value of 1 for the relative VWAP equals the relative spread we will refer to VWAP at level 1 for better readability. The XLM is calculated with 10 000 and 100 000 as the targeted volume. Smaller quantities would be of interest to small investors, but that would mainly clear orders near the best bid or ask. However, due to practices such as wash trading or trading bots, it is questionable whether liquidity at these levels is real and if these orders are actually executed, so we consider a higher volume to be a more realistic representation of liquidity. The XLM measures could not be calculated for all order books as there must be suf\ufb01cient volume. The XLM with a volume of 10 000 USDT could not be calculated 38 151 times (4 % ), which is mainly due to LTC on CEXIO (38 125). For the XLM with a volume of 100 000 USDT , 135 569 values are missing (14 % ), which is also mainly due to assets traded on CEXIO, more speci\ufb01cally LTC (98 750), followed by BTC (22 287) and ETH (13 372).\n\nA. What are the measures\u2019 similarities or differences, and how should liquidity be measured??\n\nA study by Aitken & Comerton-Forde shows that different liquidity measures may not have high correlations and the choice of measure may therefore affect the outcome of the analysis [8]. Thus, it is important to understand the commonalities and differences between the measures. Table IIa shows the correlation matrix of all relative spread measures. The correlation of the relative VWAP spread decreases from the middle of the spread toward lower levels of the order book. In general, there is a strong linear relationship between the relative VWAP spread of level 1 to 25. The correlation of XLM(10 k ) to XLM(100 k ) is 0.57, which is a strong linear relationship. However, not all order books could provide suf\ufb01cient volume for a demand of 100 000 USDT , thus the actual relationship is weaker. The correlation between XLM and VWAP measures can be seen in the table table IIb. The correlation between XLM(10 k ) and VWAP relative spread is highest at level 25, indicating that more levels are needed in the order book to deliver enough volume to satisfy the demand of 10 000 USDT . The same is true for an investment of 100 000 USDT , so the correlation between XLM(100 k ) and the relative VWAP spread is highest at Level 50. In general, we can see that the measures\n\nTABLEI: Asset Overview\n\nNote: Volume and Market capitalization refer to the asset in general, not on the certain exchange. Amounts differ because missing or invalid observations got \ufb01ltered and therefore excluded. Relative spreads are measured in 1e-3. Volume is Measured in 1e6, cap refers to market capitalization in 1e9, and values are rounded. XLM measures refer to XLM(vol).\n\nvwap 1 vwap 5 vwap 25 vwap 50\n\nMiss. Inv. Volume Cap Price spr rel. spr. spr rel. spr. spr rel. spr. spr rel. spr. XLM(10k) XLM(100k)\n\nBinance\n\nBTC 31 3 663 29 949 536 28 146 0.47 0.02 1.46 0.05 5.94 0.20 10.71 0.35 0.59 1.99 ETH 33 58 15 277 240 1 990 0.02 0.01 0.15 0.07 0.74 0.38 1.36 0.71 0.49 2.57 LTC 39 2 691 6 80 0.05 0.56 0.26 2.92 0.87 9.74 1.65 18.68 8.45 20.74\n\nHitBtc\n\nBTC 2 009 0 29 936 539 28 320 3.75 0.15 8.58 0.33 30.39 1.12 46.45 1.71 2.94 9.88 ETH 2 011 0 15 285 241 1 995 0.48 0.29 1.16 0.65 2.94 1.56 4.53 2.47 7.16 14.27 LTC 2 581 0 694 6 80 0.04 0.49 0.09 1.14 0.24 3.03 0.47 5.91 16.10 36.93\n\nCEXIO\n\nBTC 263 0 29 969 537 28 241 88.25 4.12 189.85 8.10 1 035.23 44.91 4 761.83 203.23 62.79 638.42 ETH 221 0 15 277 240 1 990 1.80 0.81 8.09 4.05 50.89 30.50 258.89 158.51 46.34 1 017.05 LTC 219 1 691 6 80 0.78 2.03 1.68 25.51 16.70 230.09 55.53 489.41 6 357.33 2 171.42\n\nTABLEII: Liquidity Measure Correlations\n\nvwap1 rel. spread\n\nvwap5 rel. spread\n\nvwap10 rel. spread\n\nvwap25 rel. spread\n\nvwap50 rel. spread\n\nvwap1 rel. spread 1.00 0.77 0.64 0.57 0.37 vwap5 rel. spread 0.77 1.00 0.82 0.69 0.58 vwap10 rel. spread 0.64 0.82 1.00 0.81 0.67 vwap25 rel. spread 0.57 0.69 0.81 1.00 0.88 vwap50 rel. spread 0.37 0.58 0.67 0.88 1.00\n\n(a) Correlations between VWAP measures\n\nXLM(10k) XLM(100k)\n\nvwap1 rel. spread 0.45 0.17 vwap5 rel. spread 0.55 0.33 vwap10 rel. spread 0.54 0.34 vwap25 rel. spread 0.67 0.69 vwap50 rel. spread 0.60 0.75\n\n-100%\n\n-50%\n\n0%\n\n50%\n\n100%\n\n(b) Correlations between VWAP and XLM measures\n\nhave a similar meaning and change similarly. Nevertheless, we argue that XLM has a higher informative value because it directly re\ufb02ects the cost involved in buying a given quantity of a given asset.\n\nB. How does liquidity differ between different assets on different exchanges?\n\nTable I is showing yearly averages of VWAP and XLM mea- sures grouped by exchange and asset. Exchanges are ordered by their average trading volume according to CoinMarketCap. Binance has the highest, HitBtc comes second, and CEXIO last. We observe several differences between the exchanges and assets. First, we compare individual assets across exchanges to see if the liquidity of exchanges in general correlates with their trading volume. We can observe that asset VWAP spreads are smaller when exchanges have higher trading volumes. The only exception is LTC on HitBtc, where the spreads are lower\n\nthan on Binance. This is similar to the relative VWAP spreads, which tend to be higher on exchanges with lower trading volume, again except LTC, which is lower on HitBtc than on Binance. This could indicate that HitBtc\u2019s LTC is more liquid than Binance\u2019s. A look at XLM values does not support this assumption. When the trading volume of an exchange decreases, the XLM measures increase, indicating less liquidity. The question of which asset in our set is the most liquid is dif\ufb01cult to answer using VWAP measures. The spread is generally higher for assets with higher trading volume and market capitalization, which is likely due to the trading price, with the exception of Binance, where the spread of ETH is smaller than the spread of LTC. A comparison of the VWAP relative spread between assets on different exchanges does not show consistent behavior. On HitBtc, the relative spread is usually lower for assets with higher trading volume and higher market capitalization, which is consistent with the previous observations. On Binance it is similar, but the relative VWAP spread at level one is lowest for ETH. On CEXIO, ETH has the lowest relative spread, followed by BTC and LTC. In terms of XLM measure, BTC is usually the most liquid, followed by ETH and LTC. The only exception is Binance, where ETH is more liquid and the most liquid market in our set (Binance ETH- USDT) if you invest a smaller amount. It has an XLM(10 k ) value of 0.49, which means that the market impact for the so- called round trip (simultaneous purchase and sale of a position) of 10 000 USDT is 0.49. For an investment of 100 000 USDT , it would be 2.57 5 .\n\nC. Is the liquidity of different assets or exchanges independent of each other?\n\nIn contrast to the annual review, this section aims to provide a more detailed insight into the similarity of liquidity, in\n\n5 This is generally a low market impact. For instance, the XLM(25 k ) value of one of the most liquid stocks on the German Stock Exchange is 2.8. See https: //www.xetra.com/xetra-de/handel/marktquaelitaet/xlm-xetra-liquiditaetsmass\n\nTABLEIII: Asset Correlations using XLM(10k)\n\nBTCETH LTC\n\nBTC 1.00 0.44 0.30 ETH 0.44 1.00 0.48 LTC 0.30 0.48 1.00\n\n-100%\n\n-50%\n\n0%\n\n50%\n\n100%\n\n(a) Asset Correlations\n\nBTCETH LTC\n\nBTC 1.00 0.32 -0.08 Binance ETH 0.32 1.00 0.33 LTC -0.08 0.33 1.00\n\nBTC 1.00 0.68 0.54 HitBtc ETH 0.68 1.00 0.58 LTC 0.54 0.58 1.00\n\nBTC 1.00 0.33 0.15 CEXIOETH 0.33 1.00 0.27 LTC 0.15 0.27 1.00\n\n(b) Asset correlations separated by exchange\n\nBinance HitBtc CEXIO\n\nBinance 1.00 0.21 0.13 BTCHitBtc 0.21 1.00 0.23 CEXIO 0.13 0.23 1.00\n\nBinance 1.00 0.08 0.03 ETHHitBtc 0.08 1.00 0.15 CEXIO 0.03 0.15 1.00\n\nBinance 1.00 0.09 -0.03 LTCHitBtc 0.09 1.00 0.39 CEXIO -0.03 0.39 1.00\n\n(c) Correlations of assets between exchanges\n\nparticular, whether liquidity is correlated between assets and trading venues. To this end, we measure the Pearson correlation of the XLM(10 k ) measure, as we believe it has the best explanatory power of the calculated measures. Table IIIa shows the correlation of the XLM measure between all assets across the entire dataset. All show moderate correlation, with ETH and LTC being the most correlated at 0.48, followed by BTC and ETH at 0.44, and \ufb01nally BTC and LTC at 0.30. A breakdown by exchange provides a more detailed view, which can be seen in table IIIb and reveals different patterns. On HitBtc, there is a strong correlation of liquidity across all assets, with BTC - ETH having the highest correlation. On Binance, the correlation is mostly moderate, with BTC - LTC being the exception, showing almost no correlation. The assets on CEXIO mostly show a weak correlation, with BTC - ETH being the highest. Another angle on this matter is to see if, for example, the liquidity of an asset like BTC correlates with each other on different exchanges. As can be seen in table IIIc, assets show only a weak correlation between exchanges. The only exception is LTC, where there is a moderate correlation between HitBtc and CEXIO.\n\nD. Are there noticeable changes in liquidity throughout 2022?\n\nTo see how liquidity has changed over 2022, we created daily averages of the XLM(10 k ) measure for each asset on each exchange, which can be seen in Figure 1. The chart con\ufb01rms\n\nour previous \ufb01ndings that assets on Binance are generally more liquid, followed by HitBtc and then CEXIO. As an asset itself, LTC is always the least liquid. In general, BTC is the most liquid, but on Binance and CEXIO this is only true for the \ufb01rst seven months of the year, after which ETH becomes more liquid on Binance. On CEXIO, BTC and ETH alternate as the most liquid assets. Signi\ufb01cant changes in liquidity can also be seen over the course of 2022. Most assets saw a signi\ufb01cant drop in liquidity in May, most likely caused by the collapse of the Terra ecosystem. After the swings, almost all markets returned to their previous state, with the exception of LTC on CEXIO, which continued to \ufb02uctuate in a less liquid state. The collapse of the Terra ecosystem had far-reaching consequences and led to major players becoming insolvent around June. We can observe that this affects liquidity for most assets, with the exception of LTC on CEXIO. Again, liquidity returned to its previous state for the most part. In the months of July to October, liquidity on the various exchanges did not behave uniformly. For BTC and ETH, liquidity on Binance and CEXIO suddenly dropped, but then slowly rose again. HitBtc did not experience this spike, but another one around mid-September. Towards the end of the year, especially in November, all assets became more illiquid, most likely due to the FTX crash. Assets on Binance mostly recovered to earlier liquidity and became more liquid towards the end of the year. On HitBtc, liquidity remained mostly at the same level, while on CEXIO, liquidity remained similar for BTC, while ETH became more liquid.\n\nVI. DISCUSSION\n\nOur results show that there are differences in liquidity between assets on different exchanges and that the liquidity of exchanges is generally correlated with their trading volume. In addition, there is a moderate correlation in liquidity between different assets and exchanges and variation in liquidity between different assets on different exchanges. We would also like to emphasize the importance of understanding different measures of liquidity and their correlation with each other. Due to their higher explanatory power, we believe that XLM is a good option for measuring and interpreting liquidity. External events such as the Terra Luna crash and the FTX crash had a signi\ufb01cant impact on liquidity and the recovery time does not show consistent behavior. We would also like to point out that the limited number of assets and exchanges studied could pose a threat to validity. This also applies to the use of Tether as the only quote currency, as the study by Angerer et al. found that the choice of quote currency has an impact on liquidity [11]. Moreover, the XLM measure for LTC on CEXIO could not be calculated for each observation, so it can be assumed that the actual liquidity is worse.\n\nVII. CONCLUSIONS\n\nIn this study, we examined the liquidity of exchanges and assets and the impact of external events on centralized crypto exchanges over the course of 2022. We measured several measures of liquidity for nine different order books with three\n\n10 1\n\n10 0\n\n10 1\n\nBinance\n\n10 0\n\n10 1\n\nHitBtc\n\nBTCETH LTC\n\n2022-01 2022-03 2022-05 2022-07 2022-09 2022-11 2023-01\n\n10 1\n\n10 2\n\n10 3\n\n10 4\n\nCEXIO\n\nFig. 1: Daily averages of the XLM(10 k ) measure of BTC, ETH, and LTC divided by exchange.\n\ncurrency pairs on three exchanges and analyzed the resulting multivariate time series using correlation and time series plots. We \ufb01nd that there are differences in liquidity across assets on different exchanges and that the liquidity of exchanges is generally correlated with their trading volume. We found only a moderate correlation of liquidity between different assets and exchanges, and variation in liquidity between different assets on different exchanges during 2022. The study also found that external events such as the Terra Luna crash and the FTX crash had a signi\ufb01cant impact on liquidity, and the recovery time varied across assets and exchanges. We believe our results can help traders and investors make more informed decisions about investing in crypto exchanges. For future work, we plan to expand the number of assets and exchanges studied and examine the impact of different quote currencies on\n\nliquidity. In addition, correlations could also be time-shifted, which we will investigate with more appropriate measures. In general, future research could bene\ufb01t from learning more about liquidity in decentralized exchanges and how it compares to centralized exchanges. In addition, a comparative study of liquidity on crypto exchanges and traditional exchanges would be interesting.\n\nACKNOWLEDGMENT\n\nPart of this research work is supported by a PhD grant from the HPIResearch School for Service-Oriented Systems Engi- neering at the Hasso Plattner Institute for Digital Engineering, University of Potsdam. The funding is gratefully acknowledged.\n\nREFERENCES\n\n[1] Wolfgang Karl H \u00a8 ardle, Campbell RHarvey, and Raphael CG Reule. Understanding cryptocurrencies. Journal of Financial Econometrics , 18(2):181\u2013208, 2020.\n\n[2] Shaen Corbet, Brian Lucey, Andrew Urquhart, and Larisa Yarovaya. Cryptocurrencies as a \ufb01nancial asset: A systematic analysis. International Review of Financial Analysis , 62:182\u2013199, 2019.\n\n[3] Nicholas Rossolillo. Investing in cryptocurrency etfs: An in-depth look at the leading cryptocurrency etfs in the u.s stock market this year. here\u2019s what you need to know. 2023. URL : fool.com/investing/stock- market/market-sectors/\ufb01nancials/cryptocurrency-stocks/cryptocurrency- etf/.\n\n[4] Angelo Aspris, Sean Foley, Jiri Svec, and Leqi Wang. Decentralized exchanges: The \u201cwild west\u201d of cryptocurrency trading. International Review of Financial Analysis , 77:101845, 2021.\n\n[5] Francesca Cornelli and David Goldreich. Bookbuilding: How informative is the order book? The Journal of Finance , 58(4):1415\u20131443, 2003.\n\n[6] Elizabeth Napolitano and Brian Cheung. The ftx collapse, explained - wondering about the massive crypto debacle of ftx and its wunderkind former ceo sam bankman-fried? nbc news breaks down what happened and why it matters. 2022. URL : nbcnews.com/tech/crypto/sam-bankman- fried-crypto-ftx-collapse-explained-rcna57582.\n\n[7] Ekin Gen c\u00b8 Krisztian Sandor. The fall of terra: A timeline of the meteoric rise and crash of ust and luna - a detailed timeline of terra\u2019s journey from its underdog start as a payments app in south korea to a $ 60 billion crypto ecosystem to one of the biggest failures in crypto. 2022. URL : coindesk.com/learn/the-fall-of-terra-a-timeline-of-the-meteoric-rise- and-crash-of-ust-and-luna/.\n\n[8] Michael Aitken and Carole Comerton-Forde. How should liquidity be measured? Paci\ufb01c-Basin Finance Journal , 11(1):45\u201359, 2003.\n\n[9] Peter Gomber and Uwe Schweickert. The market impact-liquidity measure in electronic securities trading. Die Bank , 7(1):485\u2013489, 2002.\n\n[10] Anne H. Dyhrberg, Sean Foley, and Jiri Svec. How investible is bitcoin? analyzing the liquidity and transaction costs of bitcoin markets. Economics Letters , 171:140\u2013143, 2018.\n\n[11] Martin Angerer, Marius Gramlich, and Michael Hanke. Order book liquidity on crypto exchanges. In Proc. 3rd Crypto Asset Lab Conference , CAL \u201921. Crypto Asset Lab, 2021.\n\n[12] Alexander Brauneis, Roland Mestel, Ryan Riordan, and Erik Theissen. How to measure the liquidity of cryptocurrencies? Available at SSRN 3503507 , 2020.\n\n[13] Alexander Brauneis, Roland Mestel, Ryan Riordan, and Erik Theissen. Bitcoin unchained: Determinants of cryptocurrency exchange liquidity. Journal of Empirical Finance , 69:106\u2013122, 2022.\n\n[14] Craig WHolden, Stacey Jacobsen, Avanidhar Subrahmanyam, et al. The empirical analysis of liquidity. Foundations and Trends \u00ae in Finance , 8(4):263\u2013365, 2014."
    },
    {
        "number": 1570880759,
        "title": "Circulogy: An AI-enabled blockchain-based e-Waste management Framework using Non-Fungible Tokens (NFT) to achieve net zero and imply the circular economy",
        "abstract": "Overconsumption of resources is a global issue. To deal with resource depletion and mitigate impending crises, the circular economy (CE) solution provides an ecosystem by reducing waste by reusing, repairing, refurbishing, and recycling existing materials and products. However, as the complexity of supply chains is increasing, effective CE management is crucial. We want to address this issue by performing a feasibility study with AI-enabled blockchain technology using our developed customised NFT platform, TrackGenesis NFT, along with the OpenSea.io architecture for CE management to decrease transaction costs, enhance performance and communication along the supply chain, and reduce carbon footprints. Circulogy is an e-waste management system that can respond to supply chain challenges using blockchain technologies. A supply chain can get complicated very quickly. In our proposed solution, blockchain provides a solution by establishing transparency in every node of the product's lifecycle when users can exchange/sell/buy NFTs. In brief, it is a decentralised list of records or data, known as a block, connected using encryption technology which works in our developed blockchain platform. There are multiple copies of the audit trail for every transaction using blockchain, which will provide the ability to track and reuse/recycle Waste Electric and Electronic Equipment (WEEE).",
        "review": {
            "strength": [
                "This paper proposes a framework with technologies such as blockchain and NFT for the purpose of solving very crucial and  global problem that is to reduce e-waste by improving traceability, transparency and irreversibility of EEAs\u2019 lifecycle in the value chain.",
                "- interesting application with potential\n- the motivations are explained well\n- the paper is written in a style of a white paper rather than a technical research article",
                "Comprehensive overview of the blockchain platform for e-Waste management",
                "The framework presented in this paper consists of cutting-edge technologies such as blockchain and NFTs to address a critial and global issue: reducing e-waste by enhancing the traceability, transparency, and tracking the lifecycle of EEA products in the value chain."
            ],
            "shortcoming": [
                "1. The presentation and organization of this paper are very poor. This might hinder readers from understanding this work. For example, there are sections where the contents are not appropriately positioned, or where unnecessary content is added. In addition, this paper is short to be accepted as a full paper.\n2. The title of this paper is misleading. For example, although the 'AI' keyword is at the title, there is no mention of AI at all in the part that explains the design of the proposed framework in this paper.\n3. In the paper, other studies on blockchain-based e-waste management were introduced, and many studies on blockchain-based supply chain have been conducted so far. This paper does not mention what is different from previous studies. \n4. Overall, there is a lack of technical details on the proposed framework. Furthermore, this paper contains information on what can do, but does not include how to do it.",
                "- the technical contributions are minimal\n- the concept is nice, but there is little to show regarding specific design details, implementations, insights, etc. \n- the pitch for AI is weak. Unclear how it fits in.",
                "Lack of important details, including the proposed NFT platform, and AI component used. \n\nA number of grammatical and typographical errors found.",
                "- The organization and presentation of this paper are inadequate and may impede readers' comprehension. The placement of some sections is inappropriate, and extraneous content is included. \n\n- The title of this paper is misleading as it suggests the inclusion of AI, but the section describing the proposed framework does not contains the contents related to AI.\n\n- This paper includes the references of previous studies on blockchain-based e-waste management and supply chain management, but it fails to differentiate its approach from these earlier works.\n\n- This paper lacks sufficient technical details of the proposed framework."
            ],
            "comment": [
                "1. The authors need to rewrite Abstract focusing on the fundamental content of this paper. In particular, there is no need to introduce blockchain technology in Abstract.\n\n2. The authors insist that the existing CE and e-waste management services are ineffective in the Introduction section. However, it does not contain clear evidence to support the reasons why the authors mentioned this. This part needs to be clearer because it is an important part of expressing the problem statement of this work.\n\n3. The authors need to reconsider the benefits and challenges of the blockchain mentioned in the Literature review section. For example, \"More efficient payment\" is limited to public blockchain with its cryptocurrency. In addition, if \"security and privacy\" is a challenge, no one has to use blockchain.\n\n4. Among the features of NFT, \"Traceability\" and \"Product life cycle management\" seem to be some overlap.\n\n5. The description of technical contents is poor. For example, Ethereum has a low TPS and is a public blockchain, so it is impossible to solve on-chain problems when some errors arise, but there is no explanation for why it must be used as the framework\u2019s base network. In addition, there is no explanation of why OpenSea API is used. If NFT is created using OpenSea, information about assets is stored in OpenSea's smart contract, and the NFT smart contract cannot be customized.\n\n6. The authors wrote \u201cCreate the Ethereum block\u201d in this paper. How can the proposed framework produce blocks of Ethereum at will? Will they use a test network?\n\n7. A higher resolution of figures (1 and 2) would be nice. In addition, Figure 2 is not referred in this paper. The authors need to remove it or add the explanation to increase the reader\u2019s understanding.\n\n8. The scientific novelty presented in this paper includes characteristics of the technologies (e.g., blockchain and fog computing) used in the proposed framework. The authors need to focus on the novelty of this work itself.\n\n9. Some references are missing. For example, readers may not know about \u2018Recycle Now Brand Guides\u2019, \u2018Recycle Now National Recycling Campaign\u2019, or \u2018WRAP\u2019, so the authors need to add references to them.\n\n10. The explanation of DDP and EEA abbreviations should be mentioned in III, not IV.\n\n11. Conclusion is too long. It would be better that the authors rewrite it focusing on the core, results, and future work of this research. In addition, the content of IoT seems to be better to come from III and IV than to be located in Conclusion. Moreover, there is a lack of convincing the description that IoT will be easily integrated into CE.\n\n12. The authors need to carefully proofread this paper.\n- In page 2, \u201cThe scientific novelty of our proposed Framework:\u201d is used twice. \n- In page 4, According to the [18]~ -> ~ survey report, in 2021 [18], \n- In page 5, willenable -> will enable\n- \u2026",
                "This article reads like a whitepaper of a start-up rather than a technical paper. This is an excellent use case but the research questions need to be fleshed out significantly.",
                "The paper presents a work on AI-enabled blockchain-based e-waste management system using Non-Fungible Tokens (NFT), in order to enhance the effectiveness of Circular Economy (CE) implementation. A feasibility study was conducted using customized NFT platform that offers AI-enabled blockchain technology for keeping track of e-waste disposal and recycling. \n\nThe primary aim of the work presented is to digitize the CE implementation for Waste Electric and Electronic Equipment (WEEE).  \n\nIn general, the paper provides a good overview on how blockchain, in particular NFT is used to trace the electrical and electronic devices lifecycle, from their releases to the market, up until the time when these devices are to be disposed or recycled. The use of customized NFT platform known as TrackGenesis NFT was introduced.\nOn the downside, the paper lacks of details on the design of the NFT platform. Although the integration of TrackGenesis NFT with OpenSea was presented, the functional details of the NFT platform was not clearly explained. In addition, the AI component was not clearly discussed in this paper. \n\nThe contents of the paper is suitable for publication in this workshop. However, there is a need to revise the paper to include more details on the TrackGenesis platform. Perhaps a subsection on this topic should be provided.\n\nThe paper also need further revision for removing any grammatical and typographical errors.",
                "- The authors should revise the Abstract to focus on the core content of this paper. For example, remove the introduction of blockchain technology.\n\n-  The authors should explain why Ethereum and OpenSea API were chosen as the framework's base network and tool of creating NFTs, respectively.\n\n- The features of NFT, such as \"Traceability\" and \"Product life cycle management,\" appear to overlap.\n\n- The technical content of this paper should be better explained, including why Ethereum and OpenSea API were chosen as the framework's base network and tool of creating NFTs, respectively, and how the proposed framework can create blocks of Ethereum. In addition, Figure 2 should be removed or explained.\n\n- The authors should focus on the novelty of the work itself rather than the characteristics of the technologies used.\n\n- The Conclusion should be rewritten to focus on the summary, results, and future work of this research. The authors should remove IoT-related content from the Conclusion and add it to sections III and IV."
            ],
            "score": {
                "Relevance": 2.3,
                "Content and originality": 2.3,
                "Reference": 3.3,
                "Overall recommendation": 2.3,
                "Poster acceptance": 4.0
            }
        },
        "body": "I. INTRODUCTION\n\nGreenwashing has hindered the effectiveness of the UK recycling industry (BBCPanorama, March 2022)[1]. The successful UK government strategy for achieving net zero by 2050 is underlined by waste management, as waste sector emissions are primarily driven by the volume of residual waste from industry and consumers (CCC, 2020). Therefore, we aim to build a high-tech waste management solution with our\n\ndeveloped platform (i.e., blockchain technology), helping to reduce costs and enhance performance and communication along the supply chain. The project's outcome will help reduce carbon footprints with a blockchain-based Circular Economy (CE) [2].\n\nCurrently, overconsumption of resources is a global issue. E- waste management planning is necessary for the circular economy to respond to resource depletion and mitigate the impending waste crises in supply chain impacts.\n\nAlthough some CE management services and E-waste management services exist. Still, these are ineffective due to a lack of transparency, improper record keeping, inability to track product lifecycle fully, etc.\n\nII. LITERATURE REVIEW\n\nA. Blockchain Implementation in Supply Chain Management According to the Bank of England, blockchain is a technology that allows unknown people who do not know each other to trust a shared record of events. Furthermore, blockchain in supply chain management increases transparency and traceability of materials. This will reduce administration costs. Blockchain can be used to connect every stakeholder in the supply chain for information exchange[3]. Also, blockchain can replace traditional ERP (Enterprise Resource Planning) systems which will allow more integration and use of the more energy-efficient system [4]. This will also help in tracing errors better, and this will allow a complete, trustworthy and tamperproof audit in the supply chain. Benefits of blockchain in supply chain management:\n\n979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n\uf0a7 Increased traceability to ensure the standards are met. \uf0a7 Reduced losses due to counterfeit products. \uf0a7 Reduced paperwork and administration costs. \uf0a7 More ethical and sustainable sourcing. \uf0a7 CO2 emission reduction. \uf0a7 More efficient payments. \uf0a7 Better communication and collaboration. \uf0a7 Impact assessment and global governance tool.\n\nOn top of that, blockchain-based supply chain systems are becoming more in demand due to the customer\u2019s need to know the source of their products and whether they were made according to ethical standards[5]. Several companies such as Walmart, IBM, FedEx, Microsoft, Huawei and many more have adopted blockchain for supply chain management.\n\nB. NFT for Better Waste Management Besides, Non-Fungible tokens (NFT) technology can be used in e-waste management in a variety of ways: Traceability: NFTs can be used to establish a traceable chain of custody for e-waste, allowing stakeholders to track e-waste movement from collection to disposal [6]. This can be useful for ensuring regulatory compliance and monitoring the environmental impacts of e-waste management. Recycling incentives: By offering rewards or discounts to individuals or organizations that properly dispose of e-waste, NFTs can be used to incentivize recycling[7]. This could be accomplished by providing an individual or organization with an NFT that can be redeemed for a reward or discount. Product lifecycle management: NFTs can be used to track a product's lifecycle [8], from manufacture to disposal. This data can be used to improve product design and promote more sustainable consumption habits. Certifying recycled materials: NFTs can be used to certify the recycling of a material, ensuring that the material can be used in new products without additional processing. Carbon offsetting: NFTs can be used to offset the environmental impact of e-waste by creating a market for carbon credits. Reselling and repurpose: NFTs can be used to resell and repurpose e-waste, such as by establishing an NFT marketplace where people can buy, sell, and trade e-waste.\n\nC. Blockchain Implementation In E-Waste Management As the world moves towards a more technologically advanced lifestyle, the issue of e-waste is becoming increasingly detrimental. Electronic equipment and devices typically discarded can be repaired, reused or even resold. In fact, the global e-waste volume is anticipated to reach 75\n\nmillion tons by 2030 [9], which is nearly double the amount from current estimates.\n\nIII. PROPOSED FRAMEWORK\n\nIn our proposed system, we have used NFT enable consumer and other stakeholders to trace their e-waste. In addition, it will also provide commercial benefit to the consumer for rightly disposing the e-waste. In this system, when any producer produces the electronic product, a digital photo of the product will be taken and the device will also be given a number (e.g., something like IMEI number for mobile phone). Both the photo and the unique number will be used to create a NFT in the system which can be traced in the system. As blockchain provides the ability to verify the ownership, the consumer can be sure of the authenticity of product. When the consumer buys the product (electronic device), the ownership of the product will be changed and it will be recorded in the blockchain. If the buyer (consumer) dispose the devices in the designated drop points, they will be given credits which they can trade in the system. This provides motivation/incentive to the consumers to dispose the used devices in the appropriate dropping points. From the dropping points, the recyclers will collect the product and either refurbish them recycle them. The buyer and other stakeholders in the system can also trace the product through out its life cycle. To implement our system, we have proposed the folling framework:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFig. 1. High-level architecture of the TrackGenesis Platform integrating with OpenSea.io.\n\nCirculogy platform has simplified the NFT creation process for end users, which can be used to track and trace e-waste (e.g., laptops and mobile phones). This can also be utilized in the digital art submission into the trackgenesis platform. Needless to say, Opensea is one of the largest NFT and crypto collection marketplaces. Through opensea api trackgenesis process, the NFT allocation, as shown in the above figure 1 and using the Ethereum block for the NFT assets. Finally, OpenSea platform has been integrated with the Metamask wallet, as mentioned in the figure\n\n\n\n979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n\n\nFig. 2. Blockchain platform developed by TrackGenesis\n\nSteps are:\n\n\u2022 Upload assets to the TrackGenesis platform. -process the asset through opensea api \u2022 process with InterPlanetary File System (IPFS) and smart contract signature platform generate crypto metadata for blockchain. \u2022 sync metadata to a connected crypto wallet.\n\nIV. ANALYSIS ANDD ISCUSSIONS\n\nTherefore, our project can be a rapid solution to tackle this issue for digital assets and generate revenue and create a positive financial impact.\n\n\u2022 The electronic and electrical appliances\u2019 (EEAs) life cycle shall comply with the Waste Electric and Electronic Equipment (WEEE) Regulations 2013, which transpose the main provisions of Directive 2012/19/EU on WEEE.\n\n\u2022 The UK and EU standard-compliant data models for the DT system will be prepared to assist Circulogy CE stages and target WEEE recovery services with high data interoperability. The proof of concept of the presented procedures and system will be evaluated and validated during implementations in the DT cloud system.\n\nV. CONCLUSIONS\n\nTo sum up, approximately 50 million tonnes of electrical and electronic equipment waste (WEEE) is produced worldwide annually, a figure expected to increase by 2050 to 120m tonnes due to only a fifth of WEEE being recycled globally. Investigation about how circular economy (CE) has been adopted in the household electronic and electrical appliances (EEAs) industry indicated that little attention is devoted to circular product design practices where digital technologies\n\nsuch as big data, artificial intelligence (AI) and the Internet of Things (IoT) should be considered essential enablers of the CE. IoT can be most easily integrated into CE practices due to the: \u25cf New waste management strategies, aiding in the redesign, maintenance, upgrade and disassembling of the product- related data. \u25cf Improvement of the process\u2019s circularity level, optimising recycling and remanufacturing practices and allowing enhanced production control. \u25cf Implementation of smart industrial environments in Industry 4.0. We intend to automate the process with our bespoke Machine Learning (ML) algorithm of Circulogy to control system dynamics simulation modelling for household EEAs.\n\nACKNOWLEDGMENT\n\nThe project is funded by the Innovate UK. Authors are grateful for all sorts of supports provided by the funders.\n\nREFERENCES\n\n[1] What is greenwashing and how can you spot it? - CBBCNewsround . (n.d.). Retrieved January 23, 2023, from https://www.bbc.co.uk/newsround/58465027; https://www.youtube.com/watch?v=NOXy4zhe5Dc [2] Ferreira, I. A., Godina, R., Pinto, A., Pinto, P., & Carvalho, H. (2023). Boosting additive circular economy ecosystems using blockchain: An exploratory case study. Computers and Industrial Engineering , 175 . https://doi.org/10.1016/j.cie.2022.108916\n\n[3] Sunmola, F., & Burgess, P. (2023). Transparency by Design for Blockchain-Based Supply Chains. Procedia Computer Science , 217 , 1256\u20131265. https://doi.org/10.1016/J.PROCS.2022.12.324 [4] Xiao, P., Salleh, M. I., Zaidan, B. B., & Xuelan, Y. (2023). Research on risk assessment of blockchain-driven supply chain finance: A systematic review. Computers & Industrial Engineering , 176 , 108990. https://doi.org/10.1016/J.CIE.2023.108990 [5] Global e-waste generation outlook 2030 | Statista . (n.d.). Retrieved January 23, 2023, from https://www.statista.com/statistics/1067081/generation-electronic- waste-globally-forecast/ [6] Ke, J., Cai, K., Yuan, W., Li, J., & Song, Q. (2022). Promoting solid waste management and disposal through contingent valuation method: A review. Journal of Cleaner Production , 379 , 134696. https://doi.org/10.1016/J.JCLEPRO.2022.134696 [7] Baralla, G., Pinna, A., Tonelli, R., & Marchesi, M. (2023). Waste management: A comprehensive state of the art about the rise of blockchain technology. Computers in Industry , 145 , 103812. https://doi.org/10.1016/J.COMPIND.2022.103812 [8] Yu, H., & Wang, H. (2022). Elliptic curve threshold signature scheme for blockchain. Journal of Information Security and Applications , 70 , 103345. https://doi.org/10.1016/J.JISA.2022.103345 [9] Gupta, N., & Bedi, P. (2018). E-waste Management Using Blockchain based Smart Contracts. 2018 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2018 , 915\u2013921. https://doi.org/10.1109/ICACCI.2018.8554912"
    },
    {
        "number": 1570880764,
        "title": "ALT: Aggregate Liquidity Technology",
        "abstract": "Decentralized exchanges often need to combine liquidity from multiple sources in order to provide the best prices to their users. However, combining liquidity from multiple sources into a single trade has not only required high transaction fees, but is also computationally expensive. Here, we propose a framework for combining liquidity from multiple sources, called Aggregate Liquidity Technology (ALT). ALT maps each liquidity source onto a 2-dimensional space as a curve or line segment, where the input token is on one axis and the output token is on the other. Once this is accomplished, liquidity sources can be combined by finding the points where the curves or lines intersect. Users can get the optimal liquidity on each trade by maximizing the number of output tokens returned. ALT is implemented into Polkaswap on the Parity Substrate-based SORA network, which has processed more than $1 billion worth of token swaps. While the current iteration of ALT works only on a single blockchain network, future work should explore ways to combine liquidity using this methodology across multiple blockchain networks and even centralized exchanges.",
        "review": {
            "strength": [
                "- The author tries to address an important challenge (liquidity aggregation) of DEXs.\n- The proposed idea is already implemented and works in production.",
                "The article describes an algorithm that is using different alternative liquidity sources to achieve the best price for token swaps. The blockchain networks under analysis provide not only the traditional XYK liquidity pools for AMM exchange protocols (Automated Market Maker DEX), but also on token bonding curves and other liquidity sources. The latter might help to improve the exchange price by distributing the order volume between XYK pools and the token bonding curves buy function. Additionally, the article describes the scenario of using XOR Synthetics (XST) to increase available liquidity, and therefore again improve the final price.",
                "This paper shows well the necessity and efficiency of Aggregate Liquidity Technology (ALT).\nThe concept of ALT also explains well.",
                "This paper propose novel liquidity technology, ALT(Aggregate Liquidity Technology) that combines liquidity sources used in a token swap.\nTo find the best way to combine the sources, ALT compute the geometric intersections between 2-dimensional representations of the liquidity sources. ALT extends the existing AMM in an appropriate way and is a very useful technology for DEX."
            ],
            "shortcoming": [
                "- The key concept is clear. However, the manuscript does not provide detailed process of mapping liquidity sources onto a 2-dimensional space.\n- The author did not mention any related work in detail and explain how the proposed system is better and novel.\n- Equations and some figures are not clear to understand.",
                "The paper provides a summary of calculations for determining the split between liquidity sources.",
                "However, there is a lack of explanation of the benefits or consequences of using ALT afterwards.\nSection 3 states implementation of ALT using POLKASWAP, but that explanation is insufficient.",
                "This paper lacks an analysis of related work- introducing previous work on how to aggregate multiple liquidity sources, and presenting analysis results on the problems of the work presented in these paper."
            ],
            "comment": [
                "- Add some related work and compare them to the proposed system\n- How can we say that ALT is computationally efficient compared to other methods? \n- Please explain what x, y, x\u2019, and y\u2019 in the equations mean.\n- Please draw axises on the Fig.3.\n- Please explain a detailed process to map liquidity sources onto a 2-dimensional space.\n- Captions of some figures seem too long. Please reduce them and give explanations in the paragraphs.\n- There are some minor typos. Please proofread again carefully.",
                "However, there are several areas in which the paper could be improved. Firstly, it would be beneficial to provide more concrete evidence on the actual improvement that the ALT framework brings compared to fragmented XYK liquidity sources (the SORA network provides the opportunity for such modeling). Secondly, an analysis of the increase in computational costs associated with on-chain calculations for building a correct distribution and the implications for the final TCA (transaction cost analysis) would be useful. Here, on-chain specificity is important and traditional or CEX market frameworks cannot be applied. It would be interesting to discuss potential extensions of this model to Level 2 blockchain networks, CEX/Orderbook DEX liquidity in more details as it might drastically change the implementation approach, but the concept of 2-dimensional representation of liquidity pricing curves still might be used (at least for orderbook liquidity). Finally, given the existing implementation on the SORA network, the paper could explore the possibility of adapting this model for other L1 blockchain and DEX protocols, including EVM-compatible network.",
                "The implementation details of ALT using POLKASWAP in Section 3 is not sufficiently explained. \nAlso, application field or examples that go with ALT need to be mentioned and explained. \n\ntypo: in the sentence \"first the Equation 1 sows the XYK liquidity pool change equation\", change sows to shows",
                "This paper lacks an analysis of related work- introducing previous work on how to aggregate multiple liquidity sources, and presenting analysis results on the problems of the work presented in these paper."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 3.0,
                "Reference": 3.3,
                "Overall recommendation": 3.0,
                "Poster acceptance": 3.8
            }
        },
        "body": "I. INTRODUCTION ANDR ELATEDW ORK\n\nCentralized exchanges (CEXs) have facilitated early adop- tion and value creation for cryptocurrencies during their nascency, through linking cryptocurrency economies to tra- ditional \ufb01at economies. However, challenges such as hacking [1]\u2013[3], wash trading [4], using customer funds [5], price ma- nipulation [6], and regulatory action by government agencies [7] due to their centralized control have become major issues in the cryptocurrency industry. For these reasons, alternatives to CEXs, namely decentralized exchanges (or, DEXs), have received considerable use and attention, as well as market traction. DEXs address many of the shortcomings of CEXs: they are not vulnerable to inside-jobs or hacking (if programmed correctly), provide transparency into trades so that wash- trading can be observed, are self-custodied so that users hold their own funds, and are censorship resistant, especially against government intervention because DEXs do not have logic that is executed on centralized servers. DEXs have become impor- tant infrastructure on many blockchain networks, enabling the exchange of values through decentralized networks and thus facilitating access to Decentralized Finance (DeFi) [8].\n\nThanks to the SORA (https://sora.org) ecosystem for funding this research.\n\nDEXs are liquidity market places where users trade tokens with each other directly, by interacting with each other via transacting on a blockchain network (so-called on-chain in- teraction). DEXs themselves can be considered as two broad categories: 1) order-book DEXs and 2) Automated Market Maker (AMM) DEXs. Order-book DEXs often have had off-chain components that aggregate bid and ask orders, though some fully on-chain solutions exist. However, on-chain order-book DEXs, such as implemented in NXT in 2014, had very little use due to poor liquidity. XYKConstant Product Automated Market Maker (AMM) DEXs [9] are liquidity market places where users provide liquidity to given token pairs, based on the x \u2217 y = k constant product formula, where x is a blockchain-based token of one type and y is some other token. Blockchain-based tokens can represent a variety of assets, such as cryptocurrencies, utility tokens, divisible NFTs, tokenized commodities, or any other arbitrary asset or object that users want to represent with a token. Because all swaps into XYK liquidity pools maintain the constant product, k , swapping a number of x tokens will yield a number of y tokens such that after the swap, the liquidity pool has x \u2032 and y \u2032 numbers of tokens such that the constant product invariant is maintained and x \u2032 \u2217 y \u2032 = k . Liquidity is the capability of a person to convert any asset into another asset, affecting the price of the asset as little as possible (i.e., the more liquidity, the lower the price change in the assets being swapped). In the early days of DEXs, having suf\ufb01cient liquidity to have a good trading experience was dif\ufb01cult due to the low amount of users and volume. The \ufb01rst popular decentralized exchange, IDEX, was launched in 2017, and was an order-book DEX. However, the annual trading volume was less than $5 million at \ufb01rst and could not really be described as facilitating trades with high liquidity. Between 2018 and the 2020 Summer of DeFi , DEXs experienced a turnaround in growth, leading AMMDEXs to surpass order- book DEXs like IDEX to assume a total market share in cryptocurrency volume of approximately 5% in 2020 and 10% in early 2023 1 . Notably, Uniswap [10] was the \ufb01rst popular\n\n1 Measured on January 22, 2023 at https://coinmarketcap.com/rankings/ exchanges/. On that date, the top 20 CEXs, ranked by CoinMarketCap\u2019s Spot Exchange Score reported 24-hr volume of $33,396,504,529, while the top 20 DEXs reported 24-hr volume of $3,454,015,060, or 10.34% of the top-20 CEX volume 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nAMMDEX and even in early 2023, is still the second most popular DEX (after DXDY). However, DEXs face many technological dif\ufb01culties. For one, to process all transactions on-chain is very computation- ally intensive and is associated with high costs. Additionally, liquidity can also be fragmented across DEXs, even on the same blockchain network. 1inch is a popular DEX aggregator that combines liquidity from multiple sources and has been shown to provide better trade results than using single liquidity sources [11]. 1inch allows users to execute transactions on the smart contracts of multiple exchanges, splitting their trades across multiple DEXs such that the liquidity is combined and users get more output tokens for their input tokens. However, this method of executing transactions across multiple DEX smart contracts requires a large amount of gas, making 1inch cost prohibitive to use for small valued token swaps. To create a more ef\ufb01cient framework for combining liquidity across multiple sources on the same blockchain, with respect to computational ef\ufb01ciency and swap liquidity, we propose Aggregate Liquidity Technology.\n\nII. AGGREGATE LIQUIDITY TECHNOLOGY (ALT)\n\nLiquidity aggregators combine liquidity from multiple sources in order to provide economically ef\ufb01cient token swaps from a given input asset to an output asset. When inte- grated into a DEX, a liquidity aggregator collects liquidity from different sources and ensures that the used liquidity is combined in an optimal, or nearly optimal way. This is the case of parallel composition in [12], where multiple AMM liquidity sources exist, but traders want to treat them as if they were a single, combined source. This increases the effective liquidity of a DEX, by using the liquidity from multiple sources. Aggregation of liquidity can make a large impact for investors who swap large amounts of tokens in a single order, as liquidity aggregation can reduce price slippage. While there are many ways to possibly aggregate liq- uidity across multiple sources, to focus on economic and computational ef\ufb01ciency, we propose the Aggregate Liquidity Technology, or ALT, framework. By economic ef\ufb01ciency, we mean that swaps are executed such that available liquidity sources are combined in an optimal way so that users get the maximum number of output tokens for a given amount of input tokens; for example, if a user swaps from 1000 DAI 2\n\nto XOR 3 , they should get the largest amount of XOR tokens possible for their 1000 DAI. By computational ef\ufb01ciency, we mean that the solution to combine liquidity sources needs to be very fast to compute, given that all the processing should be done only on-chain, without off-chain computation. ALT achieves economic and computational ef\ufb01ciencies by mapping liquidity sources as curves and line segments onto a 2-dimensional space and then calculating the share of input tokens across liquidity sources by \ufb01nding the intersections\n\n2 DAI is a USD-pegged stablecoin. 3 XOR is the native token of the SORA network.\n\nXOR\n\nDAI\n\nxy=k=x\u2019y\u2019\n\nA\u2019\n\ny\u2019\n\nx\u2019 x\n\ny A\n\nFig. 1: XYKConstant Product AMMDEXs (such as Uniswap [10] or Polkaswap) swap tokens on an x \u2217 y = k curve such that the constant, k , stays the same. This has the effect that any in\ufb02ow of token x necessitates an out\ufb02ow of token y to maintain the constant product (or vice versa). For example, inputting DAI in a XOR-DAI liquidity pool, will return some amount of XOR such that x \u2032 \u2217 y \u2032 = k .\n\nof the curves and lines. On the x -axis of the 2-dimensional space is the quantity of one of the tokens to be traded and on the y -axis is the quantity of the other token to be traded, and the curves and lines on the 2-dimensional space represent functions where token conversions can happen (i.e., tokens trade for known values and AMM liquidity sources and limit orders provide amounts of tokens for sale, denominated in amounts of another token). The main target of ALT is integration into constant-product AMMDEXs. Recall that x \u2217 y = k is a curve (as shown in Figure 1; note, we only care about positive values for x and y when discussing token amounts) and that constant product AMMDEXs always trade along this curve to calculate the output number of tokens for a given input amount. This feature of AMMDEXs makes them a great target for liquidity aggregation using ALT because different liquidity sources, such as XYK liquidity pools, can be mapped onto the same 2D space and then combined. For example, if there are 2 DEXs on the same blockchain network that both have XOR-DAI liquidity pools, then it is possible to map both of the XYK curves onto the same pair of axes and then determine the ratio of input tokens that should go into each of the pools in order to maximize the amount of tokens returned to the user. With ALT, liquidity sources can be liquidity pools on multiple DEXs on the same blockchain network or be other types of functions that provide liquidity, such as token bonding\n\ncurves or synthetic assets. Section III will explore the details of how ALT can is used in real-world scenarios. We implemented the ALT framework into Polkaswap, an open-source DEX for the Polkadot and Kusama ecosystems. On Polkaswap, multiple liquidity sources can be implemented under a liquidity aggregation algorithm. In the current imple- mentation, all liquidity sources should be on the same layer 1 (L1) blockchain network. Sources of liquidity in Polkaswap are currently XYK liquidity pools, a multi-collateral token bonding curve (TBC), and a synthetic asset system, but in the future order books are also planned to be supported.\n\nIII. IMPLEMENTATION OFALT INP OLKASWAP\n\nPolkaswap (https://polkaswap.io) is a DEX built as Rust pallets using the Parity Substrate blockchain framework, on the SORA (https://sora.org) L1 blockchain network [13]. As of January 24, 2023, Polkaswap has processed more than $1 billion across more than 2 million token swaps 4 since launch in April 2021. Polkaswap is a DEX designed for the Polkadot and Kusama ecosystems. The Polkadot and Kusama ecosys- tems offer several advantages over EVM-based networks like Ethereum, including heterogeneous sharding, shared secu- rity, runtime upgradeability, and cross-chain message-passing (XCM). Parity Substrate, which is used by Polkadot and Kusama, as well as the SORA network, is highly performant compared to EVM and building decentralized apps (dApps) using the pallet framework in Substrate allows for complex applications that would be infeasible to implement in Solidity code for EVM. We have been contributing to the Polkaswap codebase 5\n\nsince 2020, and the initial development was funded by a Web3 Foundation grant. Polkaswap has many innovative features, including the integration of ALT, which aggregates liquidity across all available liquidity sources on the SORA network for a given token pair; this is called the SMART market algorithm on the https://polkaswap.io user interface. Another innovation that is built into Polkaswap is the SORA token bonding curve (Figure 2). The SORA token bonding curve is the primary market for the XOR token and will mint new XOR when users buy from the buy-price function of the token bonding curve, and will burn XOR when users sell their XOR into the sell-price function, returning collateral assets. Collateral tokens that are accepted by the buy-price function as of March 2023, are ETH, DAI, TBCD, VAL, PSWAP, and XST. Users who input any of these into the buy-price function give the collateral tokens to the token bonding curve dApp, which holds them as reserves. There\u2019s a 20% margin between the buy-price function and the ideal sell-price function, which allows the SORA ecosystem to have some seignorage pro\ufb01t on the minted XOR. Because the buy-price function is able to mint new XOR, it is in\ufb01nitely liquid and is de\ufb01ned as a straight line with a \ufb01xed slope. In the ideal case, the sell-price function\n\n4 See https://sora.subscan.io to explore transactions on the SORA network and https://sora.subscan.io/extrinsic?module=liquidityproxy&call= swap&result=success to view token swaps on Polkaswap. 5 https://github.com/sora-xor/sora2-network\n\nBuy-Price Function\n\nThe area of this surface is the di\ufb00erence between ideal and actual reserves\n\nMargin 20%\n\nToken Bonding Curve Reserves\n\nIdeal Sell-Price Function\n\nA c t u a l\n\nS el l - P\n\nr i ce\n\nF u n\n\nct i o\n\nn\n\nUSDPrice\n\nAmount of XOR in Circulation\n\nFig. 2: The SORA token bonding curve is the primary market maker to buy and sell XOR. The token bonding curve is a dApp on the SORA network and is de\ufb01ned by a buy-price function and sell-price function. The token bonding curve is integrated into Polkaswap trading via implementation of the ALT framework, for all trades between XOR and DAI, ETH, TBCD, VAL, PSWAP, and XST.\n\nis also a straight line, but in reality the collateral tokens held by the token bonding curve \ufb02uctuate in value and it is likely that suf\ufb01cient reserves are not held by the token bonding curve. Therefore the actual sell-price function of the token bonding curve will fallback to a curve that mimics an XYK constant product function when selling reserves for XOR. The token bonding curve acts as a liquidity source in parallel to XYK liquidity pools on Polkaswap. Because there are multiple liquidity sources available on Polkaswap when users are trading XOR-ETH, XOR-DAI, XOR-TBCD, XOR-VAL, XOR-PSWAP, and XOR-XST, combining token bonding curve and XYK liquidity pools in single token swaps are a good example of the bene\ufb01t of using ALT. This is shown in Figure 3 for the case where users are buying XOR using DAI, one of the collateral assets of the token bonding curve. In this \ufb01gure, the y -axis is DAI and the x -axis is XOR, with the secondary market (XYK pool) and primary market (token bonding curve) functions shown. In this example, to \ufb01ll an order using the input token DAI, a portion of the trade is \ufb01lled in the secondary market for XOR (XOR-DAIXYK liquidity pool) until the\n\nPrimary Market Buy\n\nToken Bonding Curve Buy-Price Function\n\nSe\n\nc o\n\nn d\n\na r\n\ny\n\nM\n\na r\n\nk e\n\nt B\n\nu y\n\nDAI\n\nXOR\n\n(x\u2019, y\u2019)\n\nFig. 3: Combining the token bonding curve liquidity and XYK liquidity pool together in the same buy order for XOR using ALT.\n\nXYK curve intersects at ( x \u2032 , y \u2032 ) with the line of the XOR primary market, de\ufb01ned by the buy-price function of the token bonding curve. Here we consider the case of buying XOR with DAI, but this is the same for all token pairs that have multiple liquidity sources. To calculate the split between the primary and secondary market liquidity sources in this example, \ufb01rst Equation 1 shows the XYK (secondary market) liquidity pool equation after some input of tokens is done to get to the new point, ( x \u2032 , y \u2032 ) along the XYK curve:\n\nx \u2032 \u2217 y \u2032 = k (1)\n\nThen we de\ufb01ne the equation for \ufb01nding the amount of change in the XYK liquidity pool to get up to the desired price, p , which is the current price in DAI of the XOR primary market (i.e., the current price of the token bonding curve\u2019s buy function). This is shown in Equation 2 (amount of DAI per XOR in our example):\n\np = y \u2032\n\nx \u2032 (2)\n\nComposing Equations 1 and 2, we get:\n\n( y \u2032 ) 2 = k \u2217 p (3)\n\nwhich we can then solve for y \u2032 (both the constant k and token bonding curve buy-price p are known):\n\ny \u2032 = \u221a\n\nk \u2217 p (4)\n\ny \u2032 is the y-intercept between the primary and secondary markets for XOR and we can trivially solve for x \u2032 as well:\n\nx \u2032 = k \u221a k \u2217 p, (5)\n\nIn the case of buying XOR with DAI, we want to know the amount of DAI to input into the secondary market. y in , the number of tokens that are input to the secondary market is then:\n\ny in = y \u2032 \u2212 y, (6)\n\nwhere y is the starting point on the y -axis on the AMM curve of the secondary market. The input into the primary market (i.e., the token bonding curve\u2019s buy function) is then the remaining amount of tokens. If, for example, there are 1000 DAI to buy XOR with and y in is 800, then 800 DAI will be swapped in the XYK liquidity pool and 200 DAI will be input into the token bonding curve\u2019s buy function. In the ALT implementation in Polkaswap, this is done atomically in a single transaction that splits the liquidity between the sources. For the case of selling XOR for one of the reserve assets of the token bonding curve (e.g., DAI; Figure 4), the math to \ufb01nd the intercept point is very similar (the only difference is that instead of moving up on the XYK curve, we are moving down, so the signs are \ufb02ipped when calculating y in . However, because it is often the case that there are not suf\ufb01cient reserves in the token bonding curve to return an ideal amount of tokens for input XOR, the token bonding curve approximates an XYK constant product function instead of a straight line. This is shown in Figure 4 (b), where the token bonding curve acts like an XYK liquidity pool when selling. What this means is that the token bonding curve\u2019s sell function, rather than being a straight line, is an x \u2217 y = k function, where x is the total amount of XOR (the token issued by the token bonding curve) in circulation, y is the \u201cimagined\u201d reserves of equal DAI value, and k is the constant product of multiplying these numbers. In this case too, there may be insuf\ufb01cient reserves, so the token bonding curve does a best-effort at returning reserves using this XYK model until they run out. In addition to using XYK liquidity pools and the token bonding curve as liquidity sources, Polkaswap also has a SORASynthetics (XST) liquidity source. This is used to manage an algorithmic stablecoin pegged to the USD called XSTUSD. XSTUSD can be minted by burning XST and burning XSTUSD mints an equivalent amount of XST. There- fore, this liquidity source acts much like the token bonding curve\u2019s buy function, as it can be represented as a straight line and is in\ufb01nitely liquid. For combining XYK liquidity pools and the XSTUSD liquidity source when swapping XSTUSD- XST, ALT works as shown in Figure 5. The math here is exactly the same as shown in Equations 1-6 for calculating the intersection point between the XYK liquidity pools and the XSTUSD liquidity source; only this time the XSTUSD liquidity source has a no slope and outputs a constant price,\n\nIdeal\n\nSell-Price Function\n\nBuy-Price Function\n\nXORBought with TBCReserves\n\nSecondary Market\n\n(a) Token Bonding Curve Ideal Sell-Price Function\n\nActual\n\nSell-Price Function\n\nBuy-Price Function\n\nXORBought with TBCReserves\n\nSecondary Market\n\nPrimary Market\n\n(b) Token Bonding Curve Actual Sell-Price Function\n\nFig. 4: Combining the token bonding curve liquidity and XYK liquidity pool together in the same sell order for XOR using ALT, in: (a) the theoretically ideal case where the token bonding curve has full reserves and (b) the actual case where the token bonding curve has insuf\ufb01cient reserves to fully back all XOR tokens in circulation at the target price level de\ufb01ned by the sell-price function.\n\nXSTUSDPrimary Market Maker\n\nSecondary Market (XSTUSD-XSTPool)\n\nPrice in DAI\n\n$1\n\nFig. 5: The SORASynthetics liquidity source, as implemented for the XSTUSD-XST trading pair.\n\nwhereas the token bonding curve settings have a slope value, and the convertibility is with the XST token and not XOR. Taken together, these examples show how ALT is enabled in Polkaswap. Over two million token swaps have been processed on Polkaswap, which implements this methodology, and it has worked in production since 2021, thus showing the ef\ufb01cacy of the ALT framework for quickly combining liquidity across multiple liquidity sources that exist on the same blockchain network. Generalizing beyond Polkaswap, the ALT framework can be used for combining multiple liquidity sources of the same two (input and output) tokens. First, each liquidity source must be mapped into a 2-dimensional space, where one is represented on the x -axis and the other on the y -axis, with a curve or line de\ufb01ning the token convertibility function in two dimensions. Limit orders in order books can be represented in this framework as line segments, with the y -value of the limit order being the price and length of the line-segment representing the liquidity (i.e., size of the order), but the speci\ufb01c implementation of limit orders in ALT are a topic for near-term future work.\n\nIV. CONCLUSIONS\n\nDEXs are key part of DeFi infrastructure, yet many DEXs only focus on liquidity within their own liquidity pools or order books and ignore other sources that exist. Partly this is because of computational concerns, as DEXs should process all logic on-chain, which can be slow and costly, depending on the implementation. To provide an ef\ufb01cient framework for combining liquidity sources on the same blockchain network, we propose Aggregate Liquidity Technology, or ALT. ALT combines liquidity sources used in a token swap by computing the geometric intersections between 2-dimensional representa- tions of the liquidity sources to \ufb01nd the best way to combine the sources to maximize the amount of output tokens returned to a user. ALT has been implemented in production in Polkaswap, a DEX on the SORA network that is programmed using Parity Substrate Pallets in the rust language and compiled to a WASM runtime. The SORA network provides a good showcase for how the ALT framework can be useful in real- world DEXs, as in addition to Polkaswap liquidity pools, the SORA network also implements exotic liquidity sources such as a token bonding curve and a synthetic, algorithmic stablecoin. Combining these varied liquidity source types has already been accomplished and millions of transactions have been processed by users of the SORA network.\n\nV. FUTURE WORK\n\nDecentralized apps on blockchain networks face many con- straints and there are ample directions for future work that can build on and improve the ALT framework. First, adding order book support in ALT can be done by representing bids and asks as 2-dimensional curves or groups of line segments, and combining them with other liquidity sources as we showed in this contribution. This should be\n\npossible to do in a computationally ef\ufb01cient manner, but has not been implemented yet. Second, standalone L1 blockchain network DEXs have fought liquidity wars in the past, such as the \u201cvampire attack\u201d [14] that Sushiswap did against Uniswap, to take liquidity from others for their trading platform. A framework like ALT may make such attacks obsolete, as DEXs on the same L1 network can implement ALT to trade with multiple liquidity sources in a way that is transparent to their users, similarly to how Polkaswap is implemented, but combining even more liquidity pools and other sources. Sources of liquidity that exist on other L1 blockchain networks or L2 networks should be combined with the ALT framework as well. This is not trivial to accomplish because different networks have different concepts of transaction \ufb01- nality. However, developing a method for combining these liquidity sources into a single source that users can trade into is an important direction for future work. Finally, integrating liquidity on CEXs with DEX liquidity via the ALT framework is also needed in order to combine all possible liquidity sources. This has many regulatory hurdles, but may be possible within some well-de\ufb01ned groups of users. By accomplishing all these directions for future work, realizing the dream of a global order book that unites all liquidity sources may become achievable.\n\nACKNOWLEDGMENT\n\nThis work is funded in part by SORA (https://sora.org) ecosystem development grants.\n\nREFERENCES\n\n[1] S. Corbet, D. J. Cumming, B. M. Lucey, M. Peat, and S. A. Vigne, \u201cThe destabilising effects of cryptocurrency cybercriminality,\u201d Economics Letters , vol. 191, p. 108741, 2020. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0165176519303714\n\n[2] B. Charoenwong and M. Bernardi, \u201cA decade of cryptocurrency \u2018 hacks \u2019 : 2011\u20132021,\u201d Available at SSRN https://ssrn.com/abstract=3944435 , 2021. [Online]. Available: https://ssrn.com/abstract=3944435\n\n[3] G. Milunovich and S. A. Lee, \u201cMeasuring the impact of digital exchange cyberattacks on bitcoin returns,\u201d Economics Letters , vol. 221, p. 110893, 2022. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S0165176522003676\n\n[4] G. L. Pennec, I. Fiedler, and L. Ante, \u201cWash trading at cryptocurrency exchanges,\u201d Finance Research Letters , vol. 43, p. 101982, 2021. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S1544612321000635\n\n[5] M. Aquilina, J. Frost, and A. Schrimpf, \u201cAddressing the risks in crypto: laying out the options,\u201d BISBulletin , 2023.\n\n[6] F. Eigelshoven, A. Ullrich, and D. A. Parry, \u201cCryptocurrency market ma- nipulation: A systematic literature review,\u201d in International Conference on Information Systems , 2021.\n\n[7] B. D. Feinstein and K. Werbach, \u201cThe impact of cryptocurrency regula- tion on trading markets,\u201d Journal of Financial Regulation , vol. 7, no. 1, pp. 48\u201399, 2021.\n\n[8] D. A. Zetzsche, D. W. Arner, and R. P. Buckley, \u201cDecentralized \ufb01nance,\u201d Journal of Financial Regulation , vol. 6, no. 2, pp. 172\u2013203, 2020.\n\n[9] A. Lehar and C. A. Parlour, \u201cDecentralized exchanges,\u201d Available at SSRN 3905316 , 2021. [Online]. Available: https://ssrn.com/abstract= 3905316\n\n[10] Y. Lo and F. Medda, \u201cUniswap and the rise of the decentralized exchange,\u201d University Library of Munich, Germany, MPRAPaper 103925, Nov. 2020. [Online]. Available: https://ideas.repec.org/p/pra/ mprapa/103925.html\n\n[11] N. Boonpeam, W. Werapun, and T. Karode, \u201cThe arbitrage system on decentralized exchanges,\u201d in 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON) . IEEE, 2021, pp. 768\u2013771.\n\n[12] D. Engel and M. Herlihy, \u201cComposing networks of automated market makers,\u201d in Proceedings of the 3rd ACMConference on Advances in Financial Technologies , ser. AFT \u201921. New York, NY, USA: Association for Computing Machinery, 2021, pp. 15\u201328. [Online]. Available: https://doi.org/10.1145/3479722.3480987\n\n[13] M. Takemiya, \u201cSora: A decentralized autonomous economy,\u201d in 2019 IEEEInternational Conference on Blockchain and Cryptocurrency (ICBC) , 2019, pp. 95\u201398.\n\n[14] I. Makarov and A. Schoar, \u201cCryptocurrencies and decentralized \ufb01nance (de\ufb01),\u201d National Bureau of Economic Research, Tech. Rep., 2022."
    },
    {
        "number": 1570880790,
        "title": "Decentralized Exchanges: The Profitability Frontier of Constant Product Market Makers",
        "abstract": "In this paper we analyze constant product market makers (CPMMs). We formalize the liquidity providers' profitability conditions and introduce a concept we call the profitability frontier in the xyk-space. We study the effect of mint and burn fees on the profitability frontier, consider various pool types, and compile a large data set from all Uniswap V2 transactions. We use this data to further study our theoretical framework and the profitability conditions. We show how the profitability of liquidity provision is severely affected by the costs of mint and burn events relative to the portfolio size and the characteristics of the trading pair.",
        "review": {
            "strength": [
                "- The paper proposes a profitability frontier by reflecting network fee, transaction fee, etc., and proves it mathematically.\n- Profitability is well-visualized to show what the paper suggests",
                "This paper analyses the profitability regions under different conditions, e.g. with/without Ethereum network fees, for the liquid providers in the constant product market makers based decentralised exchanges. Both theoretical and experimental analyses are provided.",
                "It visualizes the profitability boundary for CPMM (an AMM method). I am not very familiar with this field of work, but it seems like a part of backtesting (considering size, fee and appropriate moment of closing position). \n\nIt has provided some backups with the empirical analysis using the real dataset.",
                "- This paper analyzes the Continuous Product Market Maker (CPMMS).\n- It formulated the profitability conditions for liquidity providers and introduced the concept of a profitability frontier in the XYK space.\n- We also compiled a large data set from all Uniswap V2 trades, compiling the effect of mint and burn fees on the profitability front tier, considering the different overall types.\n- This data was used to further study the theoretical framework and profitability conditions.\n- It shows how the profitability of liquidity provisions is severely affected by the cost of mint and burn events relative to the size of the portfolio and the nature of the trading pairs."
            ],
            "shortcoming": [
                "- Related work is well presented, but differences from previous studies are not well-explained.\n- Lack of future works",
                "The theoretical analysis needs more details to clarify the meaning of the notations and how the equations are derived.",
                "How is this work different from the related work mentioned? Like [27, 28]. LP analysis on many AMM schemes has been made before. I am not quite sure that the analysis technique here has shown a significant difference (other than visualization and empirical analysis)",
                "- It is judged that it would be better if the basis for the expected contents in the empirical analysis part was presented together.\n- It is judged that it would be better if the standards for small, medium, and large liquidity position sizes are presented together."
            ],
            "comment": [
                "- Related work is well presented, but differences from previous studies are not well-explained. It would be good to clarify the differences from related works and to highlight what kind of novelty this paper has.\n- In case 4 of the section explaining formal LP profitability, it would be helpful to add an explanation of symbol (\ud835\udc43_1 )\u00a0\u0305 and another. \n- In conclusion, \"The paper provides a novel analytical framework to study LP pro\ufb01tability and highlights the importance of layer 2The part ending with \"deployments and improvements to the token approval process.\" does not seem to be related to the main text. It would be nice to add a further explanation.",
                "The second paragraph in Section II (Related work) does not provide any meaningful information instead of listing of all the related works. \n\nThe last paragraph in Section II needs to clarify the difference between this paper and the existing work, what have not been covered by the related works. \n\nThe meaning of the notations in Equation (5) & (6) is not clear. If someone holds certain amount of token of x and y, should the amount be the same no matter the ratio between x and y? What are the meaning of the starting and the ending points? \n\nIn relation to the 4 cases in Section IV, is it possible that k_0 > k_1, and why?\n\nWhile considering the effects of mint / burn fee on the profitability (Section IV.A IV.B), e.g. Equation (11) & (14), why should the fee be proportional to the x and y? Should the fee roughly be a constant value (as specified by the Ethereum transaction sender)?",
                "(Again, I am probably not qualified for reviewing this paper properly).\n\nMany of the notations in page 2 (Framework) are conventional analogy from the popular AMM papers. Isn't it? Yet I don't mind seeing repeated here.  \n\nI am also not very clear on the part how the liquidity position size and fee are taken into simulation here (page 4, regarding Table I). Usually in spot trading simulation (backtesting for algorithmic trading), position size is limited to the entire volume of the market as well as the size of order book level. So the position size variation given in this paper might not show a significant impact in overall. It may just become a simple number multiplication. \n\nWill this analysis be realistic in algorithmic trading for DEX? Can you elaborate a little bit?",
                "- It is judged that it would be better if the basis for the expected contents in the empirical analysis part was presented together.\n- It is judged that it would be better if the standards for small, medium, and large liquidity position sizes are presented together."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 3.0,
                "Reference": 3.0,
                "Overall recommendation": 3.3,
                "Poster acceptance": 3.5
            }
        },
        "body": "I. INTRODUCTION\n\nConstant product market makers (CPMM) are smart\n\ncontract-based liquidity pools that contain two distinct assets. They serve as neutral exchange infrastructure and employ an endogenous pricing model, based on the proportion of their token reserves. Generally speaking, the greater a CPMM\u2019s reserve of token x in relation to the CPMM\u2019s reserve of token y , the higher the relative price of token y .\n\nAnyone can become a liquidity provider (LP) by\n\ncontributing tokens to the pool contract in line with the current pool ratio. They can later redeem their share and close their position by withdrawing their proportional stake of the pool\u2019s liquidity. LPs essen- tially act as passive market makers. Their allocation (i.e., ratio between x and y token holdings) changes whenever anyone performs a swap using the CPMM. To compensate LPs for their opportunity costs and the risks of passive market making, they earn a portion of the trading fees.\n\nIn this paper we take a closer look at these effects\n\nand analyze the pro\ufb01tability of CPMMLPs. In Sections II and III we lay the foundation by summarizing related\n\nliterature and introducing the formal framework for our analysis. In Section IV we propose a concept we call the pro\ufb01tability frontier in the xyk -space and study the effects of mint and burn fees. Moreover, we consider the effects of various pool types. In Section V we provide empirical evidence from Uniswap V2 pools and show how relative fee size and pool type affect the pro\ufb01tability conditions. In Section VI we discuss our results and conclude.\n\nII. RELATED WORK\n\nTo the best of the authors\u2019 knowledge, the concept\n\nof a blockchain-based automated market maker (AMM) was \ufb01rst proposed by [1] and [2]. [3] introduced a sim- pli\ufb01ed model based on the work of [4], which was later formalized by [5] and extended by [6]. [7] generalized the concept to allow for various token weights and pools with more than two assets. Furthermore, modi\ufb01cations for speci\ufb01c use-cases, such as stablecoin exchanges, have been proposed by [8]. Additionally, [9] introduced the concept of concentrated liquidity.\n\nThere is a signi\ufb01cant body of literature regarding the\n\ndesign of AMMs, as demonstrated by [10], [11], as well as their properties, outlined in [12]\u2013[14]. [15] propose a general framework for the analysis of CPMMs as a major subset of AMMs. Numerous articles discuss the ef\ufb01ciency of AMM designs with respect to price discovery [16], [17] and compare price ef\ufb01ciency to centralized exchanges [18], [19]. [19] further character- ize equilibrium liquidity pools and \ufb01nd no long-lived arbitrage opportunities. [14] conduct agent-based simu- lations to demonstrate that AMMs can theoretically be used as sound price oracles. [20] uses time-varying and stochastic weights to replicate the payoffs of \ufb01nancial derivatives. [21] investigate the market microstructure of AMMs.\n\nMany papers study the pro\ufb01tability of providing\n\nliquidity to AMMs. For instance, [22] and [23] research the relationship between information sets of traders, LP returns and the choice between centralized and 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\ndecentralized exchanges. [24] analyze the risk pro\ufb01le of LPs and discuss differences in the presence of con- centrated liquidity. [25] propose a decomposition of the LP returns into an instantaneous market risk component and a predictable component, which they term as \u201dloss- versus-rebalancing\u201d. [26] analyze the returns of LPs of Uniswap V2 pools and study the movement of liquidity between pools. [27] introduce the concept of predictable loss and apply it to CPMMs with concentrated liquidity. Additionally, [28] analyze the ability of Uniswap V3 to handle unexpected price shocks.\n\nIII. FRAMEWORK\n\nIn our paper we focus on a special case of AMMs:\n\nCPMMs with two assets. Let us denote the pool amounts of these two assets by x and y . The reserve constraint is shown in equation (1), where k is the constant product of token amounts x and y . There are three explicit actions that affect the pool\u2019s token reserves: Swap one token for the other, provide liquidity in the form of x - and y -tokens to the pool ( mint ) and redeem liquidity from the pool ( burn ).\n\nx \u00b7 y = k (1)\n\nA. Token to Token Swap\n\nAssume that an agent wants to trade x -tokens for\n\ny -tokens. The agent sends \u2206( x ) of their x -tokens to the liquidity pool contract and receives \u2206( y ) y -tokens in exchange. The reserve constraint from (1) must still hold for new token reserves after the trade.\n\nWe follow the notation of [5] and de\ufb01ne \u21b5 = \u2206( x )\n\nx\n\nand \u03b2 = \u2206( y )\n\ny . Assume \u2206( x ) to be \ufb01xed, i.e., the trader\n\nprovides a \ufb01xed amount of x -tokens to the pool. The token reserves after the trade y 0 and change in token reserves \u2206( y ) are de\ufb01ned as:\n\ny 0 = 1\n\n1 + \u21b5 \u00b7 y , \u2206( y ) = \u21b5\n\n1 + \u21b5 \u00b7 y (2)\n\nNote that the same relation applies for the opposite\n\ncase where \u2206( y ) is \ufb01xed.\n\nRelative prices are given by the \ufb01rst derivative of\n\nk at a given point, allowing us to write P x = y x\n\nand P y = x y respectively. Considering the constant\n\nproduct constraint, only points on k are feasible. This has two consequences. First, when someone uses the CPMM to swap x for y -tokens, there is a diminishing marginal return for every x -token that is sent to the smart contract. Second, for any given amount of x - tokens, the contract will be able to quote a relative exchange rate and an amount in y -tokens that does not completely deplete its reserves.\n\nB. Liquidity Provision and Redemption\n\nAnyone can contribute liquidity to the pool by pro-\n\nviding n x -tokens and n \u00b7 y\n\nx y -tokens to the smart\n\ncontract. This changes the token amounts as well as the constant k . The ratio between the two tokens remains unchanged. Both reserves are increased by the factor ' = \u2206( x )\n\nx = \u2206( y )\n\ny as shown in (3).\n\nk 0 = (1 + ' ) 2 k (3)\n\nIn return, the LP receives (mints) a corresponding\n\namount of liquidity tokens that represent partial pool ownership and can be redeemed for their proportional share of the pool\u2019s token holdings. Redemption is referred to as a burn action. It is the exact opposite of a mint action and reduces the pool\u2019s k -value.\n\nC. The Role of Trading Fees\n\nTo incentivize liquidity provision, the model relies\n\non trading fees. Let us assume a fee \u21e2 2 [0 , 1) with \u03b3 := 1 \u2212 \u21e2 . The fee is charged on every trade and added to the liquidity pool and therefore leads to an increase in the normalized k , i.e., the k -value in relation to the outstanding liquidity tokens. Applying a fee to both equations in (2) leads to the following equations for the new token reserves as well as the change in token reserves:\n\ny 0\n\n\u21e2 = 1\n\n1 + \u21b5\u03b3 \u00b7 y , \u2206( y \u21e2 ) = \u21b5\u03b3\n\n1 + \u21b5\u03b3 \u00b7 y (4)\n\nLet us revisit the swap action and assume that an\n\nagent wants to trade x -tokens for y -tokens. They send \u2206( x ) of their x -tokens to the smart contract. In the setup with fees, the agent receives only \u2206( y \u21e2 ) y -tokens.\n\nSince the smart contract adds the fee to the liquidity\n\npool, the trade leads to an increase in k . These equations build the foundation for our LP pro\ufb01tability analysis.\n\nIV. FORMAL LPP ROFITABILITYA NALYSIS\n\nTo determine whether liquidity provision is prof-\n\nitable, we compare its return to the outcome of a pure hold strategy, where the investor maintains their initial allocation of x and y . Formally, the buy and hold value in x -terms can be expressed as\n\nx 0 + y 0\n\nx 1 y 1\n\n, (5)\n\nwhere the indices 0 and 1 represent the start and end\n\npoints of the comparison period. Similarly, the liquidity pool investment value in x -terms can be expressed as\n\nx 1 + y 1\n\nx 1 y 1\n\n= 2 x 1 . (6)\n\nThe liquidity provision is worthwhile if (6) > (5).\n\nThe difference between the two strategies arises from two distinct sources.\n\nFirst , liquidity provision has a non-negative fee accu-\n\nmulation effect. Whenever someone swaps assets using the CPMM, they will pay a trading fee. These fees are assigned proportionally to all LPs.\n\nSecond , any relative price shift away from the initial\n\nprice ratio leads to a negative effect on the return compared to a pure hold strategy [29]. Intuitively, this is a result of the passive market making and a quasi- arbitrage effect, i.e., the LP will own less of the more valuable and more of the less valuable token. This phenomenon is commonly referred to as divergence - or impermanent loss . The combination of these two effects leads to four possible cases.\n\nCase 1: k 0 = k 1 , x 0\n\ny 0 = x 1\n\ny 1\n\nIt can be easily shown that (5) = (6).\n\nCase 2: k 0 = k 1 , x 0\n\ny 0 6 = x 1\n\ny 1\n\nCase 2 represents a pure divergence loss D . Hence,\n\nit can be shown that (5) > (6).\n\nD :=\n\nx 1 + y 1 x 1\n\ny 1\n\nx 0 + y 0 x 1\n\ny 1\n\n\u2212 1 (7)\n\nWe can now rewrite (7) in x 1 -terms and expand the\n\nfraction by x 0 . Assuming k 0 = k 1 , we get x 0 \u00b7 y 0 \u2318 x 1 \u00b7 y 1 , which can be rearranged to x 1\n\nx 0 \u2318 y 0\n\ny 1 . We use\n\nthis relation to expand our equation and take the square root.\n\nD = 2 \u00b7\n\nq\n\nx 1 \u00b7 y 0 y 1 \u00b7 x 0\n\n1 + x 1 \u00b7 y 0\n\ny 1 \u00b7 x 0\n\n\u2212 1 (8)\n\nNote that x 1 \u00b7 y 0\n\ny 1 \u00b7 x 0 corresponds to the change in the price\n\nratio between the two assets.\n\nCase 3: k 0 < k 1 , x 0\n\ny 0 = x 1\n\ny 1\n\nIt can be shown that (5) < (6). Starting from (7),\n\nrewriting the equation in x 1 -terms, expanding it with x 0 and replacing x 1 with x 0 \u00b7\n\nq\n\nk 1 k 0 and y 1 with y 0 \u00b7\n\nq\n\nk 1 k 0 .\n\nCase 4: k 0 < k 1 , x 0\n\ny 0 6 = x 1\n\ny 1\n\nEquating (5) and (6) and solving for y 1 we get\n\ny 1 = y 0 x 1\n\n2 x 1 \u2212 x 0\n\n. (9)\n\nWith both effects present, the pro\ufb01tability of the\n\ninvestment depends on which of the two effects is more pronounced. Equation (9) can be interpreted as the pro\ufb01tability frontier with a convex pro\ufb01tability set. The function allows us to visualize the pro\ufb01tability frontier and the pro\ufb01tability set in xy -space, as shown in Figure 1.\n\nFigure 1 shows the pro\ufb01tability frontier (dotted\n\ncurve) and the pro\ufb01tability space (shaded gray). For any given k 1 with k 1 > k 0 , there is a set of price ratios\n\nk 0 k 1\n\nP 1 ( x 0 , y 0 , k 1 )\n\nP 1 ( x 0 , y 0 , k 1 )\n\nx -tokens\n\ny -tokens\n\nFig. 1. Price limits of pro\ufb01tability frontier for a given k 1\n\n(asset allocations) between P 1 and P 1 that represents pro\ufb01table outcomes.\n\nFrom (9) we can derive the limits of the pro\ufb01tability\n\nfrontier.\n\nlim\n\nx 1 !1\n\ny 0 x 1\n\n2 x 1 \u2212 x 0\n\n= y 0\n\n2 (10)\n\nA. Effect of Mint Fees\n\nTransactions on Ethereum are subject to network\n\nfees as described by [30]. These network fees must not be confused with the trading fees described earlier. They are paid for every transaction on the Ethereum network. All three explicit actions that affect CPMM reserves (i.e., swap , mint and burn ) are transactions and therefore subject to a network fee.\n\nNetwork fees are denoted in units of gas . Every\n\noperation has a universally agreed upon cost in terms of gas units. When a transaction calls a smart contract function, it essentially executes all operations that are part of this function. Hence, each contract call has a gas cost associated with it.\n\nTransaction fees are computed by multiplying these\n\ngas units with a per unit price. The per unit price consists of a global base fee that adjusts dynamically to the demand in block space, as well as a voluntary tip, which is chosen by the transaction sender. A higher tip increases the probability that the transaction will get included in the next block and therefore decreases the expected con\ufb01rmation time. In the context of decen- tralized exchanges, this is of particular importance as transactions are usually time critical. Providing liquidity to a CPMM and closing the position requires multiple transactions. Including the ERC20 approve calls this can take up to \ufb01ve blockchain transactions. The cor- responding transaction fees can lower the pro\ufb01tability\n\nk 0 k 1\n\nP 1 ( x 0 , y 0 , k \u21e4 , & 0 )\n\nP 1 ( x 0 , y 0 , k \u21e4 , & 0 )\n\nx -tokens\n\ny -tokens\n\n& 0\n\nFig. 2. Pro\ufb01tability frontier after mint fees\n\nof the liquidity provision signi\ufb01cantly and shift the pro\ufb01tability set.\n\nLet us denote the mint fee by & 0 . Equating (5) and\n\n(6), and incorporating mint fees, we obtain\n\n\u2713\n\nx 0 + y 0\n\nx 1 y 1\n\n\u25c6\n\n\u00b7\n\n\u2713\n\n1 + & 0\n\n2 x 0\n\n\u25c6\n\n= 2 x 1 . (11)\n\nFrom (11) we can derive the shifted pro\ufb01tability\n\nfrontier as a function of network fees\n\ny 1 =\n\ny 0 x 1 \u00b7 (1 + & 0\n\n2 x 0 )\n\n2 x 1 \u2212 x 0 \u2212 & 0\n\n2\n\n(12)\n\nas well as the corresponding limits\n\nlim\n\nx 1 !1\n\ny 0 x 1 \u00b7 (1 + & 0\n\n2 x 0 )\n\n2 x 1 \u2212 x 0 \u2212 & 0\n\n2\n\n=\n\ny 0 \u00b7 (1 + & 0\n\n2 x 0 )\n\n2 . (13)\n\nThe effects on the pro\ufb01tability frontier are visualized\n\nin Figure 2. Note that the shift leads to a narrower section of the k -indifference curve between P 1 and P 1 .\n\nB. Effect of Burn Fees\n\nSimilarly to mint fees, LPs are subject to a burn fee.\n\nWe denote this fee by & 1 . It must be interpreted as an expected value. The exact fee depends on the base fee and the mempool competition at the time of the burn transaction. Moreover, effective fee size will be affected by the relative prices of the two pool tokens compared to the native protocol asset Ether (ETH). If the pool token prices increase (decrease) relative to ETH, the \ufb02at fee will have a smaller (larger) proportional effect.\n\nFor CPMM pools without wrapped ETH (wETH),\n\nan ERC20 compliant version of ETH, we assume that the normalized pool value remains constant to ETH (symmetric case). The reasoning behind this assump- tion is that the prices at the time of minting are the best predictor for prices at a later point in time. As\n\nk\n\n& 0\n\n& 1\n\nx -tokens\n\ny -tokens\n\nFig. 3. Pro\ufb01tability Frontier after burn Fees, with symmetric (blue) and asymmetric (red) burn fees.\n\nsuch, any pro\ufb01tability expectations should be based on these prices. For CPMM pools with wETH, we have additional information. Since one of the two tokens can be redeemed for ETH at a \ufb01xed 1:1 ratio, we know the prices of both pool tokens in ETH (asymmetric case). The two cases will yield slightly different pro\ufb01tability frontiers. Let us \ufb01rst consider the symmetric case, where wETH is not part of the pool.\n\n\u2713\n\nx 0 + y 0\n\nx 1 y 1\n\n\u25c6\n\n\u00b7\n\n\u2713\n\n1 + & 0 + & 1\n\n2 x 0\n\n\u25c6\n\n= 2 x 1 . (14)\n\nSolving (14) for y 1 we get\n\ny 1 =\n\ny 0 x 1 \u00b7 (1 + & 0 + & 1\n\n2 x 0 )\n\n2 x 1 \u2212 x 0 \u2212 & 0 + & 1\n\n2\n\n(15)\n\nand the corresponding limit\n\nlim\n\nx 1 !1\n\ny 0 x 1 \u00b7 (1 + & 0 + & 1\n\n2 x 0 )\n\n2 x 1 \u2212 x 0 \u2212 & 0 + & 1\n\n2\n\n=\n\ny 0 \u00b7 (1 + & 0 + & 1\n\n2 x 0 )\n\n2 . (16)\n\nFor the asymmetric case, in which one of the pool\n\ntokens is wETH, the pro\ufb01tability frontier with & 1 > 0 will look slightly different. Let us assume that y is wETH. It has a constant exchange rate to ETH, the asset in which the fees must be paid. Hence, the relative fee will change with the price ratio. We can derive this property from\n\n\u2713\n\nx 0 + y 0\n\nx 1 y 1\n\n\u25c6\n\n\u00b7\n\n\u2713\n\n1 + & 0\n\n2 x 0\n\n\u25c6\n\n= 2 x 1 \u2212 & 1 \u00b7 x 1 y 0\n\nx 0 y 1\n\n. (17)\n\nSolving (17) for y 1 we get\n\ny 1 =\n\ny 0 x 1 \u00b7\n\n\u21e3\n\n1 +\n\n& 0\n\n2 + & 1\n\nx 0\n\n\u2318\n\n2 x 1 \u2212 x 0 \u2212 & 0\n\n2\n\n(18)\n\nFig. 4. Pool path, block 11.073.311 to 13.390.744 (360 days).\n\nand the corresponding limits:\n\nlim\n\nx 1 !1\n\ny 0 x 1 \u00b7\n\n\u21e3\n\n1 +\n\n& 0\n\n2 + & 1\n\nx 0\n\n\u2318\n\n2 x 1 \u2212 x 0 \u2212 & 0\n\n2\n\n=\n\ny 0 \u00b7\n\n\u21e3\n\n1 +\n\n& 0\n\n2 + & 1\n\nx 0\n\n\u2318\n\n2 (19)\n\nlim\n\ny 1 !1\n\ny 1 \u00b7 ( x 0 + & 0\n\n2 )\n\n2 y 1 \u2212 y 0 \u00b7\n\n\u21e3\n\n1 +\n\n& 0\n\n2 + & 1\n\nx 0\n\n\u2318 = x 0 + & 0\n\n2\n\n2 . (20)\n\nFigure 3 visualizes the shift of the pro\ufb01tability\n\nfrontier for a given & 1 . The blue pro\ufb01tability frontier represents the symmetric case, where wETH is not part of the pool. The red pro\ufb01tability frontier represents the asymmetric case, where wETH is part of the pool. The blue (red) shaded pro\ufb01tability set is exclusive to the symmetric (asymmetric) case.\n\nV. EMPIRICAL ANALYSIS\n\nIn this section we use blockchain data to study the\n\npro\ufb01tability frontier empirically. Our data set includes all Uniswap V2 transactions. We used the APIs of Infura and Alchemy to collect uniswap transactions, and the Coingecko API to gather the historical mar- ket capitalization of all listed tokens. The data set includes observations from 132,657 pools, with a total of 2,371,811 mint , 1,048,613 burn and 93,749,446 swap events for the period between block number 10,000,835 (4th of May 2020, deployment of the Uniswap V2 factory contract) and block number 16,308,189 (last block of 2022). To understand the data it may be useful to explore an example. Figure 4 shows one mint event (initial point) and the corresponding pool path in xyk - space for the subsequent 360 days, normalized w.r.t. the initial allocation, i.e., the starting point is (1 , 1) .\n\nFig. 5. Reserve changes for different holding periods with relative combined fees of 0% to 50% of initial pool value (steps of 5%). Fees paid in y -token.\n\nFig. 6. Reserve changes for different holding periods with relative combined fees of 0% to 35% of initial pool value (steps of 5%). Fees constant in k .\n\nTo generalize the analysis, we assume different hold-\n\ning periods and compute outcomes of virtual liquidity positions. We take daily pool reserve snapshots (noon UTC) and divide them by the outstanding amount of liquidity pool tokens. We then observe for each day the reserve per liquidity pool token after different holding periods (30, 90, ..) and set this in relation to the initial reserves.\n\nFigure 5 shows the outcome of each observation\n\nPair Fee Type N 30 Day Pro\ufb01tability 180 Day Pro\ufb01tability 360 Day Pro\ufb01tability\n\nSmall Med Large Small Med Large Small Med Large\n\nUSDC/WETHAsymmetric OpenMarket 964 0.00 0.05 0.49 0.20 0.55 0.69 0.44 0.47 0.53\n\nDAI/WETHAsymmetric OpenMarket 956 0.00 0.03 0.31 0.07 0.36 0.61 0.34 0.44 0.47\n\nWBTC/WETHAsymmetric OpenMarket 951 0.00 0.00 0.12 0.00 0.19 0.64 0.00 0.09 0.72\n\nLINK/WETHAsymmetric OpenMarket 951 0.00 0.04 0.34 0.09 0.23 0.78 0.17 0.38 0.54\n\nMKR/WETHAsymmetric OpenMarket 951 0.00 0.00 0.19 0.06 0.28 0.77 0.23 0.51 0.85\n\nUSDT/WETHAsymmetric OpenMarket 951 0.00 0.06 0.52 0.32 0.61 0.70 0.47 0.52 0.60\n\nYFI/WETHAsymmetric OpenMarket 890 0.02 0.05 0.31 0.10 0.35 0.77 0.10 0.35 0.47\n\nUNI/WETHAsymmetric OpenMarket 829 0.00 0.00 0.10 0.01 0.14 0.49 0.11 0.42 0.61\n\nAAVE/WETHAsymmetric OpenMarket 813 0.00 0.00 0.20 0.09 0.36 0.62 0.11 0.36 0.53\n\nDAI/USDCSymmetric Stable 956 0.00 0.00 0.14 0.00 0.23 0.44 0.12 0.33 0.61\n\nUSDC/USDTSymmetric Stable 951 0.00 0.00 0.24 0.03 0.30 1.00 0.18 0.52 1.00\n\nDAI/USDTSymmetric Stable 945 0.00 0.00 0.13 0.00 0.27 0.52 0.16 0.37 0.91\n\nTABLEI\n\nTHE TABLESHOWS THEPERCENTAGE OFOBSERVATIONS THATWERE PROFITABLEFOR THE 12 LARGESTPOOLS ( FROMTHE 11 THDAY\n\nAFTERPOOL DEPLOYMENTUNTIL ENDOF 2022) BYHOLDING PERIODAND RELATIVEFEE SIZE ( INITIALPOSITION ).\n\nfor the UNI/WETH \u201copen market\u201d pool. Again, the starting point of each observation is (1 , 1) and each point re\ufb02ects the relative outcome of one observation. The pro\ufb01tability space without gas fees is highlighted as the gray area and the gray lines show the pro\ufb01tability frontier for different assumptions of relative network fees. Note, that fees are paid in wETH, which is part of the pool. Hence, the pro\ufb01tability frontiers are visualizations of (18). Points outside the gray area are not pro\ufb01table even if relative gas fees were zero. The pro\ufb01tability of points that lay within the gray area depends on the relative fee value. The various pro\ufb01tability frontiers depict relative fees in steps of 5 percentage points of the initial allocation.\n\nFigure 6 shows an example pool with two stable-\n\ncoins, which are expected to trade within a narrow price range. The results demonstrate that, in the absence of network fees, a majority of observations are pro\ufb01table. However, when substantial relative network fees are present, short-term liquidity provisions may not be pro\ufb01table.\n\nA selection of pools were chosen for Table I based\n\non the following criteria: (1) The pool has at least 100,000 events ( mint , burn and swap combined), and (2) both tokens of the pool maintained a relevant market capitalization for at least 24 months. We took a snapshot of the market capitalizations on the 15th day of each month (as recorded on Coingecko) and compared it to the market capitalization of ETH. A token was considered relevant if it maintained at least 0.5% of the Ether market capitalization.\n\nTable I summarizes the pro\ufb01tability of liquidity pro-\n\nvision for these pools. The table shows the percentage of observations that were pro\ufb01table for different holding periods (30, 180, and 360 days) and liquidity position sizes (small, medium, and large). The liquidity position sizes are de\ufb01ned as the ratio of fees to the position size,\n\nwith small (medium, large) representing an implied fee share of 0.10 (0.05, 0.01) of the initial holdings, with equally divided fees for mint and burn events. The results indicate that the pro\ufb01tability of liquidity provision in CPMM pools is heavily dependent on the size of the position and the holding period. Small and medium-sized positions are generally not pro\ufb01table in the short-term, while larger positions have a higher likelihood of pro\ufb01tability. Additionally, the volatility of the underlying assets plays a signi\ufb01cant role, as higher volatility in \u201copen market\u201d pairs can provide more opportunities to offset the high relative gas fees, but the higher volatility also comes with higher divergence loss risk. It would be of interest to include a category for \u201cPure Trend\u201d pools, however, the authors have not been able to identify a pool with signi\ufb01cant liquidity that \ufb01ts this category. Such pools would likely exhibit characteristics similar to \u201cStable\u201d pairs, with the added factor of a consistent trend in the price ratio, creating a predictable, trend-based divergence loss.\n\nVI. CONCLUSION\n\nIn this paper we analyzed LP pro\ufb01tability in CPMMs.\n\nIn the \ufb01rst part we derived the pro\ufb01tability frontier and the corresponding pro\ufb01tability set and formalized the effect of mint and burn fees. Based on these \ufb01ndings, we show that small liquidity positions face an implicit lock-in. This effect becomes more pronounced for higher relative network fees. In the second part of the paper we analyzed a large data set and studied the pro\ufb01tability frontier empirically. Empirical evidence backs the expected results and allows us to visualize pool pro\ufb01tability in xyk -space.\n\nThe paper provides a novel analytical framework to\n\nstudy LP pro\ufb01tability and highlights the importance of layer 2 deployments and improvements to the token approval process. These measures will decrease relative\n\ntransaction fees and thereby reduce holdup problems for small-scale LPs.\n\nACKNOWLEDGMENTS\n\nThe authors would like to thank Felix Bekemeier,\n\nFlorian Bitterli, Dario Th\u00a8urkauf, Mitchell Goldberg, Emma Middleton, Matthias Nadler, Remo Nyffenegger and Katrin Schuler for their valuable inputs.\n\nREFERENCES\n\n[1] A. Lu. (2017) Building a decentralized exchange\n\nin ethereum. [Online]. Available: https://blog.gnosis.pm/\n\nbuilding-a-decentralized-exchange-in-ethereum-eea4e7452d6e\n\n[2] E. Hertzog, G. Benartzi, and G. Be-\n\nnartzi. (2018) Bancor protocol. [Online]. Avail-\n\nable: https://website-bancor.storage.googleapis.com/2018/04/\n\n01ba8253-bancor protocol whitepaper en.pdf\n\n[3] H. Adams. (2018) Uniswap whitepaper. [Online]. Available:\n\nhttps://hackmd.io/@HaydenAdams/HJ9jLsfTz\n\n[4] V. Buterin. (2017) On path independence. [Online]. Available:\n\nhttps://vitalik.ca/general/2017/06/22/marketmakers.html\n\n[5] Y. Zhang, X. Chen, and D. Park, \u201cFor-\n\nmal speci\ufb01cation of constant product (xy=k) mar-\n\nket maker model and implementation,\u201d 2018.\n\n[Online]. Available: https://github.com/runtimeveri\ufb01cation/\n\nveri\ufb01ed-smart-contracts/blob/uniswap/uniswap/x-y-k.pdf\n\n[6] H. Adams, N. Zinsmeister, and D. Robinson, \u201cUniswap\n\nv2 core,\u201d 2020. [Online]. Available: https://uniswap.org/\n\nwhitepaper.pdf\n\n[7] F. Martinelli and N. Mushegian. (2019) A non-custodial\n\nportfolio manager, liquidity provider, and price sensor.\n\n[Online]. Available: https://balancer.\ufb01nance/whitepaper/\n\n[8] M. Egorov, \u201cStableswap-ef\ufb01cient mechanism for stablecoin\n\nliquidity,\u201d 2019. [Online]. Available: https://www.curve.\ufb01/\n\nstableswap-paper.pdf\n\n[9] H. Adams, N. Zinsmeister, M. Salem, R. Keefer, and\n\nD. Robinson, \u201cUniswap v3 core,\u201d 2021. [Online]. Available: https://uniswap.org/whitepaper-v3.pdf\n\n[10] F. Sch\u00a8ar, \u201cDecentralized \ufb01nance: On blockchain- and smart\n\ncontract-based \ufb01nancial markets,\u201d Federal Reserve Bank\n\nof St. Louis Review , 2021. [Online]. Available: https:\n\n//doi.org/10.20955/r.103.153-74\n\n[11] V. Mohan, \u201cAutomated market makers and decentralized\n\nexchanges: a de\ufb01primer,\u201d SSRNElectronic Journal , 2020. [Online]. Available: https://dx.doi.org/10.2139/ssrn.3722714\n\n[12] J. Xu, K. Paruch, S. Cousaert, and Y. Feng, \u201cSoK:\n\nDecentralized exchanges (DEX) with automated market maker (AMM) protocols,\u201d ACMComputing Surveys , 2022. [Online]. Available: https://doi.org/10.1145%2F3570639\n\n[13] M. Bartoletti, J. H.-y. Chiang, and A. Lluch-Lafuente, \u201cA\n\ntheory of automated market makers in de\ufb01,\u201d 2021. [Online]. Available: https://arxiv.org/abs/2102.11350\n\n[14] G. Angeris, H.-T. Kao, R. Chiang, C. Noyes, and T. Chitra,\n\n\u201cAn analysis of uniswap markets,\u201d 2019. [Online]. Available: https://arxiv.org/abs/1911.03380\n\n[15] G. Angeris and T. Chitra, \u201cImproved price oracles,\u201d in\n\nProceedings of the 2nd ACMConference on Advances in Financial Technologies . ACM, 2020. [Online]. Available:\n\nhttps://doi.org/10.1145%2F3419614.3423251\n\n[16] G. Angeris, A. Evans, and T. Chitra, \u201cWhen does the tail\n\nwag the dog? curvature and market making,\u201d 2020. [Online]. Available: https://arxiv.org/abs/2012.08040\n\n[17] M. Pourpouneh, K. Nielsen, and O. Ross, \u201cAutomated Market\n\nMakers,\u201d IFROWorking Paper, 2020. [Online]. Available: https://ideas.repec.org/p/foi/wpaper/2020 08.html\n\n[18] A. Barbon and A. Ranaldo, \u201cOn the quality of cryptocurrency\n\nmarkets: Centralized versus decentralized exchanges,\u201d 2021. [Online]. Available: https://arxiv.org/abs/2112.07386\n\n[19] A. Lehar and A. Parlour, Christine, \u201cDecentralized exchanges.\u201d\n\n[Online]. Available: https://dx.doi.org/10.2139/ssrn.3905316\n\n[20] A. Evans, \u201cLiquidity provider returns in geometric mean\n\nmarkets,\u201d 2020. [Online]. Available: https://arxiv.org/abs/2006. 08806\n\n[21] A. Capponi and R. Jia, \u201cThe adoption of blockchain-\n\nbased decentralized exchanges,\u201d 2021. [Online]. Available: https://arxiv.org/abs/2103.08842\n\n[22] J. Aoyagi, \u201cLiquidity provision by automated market makers,\u201d\n\nSSRNElectronic Journal , 2020. [Online]. Available: https: //ssrn.com/abstract=3674178\n\n[23] J. Aoyagi and Y. Ito, \u201cCoexisting exchange platforms: Limit\n\norder books and automated market makers,\u201d 2021. [Online]. Available: https://dx.doi.org/10.2139/ssrn.3808755\n\n[24] A. A. Aigner and Gurvinder Dhaliwal, \u201cUniswap: Impermanent\n\nloss and risk pro\ufb01le of a liquidity provider,\u201d 2021. [Online]. Available: http://rgdoi.net/10.13140/RG.2.2.32419.58400/6\n\n[25] J. Milionis, C. C. Moallemi, T. Roughgarden, and A. L. Zhang,\n\n\u201cAutomated market making and loss-versus-rebalancing,\u201d 2022. [Online]. Available: https://arxiv.org/abs/2208.06046\n\n[26] L. Heimbach, Y. Wang, and R. Wattenhofer, \u201cBehavior of\n\nliquidity providers in decentralized exchanges,\u201d 2021. [Online]. Available: https://arxiv.org/abs/2105.13822\n\n[27] \u00b4A. Cartea, F. Drissi, and M. Monga, \u201cDecentralised \ufb01nance\n\nand automated market making: Predictable loss and optimal liquidity provision,\u201d 2022. [Online]. Available: https://dx.doi. org/10.2139/ssrn.4273989\n\n[28] L. Heimbach, E. Schertenleib, and R. Wattenhofer, \u201cExploring\n\nprice accuracy on uniswap v3 in times of distress,\u201d 2022. [Online]. Available: https://arxiv.org/abs/2208.09642\n\n[29] Pintail. (2019) Understanding uniswap re-\n\nturns. [Online]. Available: https://pintail.medium.com/\n\nunderstanding-uniswap-returns-cc593f3499ef\n\n[30] G. Wood, \u201cEthereum: A secure decentralized generalised\n\ntransaction ledger,\u201d 2014. [Online]. Available: https://gavwood. com/paper.pdf"
    },
    {
        "number": 1570880812,
        "title": "Proof-of-Federated-Learning-Subchain: Free Partner Selection Subchain Based on Federated Learning",
        "abstract": "Previously multiple Proof-of-Deep-Learning(PoDL) consensuses have been proposed to replace hashing with useful work such as deep learning model training tasks. The energy will be more efficiently used while maintaining the ledger. However deep learning models are problem-specific and can be extremely complex. Current PoDL consensuses still require much work to realize in the real world. In this paper, we proposed a novel consensus named Proof-of-Federated-Learning-Subchain(PoFLSC) to fill the gap. We applied a subchain to record the training, challenging, and auditing activities and emphasized the importance of valuable datasets in partner selection.",
        "review": {
            "strength": [
                "This paper is well-organized and explains design and experiment of Proof-of-Federated-Learning-Subchain in detail",
                "The article discusses the use of Federated Learning Proof of Deep Learning in a blockchain context to incentivize device participation and contribute their resources and private data sets to the chain, including data from minority groups (?). The authors suggest that this approach would create a free market for miners, with incentives based on values such as response time and data. The proposal builds on previous work by Le et al. [4].",
                "In this paper, we proposed a consensus algorithm called PoFLSC (Proof-of-Federated-Learning-Subchain) to solve the disadvantages of PoDL (Proof-of-Deep-Learning).\nExperiments have verified that miners with high Shapley values (SV) have a better chance when the size of the subchain pool is limited with respect to reservation priority."
            ],
            "shortcoming": [
                "1. There are some papers proposing Proof-of-Federated-Learning but they are not introduced in this paper\n2. Measures used in this paper are not explained well.",
                "However, the paper seems to be outside the scope of the workshop and focused more on a proof of concept for a blockchain design.",
                "It is difficult to determine that the performance of PoFLSE presented in the paper is better than that of PoDL in the verification proceeding with the experimental results.\nIn addition, there are many limitations in the experimental process, so it is difficult to think that the experimental results have the energy efficiency suggested in the paper."
            ],
            "comment": [
                "1. Other works proposing Proof-of-Federated-Learning are not introduced in this paper.\n2. It would be better to add brief explanation about G-Shapley Value and LOO Shapley Value\n3. Consider to combine Fig. 5 with Fig. 7 and Fig. 6 with Fig. 8 for better comparison",
                "While the paper is reasonably well-written, there are several unclear claims, such as why energy efficiency is improved compared to PoDL due to the diversity of datasets introduced by miners, and why more data would improve performance. Additionally, the assumptions made about the data design, such as being clean and of the same size, seem unrealistic. The value of data is not clearly defined, and it would be helpful to have a formula for this. It would also be useful to comment on how response time could be variable. Finally, more information about the experiment design, including code, would be beneficial.",
                "I read the paper and thought the Proof-of-Federated-Learning-Subchain (PoFLSC) consensus algorithm was an interesting topic.\nI think it will be a good project if continuous research is done.\n\nHowever, it is difficult to grasp the overall research with the presented thesis, so it seems that some modifications are needed.\n   - It would be nice to reduce redundant explanations and add an algorithmic picture of the process presented in the steps or thesis.\n  - As a result of the experiment, it seems that the readability will improve if the order and arrangement of the pictures are changed. (Fig 5-8)\n  - The typo I found was in the Proof-of-Federate-Learning-Subchain (PoFLSC) part of the introduction. There may be typos other than that part, so a full review is required."
            ],
            "score": {
                "Relevance": 1.7,
                "Content and originality": 2.3,
                "Reference": 2.7,
                "Overall recommendation": 2.3,
                "Poster acceptance": 3.0
            }
        },
        "body": "I. INTRODUCTION\n\nAs a result, Proof-of-Deep-Learning (PoDL) [1], [2] was proposed in recent years to address the \u201cwasting energy\u201d issue, which replaced the hash algorithm with deep learning training tasks as the workload. Deep learning algorithms have been widely applied in various research areas such as com- puter vision and natural language processing. PoDL adopted the Proof-of-Work (PoW) [1], [2] and focused on designing pipelines and scheduling deep learning tasks to inherit the security properties. Successive works of PoDL chains such as DLchain [3] and DLBC [4] further improved security over the original design. However, training a deep learning (DL) model for a specific task is more complex compared with hashing. In computer vision, the state-of-the-art neural network architectures in areas such as object detection [5] and image classification [6] varied drastically depending on the details of the problem. Moreover deep learning models are data driven [7], [8]. The quality of data used to train the model has a direct impact on the model\u2019s performance. In this work, we introduce the novel consensus Proof-of- Federate-Learning-Subchain (PoFLSC) which is derived from PoDL. This is the first consensus that integrates the importance of the dataset into the task scheduling process among miners. In PoFLSC, miners are encouraged to collect and contribute their private datasets. Both the complexity of the model to train and the value of the dataset will be considered while miners choose mining partners and rank the priority of scheduled tasks. To enhance the security of PoFLSC, we adopted the\n\nFig. 1. The interaction of a miner with others participants\n\nchallenge and witness verification mechanism from Helium [9]. II. BACKGROUND\n\nPreviously, the PoDL [1] consensus mainly utilized the computation capability of miners, and the tasks publisher release the training tasks and the training data. In the PoNAS consensus [10], the tasks publisher provides training data and relatively flexible training tasks. The target task is to search a neural architecture network, thus the actual training tasks can be different from each other. Federated learning(FL) is proposed as an efficient deep learning method suitable for decentralized data [11]. The collaboration strategy within a pool was proposed in [12]. Furthermore, the combination of blockchain and FL resolved some of the existing drawbacks in FL such as centralized server, robust network communication, and lack of incentive [13]. FL-blockchains [14] removed the central server role and minimized the impact of remote devices failures. More than that, FL-blockchains naturally motivated devices to participate and contribute to the chain. In the DNSonChain [15], it adopts the decentralized network to host DNS records. Participants: 1) Miners are the machines that join the decentralized network and contribute the resource for crypt- currency reward. 2) Full nodes will generate challenges and audit the training procedure. 3) Task publisher will provide a certain DL model architecture and the sample dataset. This work is based on three assumptions: 1) The dataset is clean. 2) The size of a dataset from each data contributor is the same and the size of each sample is the same. 3) Each block will finish one task and the tasks between two blocks are independent. 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nIII. DESIGN A. Miner tasks 1) Training: With given neural network architecture and local dataset or partner shared dataset, the training workforce train DL models for certain local epoch and submit the updated gradients to the host or other miners. 2) Hosting the pool manager: Besides strong computation power, the host is the server to manage multiple other miners. 3) Proxy: The proxy can forward data or requests. With strong proxy involve, the core pool network performance of bandwidth saving and speeds will be improved. 4) Data Contributor: Data contributors will collect private datasets for DL training tasks and the owner of the high-quality dataset will be the preferred partner in the PoFLSC. B. Subchain Structure In PoFLSC, each block will finish one target task and each block will be divided into multiple sub-blocks. The sub-block time is predefined when releasing the training tasks and it is longer than multiple local epoch time for slow miners. A relatively short sub-block time will limit the number of miners to contribute to the final DL model, while increasing the global communication rounds. With relatively longer sub- block time, it encourages more miners to join the competition and it encourages miners to participate in multiple subchains. Working with multiple subchains in parallel will increase the opportunity to win. Therefore, the miner or a core pool with a valuable dataset or shorter response time will wish to work with multiple subchains and they will increase their winning chance by upgrading to better hardware or collecting valuable data. C. Verification Full nodes will perform three types of checks. i) All nodes can behave as Type One full nodes and it will record and check all blocks and transactions. ii) As Type Two full node, each data contributor will generate challenges periodically to test the DL model performance of all its visible subchain. iii) The Type Three full node will audit the training procedure by repeating it. IV. DISCUSSION In the PoNAS, the tasks publisher provided training data and relatively flexible training tasks. The target task is to search a neural architecture network, thus the actual training tasks can be different from each other. In this work, we considered the complexity of training a deep learning model and proposed the PoFLSC. Here, it emphasizes the importance of training data in DL models. In addition, the design also concerns the response time of miners, verification between miners. The response time can be expended to computation power of miner and specification of network infrastructure, etc. The verification mechanism further strengthens the security of the system. Because DL models are data-driven, it is necessary to evaluate the value of the dataset in this novel consensus. To my best knowledge, we are the first to adopt SV into novel consensus and further evaluate the effectiveness of PoFLSC. Once the consensus requests private datasets and evaluates the\n\nvalue of each private dataset, all miners will have the moti- vation to collect high-quality data. As a result, more effective and economical methods of data collection are expected to be proposed. For example, existing works [16], [17] have proved to be capable of generating synthetic training data for computer vision tasks utilizing 3D simulation techniques. Besides helping to create incentives for data collection, SV also contributes to detecting low-quality datasets, miss-label samples, and adversarial attacks [18].\n\nREFERENCES\n\n[1] C. Chenli, B. Li, Y. Shi, and T. Jung, \u201cEnergy-recycling blockchain with proof-of-deep-learning,\u201d in 2019 IEEEInternational Conference on Blockchain and Cryptocurrency (ICBC) . IEEE, 2019, pp. 19\u201323.\n\n[2] B. Li, C. Chenli, X. Xu, T. Jung, and Y. Shi, \u201cExploiting computation power of blockchain for biomedical image segmentation,\u201d in Proceed- ings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR) Workshops , June 2019.\n\n[3] C. Chenli, B. Li, and T. Jung, \u201cDlchain: Blockchain with deep learning as proof-of-useful-work,\u201d in World Congress on Services . Springer, 2020, pp. 43\u201360.\n\n[4] B. Li, C. Chenli, X. Xu, Y. Shi, and T. Jung, \u201cDlbc: A deep learning- based consensus in blockchains for deep learning services,\u201d arXiv preprint arXiv:1904.07349 , 2019.\n\n[5] J. Redmon and A. Farhadi, \u201cYolov3: An incremental improvement,\u201d arXiv , 2018.\n\n[6] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2016, pp. 770\u2013778.\n\n[7] D. Solomatine, L. M. See, and R. Abrahart, \u201cData-driven modelling: concepts, approaches and experiences,\u201d Practical hydroinformatics , pp. 17\u201330, 2009.\n\n[8] S. Grieggs, B. Shen, G. Rauch, P. Li, J. Ma, D. Chiang, B. Price, and W. J. Scheirer, \u201cMeasuring human perception to improve handwritten document transcription,\u201d IEEETransactions on Pattern Analysis and Machine Intelligence , vol. 44, no. 10, pp. 6594\u20136601, 2022.\n\n[9] K. S. Garewal, \u201cThe helium blockchain,\u201d in Practical Blockchains and Cryptocurrencies . Springer, 2020, pp. 79\u2013112.\n\n[10] B. Li, Q. Lu, W. Jiang, T. Jung, and Y. Shi, \u201cA mining pool solution for novel proof-of-neural-architecture consensus,\u201d in 2021 IEEEInter- national Conference on Blockchain and Cryptocurrency (ICBC) . IEEE, 2021, pp. 1\u20133.\n\n[11] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, \u201cCommunication-efficient learning of deep networks from decentralized data,\u201d in Artificial intelligence and statistics . PMLR, 2017, pp. 1273\u2013 1282.\n\n[12] B. Li, Q. Lu, W. Jiang, T. Jung, and Y. Shi, \u201cA collaboration strategy in the mining pool for proof-of-neural-architecture consensus,\u201d Blockchain: Research and Applications , vol. 3, no. 4, p. 100089, 2022.\n\n[13] D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le, A. Seneviratne, J. Li, D. Niyato, and H. V. Poor, \u201cFederated learning meets blockchain in edge computing: Opportunities and challenges,\u201d IEEEInternet of Things Journal , 2021.\n\n[14] H. Kim, J. Park, M. Bennis, and S.-L. Kim, \u201cBlockchained on-device federated learning,\u201d IEEECommunications Letters , vol. 24, no. 6, pp. 1279\u20131283, 2020.\n\n[15] L. Jin, S. Hao, Y. Huang, H. Wang, and C. Cotton, \u201cDnsonchain: Delegating privacy-preserved dns resolution to blockchain,\u201d in 2021 IEEE 29th International Conference on Network Protocols (ICNP) , 2021, pp. 1\u201311.\n\n[16] B. Shen, B. Li, and W. J. Scheirer, \u201cAutomatic virtual 3d city generation for synthetic data collection,\u201d in 2021 IEEEWinter Conference on Applications of Computer Vision Workshops (WACVW) . IEEE, 2021, pp. 161\u2013170.\n\n[17] N. Bhandari, \u201cProcedural synthetic data for self-driving cars using 3d graphics,\u201d Ph.D. dissertation, Massachusetts Institute of Technology, 2018.\n\n[18] T. Wang, Y. Zeng, M. Jin, and R. Jia, \u201cA unified framework for task- driven data quality management,\u201d arXiv preprint arXiv:2106.05484 , 2021."
    },
    {
        "number": 1570882712,
        "title": "Leveraging Architectural Approaches in Web3 Applications - A DAO Perspective Focused",
        "abstract": "Architectural design contexts contain a set of factors that greatly influence software application development. Among them, organizational design contexts consist of high-level company concerns and how it is structured, for example, stakeholders and development schedules heavily impacting design considerations. The Decentralized Autonomous Organization (DAO), as a vital concept in the Web3 space, represents an organization constructed by automatically executed rules, such as via smart contracts, holding features of the permissionless committee, transparent proposals, and fair contribution by participated stakeholders. In this work, we conduct a systematic literature review of existing DAO literature to summarize its structural features, benefits and challenges, and potential development directions in the context of Web3 applications.",
        "review": {
            "strength": [
                "- DAO\u2019s definition, benefits, existing challenges, and potential improvements are well explained.\n- Detailed process of literature review is provided\n- Organization of the manuscript (defining key questions and answering) is good to read and understand the paper.",
                "- research questions are clearly stated\n- the review is clear and systematic\n- very rich set of references.",
                "This paper discusses the structural aspects of the DAO, the consideration of various benefits and challenges, and the technical development direction. All discussions covered in this paper are made through literature review. The key questions of the discussion were well drawn and the process of reaching a conclusion on the question is logically reasonable.",
                "This paper provided a study of architectural-level exploration of DAO development in the context of Web3 applications. This paper make an comprehensive review of DAO architecture for Web3 application and provides the ways of leveraging architectureal designs for DAO in Web3 and the poetntial development direction for DAO design. It is good literature review paper and well organized. The openion by the authors will be very helpful to develop DAO design for Web3 applicaiton."
            ],
            "shortcoming": [
                "- The authors may clarify whether there are other literature review related to DAO\n- DAO's relevance to crypto exchanges which topic of interest of this workshop is missing",
                "- the level of the technical content of the paper should be increased\n- no reference to real DAO project",
                "This paper was discussed only from an academic perspective. In terms of industry, it would be nice to include various DAO projects currently underway in the scope of the discussion. As Section 4 Conclusion and Future Plan mentions these shortcomings as future research, the next paper is expected.",
                "It will be better to provoide the research challenges of DAO architecure desing for Web3 applicaiton in the authore's point of view in detail."
            ],
            "comment": [
                "- In \u201cSearch strategy\u201d part, there are three defined paper selective criteria, not two.\n- In Fig.2 (b), the blue bar seems to be removed.\n- Please explain how DAO could be applicable to crypto exchanges",
                "If the paper is accepted, the authors should include in their presentation also reference to real-world projects",
                "This paper was discussed only from an academic perspective. In terms of industry, it would be nice to include various DAO projects currently underway in the scope of the discussion. As Section 4 Conclusion and Future Plan mentions these shortcomings as future research, the next paper is expected.",
                "This paper provided a study of architectural-level exploration of DAO development in the context of Web3 applications. This paper make an comprehensive review of DAO architecture for Web3 application and provides the ways of leveraging architectureal designs for DAO in Web3 and the poetntial development direction for DAO design. It is good literature review paper and well organized. The openion by the authors will be very helpful to develop DAO design for Web3 applicaiton. \n\nIt will be better to provoide the research challenges of DAO architecure desing for Web3 applicaiton in the authore's point of view in detail."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 3.5,
                "Reference": 4.0,
                "Overall recommendation": 3.3,
                "Poster acceptance": 3.8
            }
        },
        "body": "I. INTRODUCTION\n\nArchitectural design contexts influence software applica- tions design in many ways, such as developmental , techno- logical , business , organizational , operational , social , and other influences [ 1 ] [ 2 ]. A system of similar functionalities can work differently in different contexts [ 3 ]. Whist design contexts are important to making design decisions, the contexts of a system are often ignored and some of the design contexts may not be explicitly captured in the requirement documents [ 4 ]. Organizational context, as one of the important design contexts, comprises considerations such as how a company is organized, stakeholders (e.g., developers, architects), de- velopment schedule, and financial factors [ 1 ]. In addition, organizational design contexts are vital in many domains, which heavily impacts a set of design considerations [ 5 ]. We develop the paper from this view. The Decentralized Autonomous Organization (DAO) is an emerging term in the Web3 space, which is an important con- sideration of organizational design contexts. Cryptocurrency communities fall into fanaticism on DAOs due to their super decentralization and self-governance [ 6 ]. Formed organiza- tions replace the traditional third party with on-chain smart contracts, aiming to establish a legal structure without central authorities that enable members to seize the best interest of the entity. DAOs achieve fairness as anyone only needs to trust the transparently operating code on-chain [ 7 ]. However, it is also realized that the current DAOs are still far from mature [ 8 ]. There is a set of issues existing, for example:\n\n\u2022 The very beginning recognition of DAO for current participants is even absent. People are unclear about the basic concepts and definitions of DAO [ 9 ].\n\n\u2022 Th claimed properties given by DAOs are debatable. It is unknown to the community whether a DAO can well hold the properties such as self-governance and complete decentralization [ 10 ].\n\n\u2022 The potential applications of DAO lack exploitation. Whether a DAO can be widely adopted in the future is still a question. Meanwhile, external tools/protocols surrounding DAOs require further development. Partici- pating members will definitely expect a smooth transition and better user experience from traditional organizations to this new form.\n\nGiven those discussed issues, the entire view of DAO needs to be structurally and systematically stated. Further technical, political, and economic challenges are also required for deep exploration. In this paper, we focus on summarizing how DAO is structured in Web3 and relevant benefits/challenges from previous literature. The main goal and three initial RQs that we try to answer are listed below: Research goals. In this paper, we aim to systematically summarize the architectural contexts (in particular, DAOs) in Web3 applications, their design benefits and challenges, and the potential development directions. We break this main goal into three research questions as follows.\n\n\u2022 RQ-1: What are general considerations about DAOs? How a DAO is structured in Web3 applications? Prob- lem space exploration is important, the more structured the problem space is, the more rationally the approach can be taken by researchers and practitioners. Design considerations are raised to address design concerns, which is one of the important design activities. This RQ helps to explore the common and general considerations that researchers seek to resolve in their work.\n\n\u2022 RQ-2: What benefits and challenges have been re- ported towards leveraging architectural solutions for DAOs in Web3 applications? DAO in Web3 applica- tions will lead to certain benefits as well as costs. The answer to this RQ can help researchers and practitioners understand the benefits and limitations of the current structured DAO in Web3 applications.\n\n\u2022 RQ-3: What is the potential direction and develop- ment in the near future? DAO in Web3 applications has been learned towards a better format with many state- of-the-art features. The answer to this RQ points out the development direction for researchers and practitioners.\n\nTo answer the RQs, we perform a systematic literature re- 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nview that complies with Kitchenham\u2019s standard guideline [ 11 ]. The objectives are to (i) provide an overview of the research activities and topics in architecture design for DAOs; (ii) understand challenges and investigate corresponding possible solutions for DAO practitioners; and (iii) point out the potential development directions for DAO designs. The key contribu- tions of this paper are as follows:\n\n\u2022 We provide a comprehensive qualitative and quantitative understanding of DAO in Web3 applications, including what design considerations researchers hold and what application goals developers expect.\n\n\u2022 We summarize the benefits and challenges of DAOs from empirical evidence that researchers report in their work. We also list the ways of leveraging architectural designs for DAO in Web3 at present, as well as the potential development directions for DAO design.\n\nII. RESEARCH DESIGN\n\nA. Research Methodology\n\nThis literature review consists of three stages: (i) planning : before conducting the literature review, we prepared a research protocol during the planning phase that focuses on the specific objectives of understanding DAO in Web3 applications; (ii) lit- erature study selection and analysis execution is described in details in Sec. II-B . and (iii) report the results : we report and discuss our results in Sec. III .\n\nB. Research Process\n\nStudy search and selection . We conducted this literature review in order to understand the state of the art of DAO in Web3 applications. We defined two research questions (RQs), which concern Sec. I , which concern how DAO is structured in Web3 applications and what benefits and challenges of DAO that summarized in previous literature. We define the search scope, search strategy, and selection criteria for conducting this literature review.\n\n\u2022 Time period : we planned to search as many research papers as possible to get a comprehensive understanding of this topic, however, as Web3 is a new concept, which has emerged within five years, so we did not define the start time to reduce risks of omitting some literature, and the end time was set on October 2022.\n\n\u2022 Electronic databases : we collected the eligible candidate papers from five mainstream academic databases, cov- ering ScienceDirect , SpringerLink , ACMDigitalLibrary , ISIWebofScience , and IEEEexplore , to retrieve related literature. GoogleScholar was not included in this study since it will produce a number of unrelated results, and the retrieved literature overlaps with the previous five indexed databases. Search strategy. Search strategy influences the quality of the retrieved literature and determines the time and effort required to search the literature. The search strategy in this mapping study was divided into two steps:\n\n\u2022 We defined the search terms based on the topics, as such the keywords we selected are: \u201cSoftware Architecture\u201d AND \u2018DAO\u201d OR \u201cBlockchain Governance\u201d.\n\n\u2022 We define two paper selective criteria: (i) A study pub- lished in full-text and written in English; and (ii) A study that investigates DAO in Web3 application, and (iii) Keywords should be included in \u201cTitle or Abstracts\u201d of the studies. We also define several exclusive criteria: (i) if a study investigates DAO but not discusses architectural design (design contexts); and (ii) if a study investigates architecture design contexts but not discusses DAO. Finally, we collected 49 relevant literature (listed in Ap- pendix), and we answer the RQs in Sec. III .\n\nTABLEI CATEGORIES OFS ELECTEDP UBLICATIONS\n\nCategory Scoping Count Reference\n\nManagerial Legality and Liability 3 [ 23 ] [ 24 ] [ 25 ]\n\nSociology and Ethics 2 [ 26 ] [ 27 ]\n\nFramework & Design\n\nSupportive middleware and architecture 2 [ 28 ] [ 29 ]\n\nSelf-governance, utility token, e-voting 2 [ 30 ] [ 31 ]\n\nApplications and use cases 6 [ 32 ] [ 33 ] [ 34 ] [ 35 ] [ 36 ] [ 37 ]\n\nSurvey & SoK\n\nSelf-governance, utility token, e-voting 6 [ 38 ] [ 39 ] [ 40 ] [ 41 ] [ 42 ] [ 43 ]\n\nCrypto, blockchain techniques and tools 2 [ 44 ] [ 45 ]\n\nDAO projects on blockchain platforms 4 [ 46 ] [ 47 ] [ 48 ] [ 49 ]\n\nDAO as a component in blockchain 3 [ 50 ] [ 51 ] [ 52 ]\n\nIII. RESULTS ANDD ISCUSSION\n\nIn this section, we analyze each paper in the pool and accordingly deliver the results surrounding research questions. Specifically, we discuss the aspects of definitions , structure , benefits , challenges , and future directions .\n\nFig. 1. Answering RQ-1: What is DAO? The figure is plotted based on statistical results of keyword frequency by the inputs of in-pool publications.\n\nA. Answering RQ-1\n\nTo answer RQ-1, the definition of DAO reported by each study is recorded. This question helps the audience to under- stand both the DAO scope and the perceptions of researchers on DAO . Fig. 1 shows a word cloud of the frequency of the words that appear in DAOs\u2019 definitions in each study. The most\n\n2\n\nfrequently appeared words include: governance , blockchain , decentralized , organizations , contracts , autonomous , manage- ment , decisions , communities , corporate , etc. More precisely, we use four categories to classify the mentioned definitions: (i) execution workflow, (ii) data indexing, (iii) self-governance, and (iv) human-centric (see Tab. II ). First, in the execution workflow , most researchers consider that all processes and operations in DAOs are executed by running decentralized smart contracts to achieve autonomous organizing and management. This can be observed as the most frequently mentioned keyword in RQ-1 is smart contracts (SC) for autonomous organization . Other frequently mentioned keywords describing the execution workflow include parallel , distributed , and corporate . Besides, smart contracts impacting on the decision-making is another characteristic that describes how the execution workflow in DAOs is performed in a decen- tralized manner. Smart contracts have had impacts on DAOs where decision-making is distributed or delegated away from a central authority. This also highlights how researchers dif- ferentiate DAO from traditional organizations. Authors in [ 12 ] also state that a widely used structure of DAO-oriented smart contracts in Web3 applications is multi-sig wallets for secure asset reservation and set voting strategies for fair governance. Smart contracts enable real-time auditing and verification, hence enhancing the machine-execution security [ 13 ].\n\nTABLEII CATEGORIES OFDAO S\n\nCategory Characteristic Count Reference\n\nExecution workflow SC for autonomous organization 5 [ 28 ] [ 30 ] [ 32 ] [ 33 ] [ 51 ]\n\nSC impacting on decision-making 2 [ 33 ] [ 43 ]\n\nApplications Multi-sig wallets 2 [ 12 ] [ 45 ]\n\nData indexing On-chain identifier 3 [ 14 ] [ 15 ] [ 41 ]\n\nOff-chain snapshot 2 [ 12 ] [ 41 ]\n\nApplications Decentralized identifiers (DIDs) 3 [ 12 ] [ 14 ] [ 15 ]\n\nSnapshot 1 [ 12 ]\n\nSelf-governance By means of e-voting 9 [ 25 ] [ 29 ] [ 30 ] [ 31 ] [ 38 ] [ 39 ] [ 40 ] [ 41 ] [ 42 ]\n\nStake and utility token 2 [ 41 ] [ 47 ]\n\nApplications Consensus procedures 2 [ 44 ] [ 49 ]\n\nDefending against Sybil attacks 2 [ 49 ] [ 51 ]\n\nHuman-centric Liability, legality and ethics 5 [ 23 ] [ 24 ] [ 26 ] [ 27 ] [ 38 ]\n\nSocial, human, communities 3 [ 46 ] [ 48 ] [ 50 ]\n\nApplications Finance and Crowdfunding 4 [ 32 ] [ 34 ] [ 37 ] [ 16 ]\n\nLaw and Democracy 3 [ 23 ] [ 35 ] [ 52 ]\n\nSecondly, DAOs can be discussed in terms of data indexing . It is realized that researchers categorize data indexing into two sectors, i.e., on-chain and off-chain. The keywords on- chain identifier and off-chain snapshot highlight the on-chain and off-chain techniques, respectively. On-chain identifiers are used to enable globally unique, secure, and cryptographically verifiable authentication services. Off-chain snapshots are used to enable the in-time data status to improve look-up efficiency and smooth collaboration. On-chain decentralized identifiers (DIDs) [ 14 ] are used instead of traditional identifiers in the absence of any central entity. By making use of Public Key Infrastructure (PKI) technology in Web3 applications to gen-\n\nerate asymmetric key pairs stored on-chain, DIDs can achieve globally unique, secure, and cryptographically verifiable au- thentication services. Typical examples of implementation of DIDs include Ethereum address and Ethereum name service (ENS) [ 17 ]. On the other hand, Snapshot is mentioned for off-chain data caching which is expected to be structured in many Web3 applications to smooth the collaboration between multiple parties and improve the efficiency of governance. The third category is self-governance which is the most crucial component in DAOs by governance being reflected in the word cloud the most, as shown in Fig. 1 . The keywords of this category found are by means of e-voting and stake and utility token . The self-governance is mainly conducted for decentralized decision-making by running e-voting across members who own a certain amount of stake or utility tokens. They are used for governance and votes, while at the same time representing an on-chain reputation or voting power of a unique DID during e-voting and being subject to consensus procedures . This brings the token system a strong capability of defending against Sybil attacks [ 18 ]. The last category is human-centric which focuses on hu- mans/communities and responsible activities. Many studies mention the words of liability , legality , and ethics . These keywords delineate a partial landscape of DAO\u2019s vision. DAO organizations should be responsible for positive and ethical activities. Another line of keywords society , human , and communities reflects the participation scale of DAOs or their impacts. We can find that many DAOs have rooted in human- centric behaviors for building a sustainable ecosystem. Finally, as a summary, by connecting and grouping each keyword with others under the same definition, a picture of answering RQ-1 can be concluded and summarized below.\n\nFindings of RQ-1: What is DAOs and How a DAO is structure in Web3 applications? \u25b7 DAO. DAO is an emerging term to describe self-governable orga- nizations in a decentralized context. It relies on cryptography and contains smart contracts, on-chain identifiers, off-chain snapshots, and e-voting-based governance with stake and utility tokens. \u25b7 Approach to construct DAOs in Web3. (i) Smart contracts used as multi-sig wallets for secure asset reservation and set voting strategies for fair governance. (ii) On-chain DIDs used to au- thenticate and authorize identities, also used for token storage and trading. Off-chain Snapshot is used to smooth collaboration and improve the efficiency of data look-up and self-governance. (iii) Stake and utility tokens representing voting power and reputation by relying on consensus procedures, which offer reliable defenses against Sybil attacks.\n\nB. Answering RQ-2\n\nWe study the benefits and challenges of leveraging archi- tectural solutions for DAOs through RQ-2 (cf. Fig. 2 ).\n\nOrganization structure. It can be realized that the most frequently mentioned benefit by researchers is the organization structure , i.e., all selected publications mention this term. The organizational structure of DAOs refers to the flat structure without relying on central entities. This also tells the most crit- ical pain point of a traditional organization, i.e., centralization\n\n3\n\nwhich is thought to be responsible for unexpected monopoly, manipulation, corruption, and inefficiency of management.\n\nAutomation. The term automation comes second (28 publi- cations) with nearly the same level of concentration as the organization structure. Researchers consider that automated execution significantly improves the efficiency and stability of management or holding any campaigns in DAOs with non- human behaviors being involved after the development has been clearly finalized and thoroughly evaluated.\n\nTransparency and openness. There are 22 publications men- tioning transparency and openness in the collection. The smart contracts are open-source and are transparently executed by blockchains where every entity can verify and validate the correctness and confirm rules or policies prior to participating in any DAO campaigns. This, in fact, can create strong trustworthiness by transparent behaviors being conducted in a decentralized manner with no human manipulation involved, which also corresponds to the fourth benefit being mentioned.\n\nTrustlessness. The strong trustworthiness created by the fac- tors above refers to a trustless trust, which is mentioned only 10 times in the publication pool. The trustworthiness being trustless is important in DAOs, highlighting strong system reliability in a decentralized manner.\n\nInvestment. Researchers also take interest in the positive financial investment return in DAOs. This refers to a healthy tokenization [ 12 ] where investors can reap profits owing to their rising capital in an influential DAO in which the price of the stake and utility tokens would accordingly increase.\n\nFindings of RQ-2.1: What benefits have been reported towards leveraging architectural solutions for DAOs? \u25b7 Benefits of architectural DAOs. Flat organization structure and automated execution are the two main benefits. A moderate number of studies pay attention to transparency and positive investment return, while only a small number of studies mention trustlessness. This may give a reminder of the need to emphasize in future studies how the trust is established and how the trust works under the hood in DAO spaces.\n\nContract reliance/vulnerability. A large number of works (20 publications) in the collection mentioned the excessive reliance of smart contracts could be risky due to the hidden vulnerabilities or bugs in current smart contracts. All of the publications highlight this factor by also mentioning the huge implication of The DAO hack that happened in 2016. Automated execution of smart contracts running on distributed nodes increases the difficulty of risk management after an attack is successfully leveraged in current DAOs.\n\nBlockchain security. Beyond the contract component, there are 8 publications diving into blockchain technology to figure out the security issues of blockchain that are inherited by DAOs. Researchers take into account the use of DIDs and discuss the threats of the Sybil attack and selfish attack [ 19 ] which are the two main attacks being noticed in publications.\n\nData privacy. Data privacy is also a factor being discussed by 8 publications. Transparency and openness are beneficial\n\n(a) What are the benefits?\n\n(b) What are the challenges?\n\nFig. 2. RQ-2\n\nfor public auditing and encourage the creation of trustlessness. However, this does not mean privatizing data would not be- come a crucial requirement in DAOs. For example, healthcare data across hospitals or private facilities that intend to be organized via a DAO may not be willing to share the data. Current DAOs lack enough concentration on this factor.\n\nLegality/Liability. Half of the studies (12 publications) men- tion that state-of-the-art DAOs still await legislation to con- solidate the business rules of DAOs. DAOs have not been rec- ognized as legal entities in most countries. Participants cannot make a profit via organizations with corporate personhood. The absence of legal recognition potentially increases the burden on individual members as they need to be responsible for both their personal and organizational liabilities.\n\nTokenization/Marketing. Upon the legislation, investing DAOs could become a long-term strategy (mentioned by 3 publications) in a more healthy tokenization ecosystem and non-opportunistic crypto-market. This would also encourage marketing and advertisement towards those who have not yet been Web3 fans. A stable space could provide huge business opportunities that could not be resisted.\n\nMonopoly. Researchers start to realize that the abuse of stakes or utility tokens in e-voting processes may cause monopoly . The governance in DAOs relies prominently on the possession of stakes and utility tokens. Although it is originally expected to be the core of the decentralization in DAOs, highly active\n\n4\n\ngroups of participants are likely to accumulate major shares of tokens (a.k.a., Matthew effect), hence breaching the decen- tralization due to the concentration of e-voting power.\n\nFindings of RQ-2.2: What challenges have been reported towards leveraging architectural solutions for DAOs? \u25b7 Challenges of architectural DAOs. Most of the known chal- lenges of leveraging architectural DAOs appear to be correspond- ing to the known benefits, including the difficulty to manage risks due to the decentralized structure and automated execution, difficulty to ensure data privacy in a transparent and open context, a management risk of monopoly due to the token accumulation in trustless e-voting processes, and financial risk of investment and marketing in the absence of legislation.\n\nC. Answering RQ-3\n\nWe study the potential development directions for DAOs through RQ-3 (cf. Tab. III ).\n\nTABLEIII CATEGORIES OFP OTENTIALD IRECTIONSFOR DAOS\n\nCount Reference Category Scoping\n\nCollaboration & Management SubDAOs organization 2 [ 6 ] [ 12 ]\n\nMulti-DAOs collaboration 3 [ 6 ] [ 12 ] [ 15 ]\n\nTechnical Tools Programming tools 4 [ 6 ] [ 12 ] [ 44 ] [ 45 ]\n\nPrivacy-preserving approaches 4 [ 6 ] [ 12 ] [ 28 ] [ 29 ]\n\nOrganization of sub-DAOs. Sub-DAOs are an emerging approach for different working groups to create their own foundation and ownership structure, which is also mentioned in 2 studies. Organizing sub-DAOs within a larger DAO can be typically managed in several ways, including (i) function- based : sub-DAOs are organized according to their specific functions or areas of responsibility, such as finance, marketing, or operations [ 12 ]; (ii) hierarchical : sub-DAOs are structured in a hierarchical way in which each sub-DAO need to report to a higher-level sub-DAO or the parent DAO; (iii) geographic : sub-DAOs are managed based on geographic regions, allow- ing for decentralized decision-making and localized imple- mentation; and (iv) hybrid : sub-DAOs are organized by a combination of any of aforementioned structures. Similar to building management across any different groups, clear lines of communication, decision-making processes, and account- ability would be established to ensure effective coordination and collaboration among sub-DAOs. Collaboration in multi-DAOs. Collaboration in multi-DAOs can refer to the cooperation between different DAOs to achieve common goals or to achieve their individual goals in a more efficient and effective way. Unlike subDAOs, multi-DAO situations do not hold a close relationship between different DAOs. There are 3 publications mentioning the interaction , collaboration and competition , between different DAOs, as well as the design of typical decentralized negotiation proto- cols. Positive collaboration can be accomplished through the use of cross-DAO communication protocols, shared resources, and shared decision-making processes. Several key techniques\n\ninclude transparent communication, aligned incentives, and a shared governance framework. Additionally, the use of decentralized technologies like blockchain and smart contracts can help ensure that all parties can trust each other and work together effectively, even if they are geographically dispersed. Notably, at the same time, the competition among different DAOs cannot be overlooked. Competition can drive innovation and efficiency within a multi-DAO ecosystem, as each DAO strives to offer the best products, services, and solutions to its stakeholders. However, competition on the flip side can also lead to fragmentation and inefficiencies, particularly if there is a lack of coordination and collaboration between the DAOs. Establishing clear norms such as fair play, open communication, and mutual benefit is critical for such cases.\n\nProgramming tools. There are 4 publications mentioning programming tools for developments in DAOs. In addition to the automated development workflow that implements the typical DAOstack [ 20 ], the considered programming tools mainly include anomaly detection to improve the security of smart contracts. DAO communities should spare efforts to establish security protocols for auditing code and develop improved DAO tooling or supportive infrastructure.\n\nPrivacy-preserving approaches. Researchers also take inter- est in preserving privacy in DAOs. As voting mechanisms play a vital role in DAOs, anonymous voting desires increasing attention with several prominent approaches being considered such as the ring signature [ 21 ] and zero-knowledge proof [ 22 ].\n\nFindings of RQ-3: What techniques will likely be used in future DAO applications? \u25b7 Well-organized and collaborative DAOs. The increasingly com- plex interaction and collaboration between different DAOs desire attention. Currently, the two most prominent approaches are DAO collaboration which helps to formalize the structure and com- munication of DAOs for higher efficiency, as well as SubDAOs which indicate hierarchical relationships across different DAOs for more concise management. \u25b7 Security&Privacy-improved approaches. Making use of anomaly detection tools for smart contracts in DAOs becomes the future. Anonymous voting is increasingly important as DAO participators are keen not to disclose who votes or the voting tally in order for a stronger privacy level.\n\nIV. CONCLUSION ANDF UTUREP LANS\n\nIn this work, we conduct a literature review, which is an extensive investigation of DAO-related studies, and analyze their corresponding features. Our results give clear answers to a series of hot topics on DAO\u2019s easy-understanding definition, architectural design, potential opportunities as well as to-be- improved challenges. From our view, we provide the first architectural-level exploration of DAO\u2019s development in the context of Web3 applications. In the future, we plan to extend the scope of our literature review singly from academia to a wide range of in-the-wild DAO projects (11,000+ projects recorded on mainstream DAO launchpads, e.g. Snapshot, Tally, etc.), and combine the results with this work to thoroughly investigate to what extent the current DAO community has leveraged the recommended architectural solutions for DAOs.\n\n5\n\nREFERENCES\n\n[1] T. Bi, P. Liang et al. , \u201cArchitecture Patterns, Quality Attributes, and Design Contexts: How Developers Design with Them,\u201d in Asia-Pacific Software Engineering Conference (APSEC) . IEEE, 2018, pp. 49\u201358.\n\n[2] K. E. Harper and J. Zheng, \u201cExploring Software Architecture Context,\u201d in IEEE/IFIPConference on Software Architecture (WICSA) . IEEE, 2015, pp. 123\u2013126.\n\n[3] K. Petersen and C. Wohlin, \u201cContext in Industrial Software Engineering Research,\u201d in International Symposium on Empirical Software Engineer- ing and Measurement (ESEM) . IEEE, 2009, pp. 401\u2013404.\n\n[4] A. Bedjeti, P. Lago, G. A. Lewis et al. , \u201cModeling Context with an Architecture Viewpoint,\u201d in IEEEInternational Conference on Software Architecture (ICSA) . IEEE, 2017, pp. 117\u2013120.\n\n[5] L. Wijerathna, A. Aleti, T. Bi, and A. Tang, \u201cMining and Relating Design Contexts and Design Patterns from Stack Overflow,\u201d Empirical Software Engineering (ESE) , vol. 27, no. 1, pp. 1\u201353, 2022.\n\n[6] Q. Wang, R. Li et al. , \u201cExploring Web3 from the View of Blockchain,\u201d arXiv preprint arXiv:2206.08821 , 2022.\n\n[7] D. Sheridan, J. Harris et al. , \u201cWeb3 Challenges and Opportunities for the Market,\u201d arXiv preprint arXiv:2209.02446 , 2022.\n\n[8] H. Samuel, \u201cDeFi Debates DAOGovernance After Vitalik\u2019s Critique,\u201d Accessible at https://thedefiant.io/will-maple-recover-from-this , 2022.\n\n[9] J. Arroyo et al. , \u201cDAO-Analyzer: Exploring Activity and Participation in Blockchain Organizations,\u201d in ACMConference on Computer Supported Cooperative Work and Social Computing (CSCW) , 2022, pp. 193\u2013196.\n\n[10] T. Dounas, E. Voeller, S. Prokop, and J. Vele, \u201cThe Architecture Decentralised Autonomous Organisation: a stigmergic exploration in architectural collaboration,\u201d 2022.\n\n[11] S. Keele et al. , \u201cGuidelines for Performing Systematic Literature Re- views in Software Engineering,\u201d Technical report, ver. 2.3 ebse technical report. ebse, Tech. Rep., 2007.\n\n[12] Q. Wang, G. Yu, Y. Sai et al. , \u201cAn Empirical Study on Snapshot DAOs,\u201d arXiv preprint arXiv:2211.15993 , 2022.\n\n[13] P. Tolmach, Y. Li, S.-W. Lin, Y. Liu, and Z. Li, \u201cASurvey of Smart Contract Formal Specification and Verification,\u201d ACMComputing Surveys (CSUR) , vol. 54, no. 7, pp. 1\u201338, 2021.\n\n[14] R. Drummond, S. Manu, S. Markus, L. Dave, and A. Christopher, \u201cDecentralized Identifiers (DIDs) v1.0: Core Architecture, Data model, and Representations,\u201d https://www.w3.org/TR/did-core/ , 2021.\n\n[15] E. G. Weyl, P. Ohlhaver, and V. Buterin, \u201cDecentralized Society: Finding Web3\u2019s Soul,\u201d Available at SSRN 4105763 , 2022.\n\n[16] R. Fritsch, M. M\u00a8uller, and R. Wattenhofer, \u201cAnalyzing Voting Power in Decentralized Governance: Who Controls DAOs?\u201d arXiv preprint arXiv:2204.01176 , 2022.\n\n[17] Ethereum, \u201cEthereum Name Service,\u201d https://ens.domains/ , 2022. [18] J. R. Douceur, \u201cThe Sybil Attack,\u201d in Peer-to-Peer Systems , P. Druschel, F. Kaashoek, and A. Rowstron, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2002, pp. 251\u2013260.\n\n[19] A. Sapirshtein, Y. Sompolinsky, and A. Zohar, \u201cOptimal Selfish Mining Strategies in Bitcoin,\u201d in Financial Cryptography and Data Security (FC) . Springer Berlin Heidelberg, 2017, pp. 515\u2013532.\n\n[20] \u201cDaostack: An operating system for collective intelligence,\u201d Accessible at https://medium.com/daostack , 2022.\n\n[21] J. K. Liu, M. H. Au, W. Susilo, and J. Zhou, \u201cLinkable ring signature with unconditional anonymity,\u201d IEEETransactions on Knowledge and Data Engineering (TKDE) , vol. 26, no. 1, pp. 157\u2013165, 2014.\n\n[22] G. Persiano and A. D. Santis, \u201cZero-knowledge proofs of knowledge without interaction,\u201d in IEEE 54th Annual Symposium on Foundations of Computer Science (FOCS) , 1992.\n\nAPPENDIX\n\nLIST OFL ITERATURER EVIEW\n\n[23] U. R. Rodrigues, \u201cLaw and the Blockchain,\u201d Iowa L. Rev. , vol. 104, p. 679, 2018.\n\n[24] P. \u00d8stbye, \u201cExploring DAOMembers\u2019 Individual Liability,\u201d Available at SSRN 4045799 , 2022.\n\n[25] K. T. Minn, \u201cTowards Enhanced Oversight of\u201d Self-Governing\u201d Decen- tralized Autonomous Organizations: Case Study of the DAO and Its Shortcomings,\u201d NYUJ. Intell. Prop. & Ent. L. , vol. 9, p. 139, 2019.\n\n[26] M. H\u00a8utten, \u201cThe Soft Spot of Hard Code: Blockchain Technology, Network Governance and Pitfalls of Technological Utopianism,\u201d Global Networks , vol. 19, no. 3, pp. 329\u2013348, 2019.\n\n[27] A. J. Sulkowski, \u201cThe Tao of DAO: Hardcoding Business Ethics on Blockchain,\u201d Bus. & Fin. L. Rev. , vol. 3, p. 146, 2019.\n\n[28] K.-B. Yue, \u201cBlockchain-augmented Organizations,\u201d 2020. [29] I. Mehdi et al. , \u201cData Centric DAO: When blockchain reigns over the Cloud,\u201d in IEEEInternational IOT, Electronics and Mechatronics Conference (IEMTRONICS) . IEEE, 2022, pp. 1\u20137.\n\n[30] W. W. Ding, X. Liang et al. , \u201cParallel Governance for Decentralized Autonomous Organizations enabled by Blockchain and Smart Con- tracts,\u201d in IEEEInternational Conference on Digital Twins and Parallel Intelligence (DTPI) . IEEE, 2021, pp. 1\u20134.\n\n[31] T. K. Mackey, N. Shah, K. Miyachi, J. Short, and K. Clauson, \u201cAFramework Proposal for Blockchain-based Scientific Publishing using Shared Governance,\u201d Frontiers in Blockchain , vol. 2, p. 19, 2019.\n\n[32] E. Bischof, A. Botezatu et al. , \u201cLongevity Foundation: Perspective on Decentralized Autonomous Organization for Special-Purpose Financ- ing,\u201d IEEEAccess , vol. 10, pp. 33 048\u201333 058, 2022.\n\n[33] R. Qin, Y. Yuan, and F.-Y. Wang, \u201cBlockchain-based Knowledge Au- tomation for CPSS-oriented Parallel Management,\u201d IEEETransactions on Computational Social Systems , vol. 7, no. 5, pp. 1180\u20131188, 2020.\n\n[34] R. Jeyasheela et al. , \u201cBlockchain-enabled Microfinance Model with Decentralized Autonomous Organizations,\u201d in Computer Networks and Inventive Communication Technologies . Springer, 2021, pp. 417\u2013430.\n\n[35] N. Diallo et al. , \u201ceGov-DAO: A better Government using Blockchain- based Decentralized Autonomous Organization,\u201d in International Con- ference on eDemocracy & eGovernment . IEEE, 2018, pp. 166\u2013171.\n\n[36] T.-V. Nguyen et al. , \u201cLeveraging Blockchain in Monitoring SLA- oriented Tourism Service Provisioning,\u201d in International Conference on Advanced Computing and Applications . IEEE, 2019, pp. 42\u201350.\n\n[37] M. Zichichi et al. , \u201cLikeStarter: a Smart-contract based Social DAO for Crowdfunding,\u201d in INFOCOMWorkshops . IEEE, 2019, pp. 313\u2013318.\n\n[38] R. Morrison, N. C. Mazey, and S. C. Wingreen, \u201cThe DAO controversy: the case for a new species of corporate governance?\u201d Frontiers in Blockchain , vol. 3, p. 25, 2020.\n\n[39] O. Rikken, M. Janssen, and Z. Kwee, \u201cGovernance Challenges of Blockchain and Decentralized Autonomous Organizations,\u201d Information Polity , vol. 24, no. 4, pp. 397\u2013417, 2019.\n\n[40] S. DiRose and M. Mansouri, \u201cComparison and Analysis of Governance Mechanisms Employed by Blockchain-based Distributed Autonomous Organizations,\u201d in Annual Conference on System of Systems Engineering (SoSE) . IEEE, 2018, pp. 195\u2013202.\n\n[41] W. Reijers, I. Wuisman, M. Mannan et al. , \u201cNow the code runs itself: On-chain and Off-chain Governance of Blockchain technologies,\u201d Topoi , vol. 40, no. 4, pp. 821\u2013831, 2021.\n\n[42] M. Singh et al. , \u201cComputational Governance and Biolable Contracts for Blockchain Applications,\u201d Computer , vol. 53, no. 1, pp. 53\u201362, 2020.\n\n[43] V. Shermin, \u201cDisrupting Governance with Blockchains and Smart Con- tracts,\u201d Strategic Change , vol. 26, no. 5, pp. 499\u2013509, 2017.\n\n[44] M. Singh and S. Kim, \u201cBlockchain Technology for Decentralized Autonomous Organizations,\u201d in Advances in Computers . Elsevier, 2019, vol. 115, pp. 115\u2013140.\n\n[45] A. Beniiche et al. , \u201cThe way of the DAO: Toward Decentralizing the Tactile Internet,\u201d IEEENetwork , vol. 35, no. 4, pp. 190\u2013197, 2021.\n\n[46] L. Liu, S. Zhou, H. Huang, and Z. Zheng, \u201cFrom Technology to Society: An Overview of Blockchain-based DAO,\u201d IEEEOpen Journal of the Computer Society , vol. 2, pp. 204\u2013215, 2021.\n\n[47] Y. Faqir-Rhazoui et al. , \u201cAComparative Analysis of the Platforms for Decentralized Autonomous Organizations in the Ethereum Blockchain,\u201d Journal of Internet Services and Applications , vol. 12/1.\n\n[48] Y. El Faqir, J. Arroyo, and S. Hassan, \u201cAn Overview of Decentralized Autonomous Organizations on the Blockchain,\u201d in Proceedings of the International Symposium on Open Collaboration , 2020, pp. 1\u20138.\n\n[49] S. Wang, W. Ding, J. Li, and other, \u201cDecentralized Autonomous Or- ganizations: Concept, Model, and Applications,\u201d IEEETransactions on Computational Social Systems , vol. 6, no. 5, pp. 870\u2013878, 2019.\n\n[50] S. Wang et al. , \u201cBlockchain-enabled Smart Contracts: Architecture, Applications, and Future Trends,\u201d IEEETransactions on Systems, Man, and Cybernetics: Systems , vol. 49, no. 11, pp. 2266\u20132277, 2019.\n\n[51] W. Ding, J. Hou et al. , \u201cDeSci based on Web3 and DAO: ACom- prehensive Overview and Reference Model,\u201d IEEETransactions on Computational Social Systems , vol. 9, no. 5, pp. 1563\u20131573, 2022.\n\n[52] S. Takagi, \u201cOrganizational Impact of Blockchain through Decentralized Autonomous Organizations,\u201d International Journal of Economic Policy Studies , vol. 12, no. 1, pp. 22\u201341, 2017.\n\n6"
    },
    {
        "number": 1570883705,
        "title": "NFTs for Online Trading of Artworks",
        "abstract": "Blockchain technology was initially designed to secure online financial transactions. It has since expanded its scope to many other areas such as healthcare, e-voting, supply chain and digital assets. One of the most important characteristics of blockchain is its transparency and immutability. Transactions performed on the blockchain are permanently and transparently stored in a public ledger. Verification of the integrity of the data stored in this ledger can be done without the need for a TTP. The blockchain is also very secure thanks to its encryption system and decentralized model, which prevents fraudulent modification of data. Smart contracts are another key element of the blockchain as they allow the creation of decentralized automated applications based on pre-established rules. They are also used to create unique digital assets (such as artwork, real estate, collectibles, etc.) by representing them as NFTs. These NFTs can then be sold and purchased transparently and securely on the blockchain. In this paper, we present an overview of smart-contracts and NFTs, and we develop a basic smart-contracts application that allows the creation of an NFT, which represents an artwork, that can be sold on an NFT marketplace while transferring the ownership from the seller to the buyer.",
        "review": {
            "strength": [
                "This paper explains the basic of smart contract and NFT",
                "It presents details of how to use smart contracts for creating NFTs for online trading. While the procedural description is fine, there is no novelty to the work. What new ideas are you presenting here?",
                "The paper presents a comprehensive work on the development of NFT platform for online trading of artworks. The implementation details were fully presented and discussed.",
                "The paper presents well-known concepts of the blockchain ecosystem.\nI see no real strength in this paper."
            ],
            "shortcoming": [
                "1. There are many papers explain smart contract and NFT  \n2. The contents are too basic for workshop",
                "The paper presents details of the procedures for using smart contracts for trading art. However, there is no new contributions being made. It is an expectation that papers submitted to this venue present some new ideas.",
                "No comparison was made with other NFT-based platform for artwork.",
                "- contracts for NFT are very popular\n- no novel ideas\n- low level of technical content\n- section II presents well-known concepts"
            ],
            "comment": [
                "1. There are already many papers explain smart contract and NFT\n2. Proposed application is too simple and there is no originality",
                "The paper does not present any novel ideas. What new insights could you present beyond describing the procedural aspects?",
                "The paper presents the work on design and development of NFT platform for selling artworks. Details on the design and implementation of the customized NFT platform were presented.\n\nThe paper provides an interesting details on the NFT platform design, specifically for selling artworks online. It includes all important components of NFT platform, as well as samples of function design used in the implementation. In addition, the overall architecture of the proposed platform was presented.\n\nThe paper is highly-relevant to the themes of the workshop. However, it would be best if the authors could provide some comparisons with other NFT-based platform for artworks. There are a number of works that could be included in the comparison.",
                "The title of the paper presents the work as oriented toward NFT for artworks. Why the smart contract for NFT presented in the paper is oriented toward artworks? What id the feauture which characterizes this NFT from other classes of NFT?"
            ],
            "score": {
                "Relevance": 2.5,
                "Content and originality": 1.8,
                "Reference": 3.0,
                "Overall recommendation": 1.8,
                "Poster acceptance": 2.5
            }
        },
        "body": "I. INTRODUCTION In the past, artists would go to art exhibitions to show their works so that people and businessmen would buy them. With blockchain technology, the same process can take place in an online marketplace specifically using NFTs (Non-Fungible Tokens). In this section, we present a basic smart-contracts application that we have developed with the solidity language on the Ethereum blockchain [1] [2]. This application allows to create, from a URI (Uniform Resource Identifier), an NFT that represents an artwork and sell this NFT on an NFT marketplace by transferring its ownership from the seller to the buyer.\n\nFig. 1. Code in solidity of NFTCreation Contract\n\nFig. 2. Code in solidity of NFTMarketplace Contract\n\nFig. 3. Smart-Contracts of the Application\n\nII. SMART -CONTRACTS APPLICATION FORNFT S\n\nOur application is composed of two smart-contracts (see Fig. 1, Fig. 2 and Fig. 3): (1) the NFTCreation contract which\n\nallows the creation of one or more NFTs for the same artist or several artists, (2) the NFTMarketplace contract which allows the trading (sale/purchase) of NFTs between users. Before proceeding to create an NFT that represents a particular artwork, it is first required to generate the metadata file of that artwork as shown in Fig. 4. Subsequently, it is required to use the InterPlanetary File System (IPFS) to store the artwork\u2019s visual through a token URI. More details are presented in [3] on this procedure. In the following paragraphs, we illustrate the role of the different functions we have developed in our smart-contacts application by dividing them into several steps:\n\nFig. 4. Creation Token URI\n\nFig. 5. Function createToken (1)\n\nFig. 6. Function createToken (2)\n\n- First Step \"Creating an NFT using the token URI\": the function shown in Fig. 5 is developed in the contract NFTCreation. It takes as parameter the token URI in order to create the corresponding NFT and returns the NFT identifier (initialized to 0 at the beginning and incremented by 1 each time an NFT is created). As illustrated in Fig. 6, the returned identifier of the NFT is 1 because we have created only one NFT and the owner inventor is the artist who has the address 0x5B...ddC4. If the same artist or another artist will create another NFT for another artwork (and thus another token URI), the function will then return an identifier which is equal to 2. - Second Step \"Adding the created NFT to the NFT mar- ketplace\": the data structure shown in Fig. 7 and the function shown in Fig. 8 are developed in the contract NFTMarketplace. The objective of the function shown in Fig. 8 and Fig. 9 is to add an NFT to the marketplace with a price proposed by 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nthe seller. This function uses the data structure MarketItem. The objective of the latter is to reference all NFTs added to the marketplace with item identifiers in the marketplace: \"each NFT added to the marketplace for trading (selling and buying) will have its identifier itemMarketId in the marketplace\". Moreover, this data structure indicates for each NFT added to the marketplace the address of the inventor owner and the address of the seller owner. Let\u2019s take an example (see Fig. 9) of a new NFT which was created by the artist 0x5B...ddC4 and was added (itemMarketId = 1) for the first time to the marketplace for trading by its inventor owner who is this artist 0x5B...ddC4. In this case, the address of the inventor owner and the address of the seller owner are the same and lastItemMarketId will be equal to 0. Let\u2019s suppose that this NFT has been bought by the buyer 0xAb....5cb2 (see Fig. 13) and that he later gave it to the marketplace (itemMarketId = 2) to sell it with a new price. In this case, the address of the inventor owner will always remain 0x5B...ddC4, the address of the seller owner will be 0xAb....5cb2 and the lastItemMarketId will be equal to 1 \"the identifier of the NFT in the marketplace when it was added by the inventor owner\" (see Fig. 10 for more details).\n\nFig. 7. MarketItem Data Structure\n\nFig. 8. Function addTokenToMarket (1)\n\nFig. 9. Function addTokenToMarket (2)\n\n- Third Step \"Selling the added NFT to a buyer\": the data structure shown in Fig. 11 and the function shown in Fig. 12 are developed in the contract NFTMarketplace. The objective of the function shown in Fig. 12 and Fig. 13 is to sell an NFT added to the marketplace to another participant (another address) by transferring the ownership of the NFT from the seller to the buyer. This function uses the data structure SoldItem. The objective of the latter is to reference all NFTs sold on the marketplace with identifiers of items sold on\n\nthe marketplace: \"each NFT sold on the marketplace will have its identifier itemSoldId on the marketplace\". Moreover, this data structure indicates for each NFT sold on the marketplace the address of the inventor owner and the address of the buyer owner (see Fig. 13 for more details).\n\nIII. CONCLUSION\n\nIn this paper, we have developed a basic smart-contracts application that allows the creation of an NFT, which repre- sents an artwork, that can then be sold on an NFT marketplace while transferring the ownership from the seller to the buyer.\n\nFig. 10. Function addTokenToMarket (3)\n\nFig. 11. ItemSold Data Structure\n\nFig. 12. Function sellTokenAndChangeOwner(1)\n\nFig. 13. Function sellTokenAndChangeOwner(2)\n\nREFERENCES\n\n[1] C. Dannen, \u201cIntroducing ethereum and solidity,\u201d Springer , vol. 1, 2017. [2] D. Pramulia and B. Anggorojati, \u201cImplementation and evaluation of blockchain based e-voting system with ethereum and metamask,\u201d pp. 18\u2013 23, 2020.\n\n[3] S. M. Jain, \u201cIpfs and nfts,\u201d ABrief Introduction to Web3: Decentralized Web Fundamentals for App Development, Springer , pp. 147\u2013165, 2022."
    },
    {
        "number": 1570886617,
        "title": "Crypto Assets Custody: Taxonomy, Components, and Open Challenges",
        "abstract": "Custody plays a fundamental role for organizations and individuals seeking to access crypto assets (e.g., cryptocurrencies) and decentralized finance (DeFi) applications. Custodians store private keys and approve and sign transactions. Crypto asset transactions must be performed efficiently and securely to prevent any losses or theft of the assets. This paper presents a survey and taxonomy of the state-of-the-art solutions for this custody problem, highlighting their various features, as well as the open challenges that must be addressed.",
        "review": {
            "strength": [
                "This paper presents a survey of crypto custody, reviewing major custody solutions for crypto assets. The authors use five key dimensions to classify current crypto custody solutions. In addition, they compare custody approaches by analyzing their advantages and disadvantages. This information might help newcomers to blockchain and cryptocurrency understand the overall crypto custody.",
                "This paper classifies the existing digital asset custody solutions into multiple categories that broadly focus on convenience (of the user) and security (against hacks and thefts). It presents insights into the cryptographic solutions available for the custody providers and other factors that interest the custody provider and custody users. This offers a holistic view of the available custody technologies and solutions.",
                "The authors present a comprehensive analysis of cryptocurrency asset custody and highlight its difficulties.",
                "This paper proposes a solution to the problem of private key management and transaction signing in cryptocurrency and decentralized finance applications.\n\nA detailed description of tokenization and the types and types of tokenization processes is provided."
            ],
            "shortcoming": [
                "This paper provides general contents of crypto custody but the information is not technically deep. In addition, there is a lack of content for the latest research. This makes it difficult for skilled people to find useful information in this paper.",
                "1) There are some notable errors in the paper.\n2) The abstract can be expanded to give a better idea to the reader about the content of the paper.\n3) References to the webpages should be included for the examples mentioned throughout the paper.",
                "Lack of a specific action plan beyond what is already being done, by the authors. Perhaps which open challenges that the authors intended to deep dive ?",
                "More related works need to be added.\nDescribe the role, characteristics, and types of existing custody and their limitations. Summarize existing research or projects to address these issues."
            ],
            "comment": [
                "1. Two advantages of multi-sig wallets are similar, not distinctive.\n2. In the \u201cThreshold Signature\u201d, the scalability exists for both MPC advantages and drawbacks, which is contradictory.\n3. Some references are missing. For example, readers may not know about custody examples such as \u2018Trezor\u2019, \u2018Ledger\u2019, \u2018ZenGo\u2019 and \u2018Qredo\u2019, so the authors need to add references to them.\n4. HSMs appears in VII before the explanation of this abbreviation is mentioned in VIII.\n5. The authors need to carefully proofread this paper.\n- In page 2, there is an additional dot. Remove it.\n- \u2026",
                "This paper presents a taxonomy and various components for custody solutions for digital assets while evaluating the trade-off between user convenience and security. Under each type of solution, it discusses the current projects using that solution. There are some notable errors throughout the paper as discussed below:\n\n1) Section 3, last line: there is a redundant bullet.\n2) Section 6: semi-decentralized solutions are not discussed although they are illustrated in Figure 1.\n3) Section 9, subsection C, line 4 : \"threshold\"  -> ``threshold\".\n4) Section 11, second bullet, last line: \"management of private keys, and reduces the risk of insider threats.\" -> \"management of private keys, and reduced risk of insider threats.\"\n5) Reference 21 and 23 are exactly the same.\n6) It would be good to provide references for projects such as \"Trejor\", \"Qredo\", etc.",
                "Can the authors provide more concrete plans beyond the current works? Perhaps which open challenges that the authors intended to deep dive ?",
                "Comment (1) Please add related work and table the differences between that research and your proposed research\nComment (2) The evaluation section lacks an explanation for Fig 2. Please provide an explanation for each column and reasons for your results."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 2.8,
                "Reference": 2.8,
                "Overall recommendation": 3.3,
                "Poster acceptance": 3.8
            }
        },
        "body": "I. INTRODUCTION\n\nAs more and more major institutions and individuals invest in crypto assets, the market continues to see an influx of funds [1], [2] . This significantly impacts deposits and presents a valuable opportunity for banks and other industries that hold assets. Thus, it\u2019s not surprising that the survey participants carried out by the financial services industry (FSI) consider custody to play a crucial role in safeguarding crypto assets within their organizations, with nearly half (47%) placing it as the top priority [3]. This number jumps to 63% among FSI pioneers. Additionally, the survey revealed that respondents consider the crypto assets\u2019 safe custody the primary concern in relation to conducting transactions with the crypto currencies of central banks with 77% of pioneers holding such a view. The fundamental role of custodians is safekeeping crypto-assets such as cryptocurrencies, NFTs, and se- curity tokens on behalf of users which requires them to safely store private keys and approve and sign transac- tions [4]. This is of significant importance for organiza- tions seeking to invest in crypto assets and decentralised finance (DeFi) applications. The custody of crypto assets, unlike other assets such as publicly traded securities, requires new technical in- frastructure, processes, and procedures due to the unique design and implementation of crypto assets and the new risks they present [5]. The aim here is to allow for strong operational protections and to accommodate the customers\u2019 needs and preferences. One of the primary challenges that crypto asset custodians are currently facing is to strike the correct balance between usability and safety. Crypto asset transactions must be conducted with maximum efficiency, whilst ensuring that no loss or theft of assets occurs. However, in the current cus- todians\u2019 platforms, security (private key protection) is\n\nintroduced at the expense of other essential aspects such as cost, scalability, governance policy flexibility, and convenience. In this paper, we review the major crypto assets custody solutions in the literature highlighting their key features, analyzing their advantages and disadvantages, and providing a taxonomy to compare the different custody approaches from different perspectives.\n\nII. RELATED WORK\n\nThe literature has limited focus on surveying cus- tody solutions, particularly since it is a relatively new market. However, some research has been conducted to examine the technology used by custodians. For instance, the authors in [6] discuss threshold signing and its components and review the state-of-the-art threshold signing protocols. Vincenzo et al. in [7] provide a survey of solutions to the custody problem, highlighting pros and cons. However, they don\u2019t classify the existing approaches and only delve into one technology, secure multiparty computation. In [8], the authors examine the considerations for digital asset custodians from industry leaders in Deloitte\u2019s digital asset practice. However, they don\u2019t survey existing solutions and don\u2019t provide information on remaining challenges. The authors in [2] overview the issues that could affect the addition of crypto assets by institutional investors to their portfolios. However, the study does not discuss the issue of crypto asset custody and how it might affect the adoption of crypto assets. The authors in [5] high- lighted the various issues, challenges, and risks in the context of crypto assets audits. The study analyzed the major players in the crypto asset ecosystems and their relationships with the aim to help auditors identify risks that may arise when auditing blockchain transactions. However, this study does not highlight any issues related the crypto assets custody which is the main theme of this paper.\n\nIII. TOKENIZATION\n\nA. What is Tokenization\n\nIn the context of the blockchain ecosystem, tok- enization is the process of converting assets such as art, real estate, or company shares into a digital form represented by tokens on a blockchain or other digital ledgers. These tokens allow information and value to be stored, transferred and verified in an efficient and secure manner and hence can be traded (i.e., sold or 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nFig. 1. Taxonomy of Custody Solutions\n\nbought) on the underlying network and represent proof of ownership of the respective asset. Crypto tokens can take many forms, and can be programmed with unique characteristics that expand their use cases [9]. Security tokens, utility tokens, and cryptocurrencies have massive implications for a wide array of sectors in terms of increasing liquidity, improving transaction efficiency, and enhancing transparency and provability to assets. The tokenization process can be divided into two steps: The first step is to create a digital representation of the asset, which is done by creating a smart contract on a blockchain or other digital ledgers. The second step is to mint new tokens that represent the digital representation of the asset. Each token represents a fraction of the underlying asset and can be bought and sold on a digital exchange.\n\nB. Token Types\n\nThere are several different types of tokens, each with its own unique characteristics and use cases. Some of the most common types of tokens include:\n\n\u2022 Asset-backed tokens: These are tokens that repre- sent ownership of a tangible or intangible asset, such as real estate, art, or a company\u2019s revenue stream. These tokens can be traded on a digital exchange and can provide investors with a new way to gain exposure to the underlying asset.\n\n\u2022 Security tokens: These are tokens that represent a security, such as a stock, bond, or derivative. These tokens can be traded on a digital exchange and can provide investors with a new way to gain exposure to the underlying security.\n\n\u2022 Utility tokens: These are tokens that represent ac- cess to a product or service, such as a membership, subscription, or usage rights. These tokens can be used to purchase the underlying product or service and can provide investors with a new way to gain access to it.\n\n\u2022 Non-fungible tokens (NFTs): These are unique digital assets that cannot be replaced by another identical asset. They are usually used in the art, gaming and collectible industries.\n\nIV. TAXONOMY\n\nAs can be seen in Fig. 1, crypto asset custody solu- tions can be categorized into multiple classes based on five key dimensions or perspectives:\n\n\u2022 Responsibility which determines who is responsible for protecting and managing the digital assets\u2019 private keys.\n\n\u2022 Distribution refers to the way in which ownership and control of the assets are distributed among different entities.\n\n\u2022 Connectivity refers to the ability to access and interact with the digital assets stored in a crypto custody platform. Connectivity is an important as- pect because it determines how easily users can access their assets and conduct transactions.\n\n\u2022 Key storage which determines how private keys, which control access to the digital assets, are stored and protected.\n\n\u2022 Technology refers to the technology(ies) used in implementing the custody solution to ensure the security and accessibility of digital assets.\n\nV. RESPONSIBILITY\n\nA. Self-Custody\n\nSelf-custody crypto refers to the practice of individ- uals or institutions holding and managing their own digital assets, as opposed to entrusting them to a third- party custodian or exchange [10], [11]. This means that the individual or institution is responsible for the safekeeping and management of their private keys, which are used to access and transact with their digital as- sets. Self-custody crypto typically involves the use of cold storage solutions, such as hardware wallets such as Trezor [12] and Ledger [13], or paper wallets, to store the private keys offline and protect them from hacking and other cyber threats. By using self-custody, individuals and institutions have full control over their digital assets, and can transact with them without the need for intermediaries. Self-custody can be more complex than entrusting your assets to a third-party custodian, as the individual or institution must be responsible for the security of their own assets. Self-custody can also be beneficial in terms of privacy and security, as it eliminates the need to share personal information with a third-party, and it reduces the risk of a third-party\u2019s security failure leading to loss of funds.\n\nB. Full-Custody\n\nFull-custody crypto refers to a type of storage setting where an individual or institution entrusts all control over their digital assets to a third party, such as a bank, exchange, or custodial service [10]. This means that the user does not have access to their own private keys and all transactions, trades, and other activities must be made through the third party. Full-custody crypto is often used by institutions and businesses that handle large amounts of digital assets and want the added security and convenience that comes with having a professional custodian. These custodians are typically regulated financial institutions that have to comply with various regulations, such as know-your-customer (KYC) and anti-money laundering (AML) regulations.\n\nHowever, full-custody also comes with its own set of risks. For example, if the custodian is hacked or com- promised, the user\u2019s assets may be at risk. Additionally, there may be additional fees associated with using a third-party custodian, and there may be limits on the types of transactions that can be made. It\u2019s important to note the level of security and insurance coverage offered by the custodian. Some providers offer insurance coverage for assets in case of theft, hacking or other security breaches, while others might not. Additionally, some providers might store assets in cold storage, which is considered to be highly secure, while others might not.\n\nC. Semi-Custody\n\nSemi-custody crypto refers to a type of storage setting that falls between self-custody and third-party custody [10]. It is a hybrid approach that aims to provide the best of both worlds: the control and security of self- custody and the convenience and added security of third- party custody. Semi-custody crypto solutions typically involve the use of Multi-sig technology, which requires multiple signatures before a transaction can be made. This means that the user holds one of the private keys and a third party, such as an exchange or a custodian, holds the other key. In this way, the user has control over their own assets, but the added security of a third party. Example of such a custody option is ZenGo [14]. It\u2019s important to note that semi-custody solutions are still vulnerable to hacking, cyber attack and other security risks and it\u2019s important to carefully evaluate the security measures offered by the provider. Additionally, in case of the failure or hacking of the third-party, the user may lose access to their assets.\n\nVI. DISTRIBUTION\n\nA centralized crypto custody solution is one in which a single entity, such as a bank, holds the assets on behalf of its clients. This central entity has full control over the assets and is responsible for their security. A decentralized crypto custody solution, on the other hand, distributes the control and management of the assets among multiple entities. This can be achieved through a network of nodes or a distributed ledger, such as a blockchain, which allows for the decentralization of the management and ownership of the assets. In a decentralized solution, there is no single entity that has full control over the assets. Example of such a custody option is Qredo [15].\n\nVII. CONNECTIVITY\n\nA. Hot Wallets\n\nA hot wallet allows for easy and immediate access to the stored assets [16], [17]. It is connected to the internet and can be accessed from any device with internet access. Hot wallets are typically used for day-to- day transactions, trading and other activities that require frequent and easy access to the stored funds. Popular hot wallet options include software wallets, which are a type of digital wallet that can be installed on a computer or mobile device, and web wallets, which are accessed via a browser. Some examples of popular software wallets\n\ninclude MyEtherWallet, Exodus, and Jaxx. Popular web wallets include Coinbase and Blockchain.info. While hot wallets offer the convenience of easy and immediate access to stored funds, they are also more vulnerable to hacking and cyber attacks compared to cold wallets. This is because hot wallets are connected to the internet and can be accessed remotely. As a result, it is recommended that only a small amount of cryptocurrency be stored in a hot wallet and the majority of funds be stored in a more secure cold wallet.\n\nB. Cold Wallets\n\nA cold wallet, also known as a cold storage, is not connected to the internet. Because it is offline [16], it is considered to be a more secure way to store crypto assets as it is less vulnerable to hacking and cyber attacks compared to hot wallets. Cold wallets are typically used to store large amounts of crypto assets for long-term holding, such as a retirement savings account. There are several types of cold wallets available, including hard- ware wallets and paper wallets. Hardware wallets, such as Trezor and Ledger, are physical devices that store the user\u2019s private keys offline. These devices are designed to be highly secure and are often used by individuals and institutions to store large amounts of crypto assets. Paper wallets, on the other hand, are a type of cold storage that involves printing out the user\u2019s private keys on a piece of paper. For institutional customers, custodians can use Hardware Security Modules (HSMs) devices, as will be seen later, to store the private keys. Some examples of these custodians include Fidelity Digital Assets, Kingdom Trust, BitGo [18], Gemini [19] and Coinbase Custody [20].\n\nC. Warm Wallets\n\nA warm wallet is a mix between a hot and cold wallet. It is a hybrid approach that aims to provide the best of both worlds: the convenience of a hot wallet and the security of a cold wallet. Warm wallets are typically connected to the internet but have added security features such as Multi-sig technology, which requires multiple signatures before a transaction can be made, and two- factor authentication. These added security features aim to reduce the risk of hacking and cyber attacks. Warm wallets are often used by exchanges and other businesses that handle large amounts of crypto assets. They allow for easy access to the assets while still providing a higher level of security compared to a hot wallet.\n\nVIII. KEY STORAGE\n\nA. Hardware Wallet\n\nA hardware wallet is a physical device designed to securely store the private keys [17]. It is considered one of the safest ways to store cryptocurrencies as it is not connected to the internet, reducing the risk of hacking or malware attacks. The private keys are stored within the hardware wallet\u2019s secure environment, and transactions are signed within the device, ensuring that the private keys never leave the device. Some popular examples of hardware wallets include Trezor, Ledger, and KeepKey. It\u2019s important to note that, even though hardware wallets\n\noffer a high level of security, they are not immune to all types of attacks. For example, if the device is lost or damaged, the private keys may be inaccessible, and if the device is compromised, the private keys may be at risk.\n\nB. Hardware Security Modules (HSMs)\n\nA hardware security module (HSM) is a physical com- puting device that safeguards and manages crypto keys, performs encryption and decryption functions for crypto signatures, strong authentication and other cryptographic functions [21]. These modules traditionally come in the form of a plug-in card or an external device that attaches directly to a computer or network server. A hardware security module contains one or more secure crypto- processor chips. Two types of HSMs can be identified: On-premise HSMs and Cloud HSMs. There are several advantages of using Hardware Security Modules (HSMs) for crypto assets custody, including: 1) meeting security standards and regulations, 2) high levels of trust and authentication, and 3) tamper-resistant, tamper-evident, and tamper-proof systems to provide extremely secure physical systems [21]. However, HSMs also have some disadvantages [22] such as: 1) HSMs require physical access for deploy- ment, maintenance and configuration. It causes issues for today\u2019s scaling teams (e.g., remote-forward work environments are incompatible with them). 2) They do not support complex business logics, cannot secure cloud applications or scale without additional hardware. 3) A single module can protect only a limited number of keys and deployment cannot be automated. 4) Single point of failure: HSM centralizes keys, which always adds a security risk. As such, HSMs are most suitable for high volume, low value transactions in traditional industries. 5) Being data compliant requires the anonymized linking of generated keys and key addresses to classic customer bank accounts, which an HSM is not capable of doing. 6) Typically, keys are also stored by some crypto asset custodians inside HSMs. This limits the number of keys to tens of thousands. It also means it is hard to quickly replace an HSM in case of failure or add a new HSM to scale out capacity. 7) Cost: HSMs can be expensive to purchase, deploy and maintain. 8) Compatibility issues: HSMs may only be compatible with specific cryptocur- rencies or software applications, limiting their utility for multi-asset portfolios. 9) Scalability: HSMs may have limited scalability, especially for organizations managing large amounts of assets.\n\nIX. CUTTING - EDGET ECHNOLOGIES\n\nA. Shamir\u2019s Secret Sharing (SSS)\n\nSSS is a method for securely distributing a secret among a group of participants, such that only a specific subset of participants (the \u201dqualified\u201d participants) can reconstruct the secret [23]. The basic idea of SSS in the custody context is to divide the secret into several parts, called \u201dshares\u201d, and to distribute these shares among the participants. To reconstruct the secret, a specific number of shares, called the \u201dthreshold\u201d, must be combined. The threshold is chosen such that only\n\nthe qualified participants, who possess enough shares, can reconstruct the secret. For example, imagine that a secret is divided into 5 shares, and a threshold of 3 is chosen. This means that any 3 shares can be used to reconstruct the secret, but any 2 or fewer shares are useless on their own. In this way, the secret can be protected even if some of the shares are lost or stolen, as long as the threshold is not reached. SSS is used in various security applications, including secure multi- party computation, secure storage of cryptographic keys, and secure communication protocols. It is also a building block for other cryptographic schemes, such as threshold cryptography and multiparty computation as will be seen later. By using SSS, organizations can ensure that their crypto assets are stored securely and that access to the assets is controlled by multiple parties, reducing the risk of theft or loss.\n\nB. Multi-signature Wallets\n\nIn a crypto asset custody solution, a multi-signature (Multi-sig) wallet is a type of wallet that requires mul- tiple private keys to authorize a transaction [24]. This adds an additional layer of security by requiring multiple parties to authorize transactions. Multi-sig has a number of applications.\n\n\u2022 Dividing up responsibility for possession of crypto assets (e.g., bitcoins) among multiple people.\n\n\u2022 Avoiding a single point of failure, making it sub- stantially more difficult for the wallet to be com- promised.\n\n\u2022 m-of-n backup where loss of a single seed doesn\u2019t lead to loss of the wallet. Until now this has been achieved at the protocol layer or through smart contracts, HSMs or Multi-party computation (MPC). Multi-sig wallets has several ad- vantages, for example, a multi-signature wallet helps to get rid of the security concerns that come with a single private key mechanism. It reduces the dependency on one person and, at the same time, makes it difficult for cyber attackers by increasing the number of potential failure points that the hacker would now have to address. However, Multi-sig on the protocol level is an example of a technology that can get in the way of scaling up operations, as it cannot offer the flexibility organizations require as they grow. As the team expands, there is a need to adjust the process of accessing and transferring the crypto assets [25]. This can include changing the number of employees required to sign a transaction, adding new key shares as new employees are hired, revoking key shares as employees leave, and modifying the required threshold to sign transactions (e.g. from \u20183 of 4\u2019 to \u20184 of 8\u2019). In these sorts of scenarios, Multi-sig addresses create various obstacles, as they are pre-set to the wallet.\n\nC. Threshold Signature\n\nThreshold cryptography and multiparty computation (MPC) are related but distinct concepts in cryptography. Threshold cryptography refers to cryptographic proto- cols that allow a group of participants to jointly perform cryptographic operations, such as decryption, signing,\n\nor key generation, without requiring the cooperation of all participants [26]. In threshold cryptography, a secret key is divided into several parts and each part is held by a different participant. To perform a cryp- tographic operation, a specific number of participants must pool their parts of the key, which is referred to as the \u201dthreshold\u201d. A threshold signature is a type of digital signature scheme where a group of signers can produce a signature on a message without revealing their individual private keys. It is based on the concept of secret sharing, where a secret is divided into multiple shares, and a certain number of shares are required to reconstruct the secret. Threshold signatures can be used to implement a multi-signature (Multi-sig) scheme, where a certain number of signatures are required to authorize a transaction. This can be used to provide an added layer of security for crypto assets, as an attacker would need to compromise multiple private keys in order to steal the assets. Threshold signature schemes have existed for some time, and have come in many different flavours. Here are the protocols for ECDSA threshold signing which were published in the last three years [6]: \u201cLindell\u201d [27], \u201cDKLS\u201d [28], \u201cGG20\u201d [29], \u201cCMP\u201d [30], \u201cCCLST\u201d [31] and \u201cGKSS\u201d [32]. In contrast, MPC refers to a broader set of proto- cols that allow multiple parties to jointly perform any computation without revealing their inputs or outputs to each other. MPC protocols can be based on various cryp- tographic techniques, including threshold cryptography, secret sharing, homomorphic encryption, and others. MPC technology has several advantages:\n\n\u2022 Improved security: MPC divides the responsibility of signing transactions among multiple parties, re- ducing the risk of theft or loss if a single party\u2019s private key is compromised and eliminating the need for trusted third parties to keep data safe.\n\n\u2022 Improved availability: MPC allows for a transaction to be signed and executed even if some parties are unavailable or offline, as long as the minimum threshold of signatures is reached.\n\n\u2022 Decentralization: MPC can be implemented in a decentralized manner, without the need for a central authority, which can improve scalability and reduce the risk of single points of failure.\n\nHowever, it has several drawbacks and limitations:\n\n\u2022 Accountability issue: accountability refers to the responsibility and obligation of the custodian to provide clear and transparent reporting on the entity(ies) who approved every transaction. With MPC, it is impossible to distinguish which of the key parts were used to sign the transaction. Accountability is vital in monetary systems, espe- cially when considering the differences in types of people and storage that are typically used for the independent parts of the keys.\n\n\u2022 Peer Review: It is noticed that several MPC im- plementations used today are proprietary and did not undergo sufficient public review. In addition, the vendors of MPC tend to restrict access to their implementation details and the source code with\n\nFig. 2. Technologies evaluation\n\nseveral patent applications already filed making it hard to verify the security or predict the licensing cost.\n\n\u2022 High computational and communication costs: It is well-known that MPC-based techniques require high computation resources as they rely on complex mathematical operations to achieve a high degree of security including homomorphic encryption and zero-knowledge proofs, a fact that would evidently decrease the performance of MPC protocols.\n\n\u2022 It is most appropriate for highly confidential trans- actions with low volume and (probably) high value.\n\n\u2022 Receptiveness: MPC techniques are simply too complex for nonexperts to understand; MPC needs to be accompanied by proper monitoring/auditing for establishing trustworthiness.\n\n\u2022 Scalability: MPC can be challenging to scale to a large number of participants, as the complexity and overhead of MPC protocols increases with the number of parties involved.\n\nX. EVALUATION\n\nIt is important to mention here that custodial platforms could leverage a mixture of the above technologies. For example, SSS can be combined with other security measures, such as HSMs and Multi-sig protocols, to provide additional layers of security for crypto asset custody. Therefore, it could be difficult to evaluate the crypto custodial solutions based on the technology(ies) used because different custodians leverage one or more technologies. However, in Fig. 2 we assess the primary technologies utilized by custodians based on a set of criteria that align with our expectations for a custo- dial solution. It becomes evident that none of these technologies can meet all of the criteria on their own. This implies that custodians should adopt a blend of technologies and tools instead of relying solely on one.\n\nXI. OPEN CHALLENGES\n\nDespite the significant progress that has been made in the development of crypto assets custody solutions, there are still several open challenges that need to be addressed. These include:\n\n\u2022 Regulation: Lack of clear and consistent regulations and legal frameworks for crypto assets custody, especially in different jurisdictions. Also, crypto as- sets custodians must comply with a rapidly evolving regulatory landscape, which can result in significant challenges and costs associated with the implemen- tation of security measures, reporting, and audits.\n\n\u2022 Security: Continuously improving the security of crypto assets custody systems to stay ahead of cyber threats and hacking attacks. This includes secure storage, generation, and management of private keys, and reduced risk of insider threats.\n\n\u2022 Privacy and data protection: Crypto assets custo- dians must protect the privacy and confidentiality of their clients\u2019 information and transactions, and comply with data protection regulations.\n\n\u2022 Insurance: Developing insurance products specifi- cally designed for crypto assets custody to provide adequate coverage.\n\n\u2022 Scalability: Addressing the scalability challenges posed by the growing demand for custody services and the increasing complexity of the crypto asset market.\n\n\u2022 Transparency: Providing more transparent reporting and accountability to clients, including the auditing and tracking of assets.\n\n\u2022 Cost: Finding a balance between providing com- petitive pricing for custody services and covering operational expenses and potential risks.\n\nXII. CONCLUSION\n\nWe believe that secure custodial solutions are a core building block for the development of an overall crypto assets\u2019 ecosystem for the future tokenized economy. One of the key challenges currently facing digital as- set custodians is striking the correct balance between usability and safety. Crypto asset transactions need to be conducted with maximum efficiency, whilst ensuring that no loss or theft of assets occurs. Finally, despite the substantial advancements in the creation of crypto assets custody solutions, several unresolved challenges remain to be tackled.\n\nREFERENCES\n\n[1] X. Huang, J. Lin, and P. Wang, \u201cAre institutional investors marching into the crypto market?\u201d Economics Letters , vol. 220, p. 110856, Nov. 2022.\n\n[2] W. Sun, A. T. Dedahanov, H. Y. Shin, and W. P. Li, \u201cFactors affecting institutional investors to add crypto-currency to asset portfolios,\u201d The North American Journal of Economics and Finance , vol. 58, p. 101499, Nov. 2021.\n\n[3] \u201cDeloitte\u2019s 2021 global blockchain survey,\u201d 2021. [4] Y. Lindell and A. Nof, \u201cFast secure multiparty ECDSA with practical distributed key generation and applications to cryp- tocurrency custody,\u201d in Proceedings of the 2018 ACMSIGSAC Conference on Computer and Communications Security . ACM, Oct. 2018.\n\n[5] S.-F. Hsieh and G. Brennan, \u201cIssues, risks, and challenges for auditing crypto asset transactions,\u201d International Journal of Accounting Information Systems , vol. 46, p. 100569, Sep. 2022.\n\n[6] J.-P. Aumasson, A. Hamelink, and O. Shlomovits, \u201cA survey of ecdsa threshold signing,\u201d Cryptology ePrint Archive, Paper 2020/1390, 2020, https://eprint.iacr.org/2020/1390. [Online]. Available: https://eprint.iacr.org/2020/1390\n\n[7] V. Di Nicola, R. Longo, F. Mazzone, and G. Russo, \u201cResilient custody of crypto-assets, and threshold multisignatures,\u201d Mathematics , vol. 8, no. 10, 2020. [Online]. Available: https://www.mdpi.com/2227-7390/8/10/1773\n\n[8] R. Walker, R. Massey, A. Steele, T. Welmans, M. Robinson, E. Mourtil, M. Marzelli, L. Strauss, P. Calaquian, and K. Schul- hof, \u201cThe unique and complex considerations of digital asset custody,\u201d Journal of Securities Operations & Custody , vol. 13, no. 2, pp. 150\u2013162, 2021.\n\n[9] L. W. Cong and Y. Xiao, \u201cCategories and functions of crypto- tokens,\u201d in The Palgrave Handbook of FinTech and Blockchain . Springer International Publishing, 2021, pp. 267\u2013284.\n\n[10] V. D. Nicola, R. Longo, F. Mazzone, and G. Russo, \u201cResilient custody of crypto-assets, and threshold multisignatures,\u201d Mathe- matics , vol. 8, no. 10, p. 1773, Oct. 2020.\n\n[11] R. Cyrus, \u201cCustody, provenance, and reporting of blockchain and cryptoassets,\u201d in The Emerald Handbook on Cryptoassets: Investment Opportunities and Challenges . Emerald Publishing Limited, Jan. 2023, pp. 233\u2013248.\n\n[12] \u201cTrezor hardware wallet,\u201d https://trezor.io/, accessed: 16 Mar 2023.\n\n[13] \u201cLedger: Hardware wallet and cold wallet,\u201d https://www.ledger.com/, accessed: 16 Mar 2023.\n\n[14] \u201cZengo crypto wallet,\u201d https://zengo.com/, accessed: 16 Mar 2023.\n\n[15] \u201cQredo crypto infrastructure,\u201d https://www.qredo.com/, accessed: 16 Mar 2023.\n\n[16] A. G. Khan, A. H. Zahid, M. Hussain, and U. Riaz, \u201cSecurity of cryptocurrency using hardware wallet and QR code,\u201d in 2019 International Conference on Innovative Computing (ICIC) . IEEE, Nov. 2019.\n\n[17] S. Suratkar, M. Shirole, and S. Bhirud, \u201cCryptocurrency wallet: A review,\u201d in 2020 4th International Conference on Computer, Communication and Signal Processing (ICCCSP) . IEEE, Sep. 2020.\n\n[18] \u201cBitgo: securely access crypto,\u201d https://www.bitgo.com/, ac- cessed: 16 Mar 2023.\n\n[19] \u201cGemini: Cryptocurrency exchange,\u201d https://www.gemini.com/, accessed: 16 Mar 2023.\n\n[20] \u201cCoinbase custody,\u201d https://www.coinbase.com/prime/custody, accessed: 16 Mar 2023.\n\n[21] A. J. Cabrera-Gutierrez, E. Castillo, A. Escobar-Molero, J. A. Alvarez-Bermejo, D. P. Morales, and L. Parrilla, \u201cIntegration of hardware security modules and permissioned blockchain in industrial IoT networks,\u201d IEEEAccess , vol. 10, pp. 114 331\u2013 114 345, 2022.\n\n[22] H. Rezaeighaleh and C. C. Zou, \u201cNew secure approach to backup cryptocurrency wallets,\u201d in 2019 IEEEGlobal Communications Conference (GLOBECOM) . IEEE, Dec. 2019.\n\n[23] A. Shamir, \u201cHow to share a secret,\u201d Communications of the ACM , vol. 22, no. 11, pp. 612\u2013613, Nov. 1979.\n\n[24] J. Han, M. Song, H. Eom, and Y. Son, \u201cAn efficient multi- signature wallet in blockchain using bloom filter,\u201d in Proceedings of the 36th Annual ACMSymposium on Applied Computing . ACM, Mar. 2021.\n\n[25] S. Ebrahimi, P. Hasanizadeh, S. M. Aghamirmohammadali, and A. Akbari, \u201cEnhancing cold wallet security with native multi- signature schemes in centralized exchanges,\u201d 2021.\n\n[26] S. Ricci, P. Dzurenda, R. Casanova-Marqu\u00b4es, and P. Cika, \u201cThreshold signature for privacy-preserving blockchain,\u201d Busi- ness Process Management: Blockchain, Robotic Process Au- tomation, and Central and Eastern Europe Forum. Springer International Publishing , pp. 100\u2013115, 2022.\n\n[27] Y. Lindell, A. Nof, and S. Ranellucci, \u201cFast secure multiparty ecdsa with practical distributed key generation and applications to cryptocurrency custody,\u201d 2018, https://eprint.iacr.org/2018/987. [Online]. Available: https://eprint.iacr.org/2018/987\n\n[28] A. Afshar, P. Mohassel, B. Pinkas, and B. Riva, \u201cNon-interactive secure computation based on cut-and-choose,\u201d in Advances in Cryptology \u2013 EUROCRYPT 2014 , P. Q. Nguyen and E. Oswald, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2014, pp. 387\u2013404.\n\n[29] R. Gennaro and S. Goldfeder, \u201cOne round threshold ecdsa with identifiable abort,\u201d 2020. [Online]. Available: https://eprint.iacr.org/2020/540\n\n[30] R. Canetti, N. Makriyannis, and U. Peled, \u201cUc non- interactive, proactive, threshold ecdsa,\u201d Cryptology ePrint Archive, Paper 2020/492, 2020, https://eprint.iacr.org/2020/492. [Online]. Available: https://eprint.iacr.org/2020/492\n\n[31] G. Castagnos, D. Catalano, F. Laguillaumie, F. Savasta, and I. Tucker, \u201cBandwidth-efficient threshold ec-dsa revisited: Online/offline extensions, identifiable aborts, proactivity and adaptive security,\u201d Cryptology ePrint Archive, Paper 2021/291, 2021, https://eprint.iacr.org/2021/291. [Online]. Available: https://eprint.iacr.org/2021/291\n\n[32] A. Gagol, J. Kula, D. Straszak, and M. Swietek, \u201cThreshold ecdsa for decentralized asset custody,\u201d Cryptology ePrint Archive, Paper 2020/498, 2020, https://eprint.iacr.org/2020/498. [Online]. Available: https://eprint.iacr.org/2020/498"
    },
    {
        "number": 1570886657,
        "title": "A Proposed Architecture for Securing Fintech Applications Using Hyperledger Fabric in Hybrid Cloud",
        "abstract": "The possibility of making secure transactions and keeping funds securely in fintech services highly depends on the application layer's security measures. The growth of cutting-edge technologies makes many options open to adopting a secure architecture for fintech organizations. However, most financial organizations still use conventional architecture for fintech applications in terms of developing and hosting. The study proposes a comprehensive architecture based on consortium blockchain, hyperledger fabric in a hybrid cloud environment. The proposed architecture is a theoretical approach. Nevertheless, consortium blockchain and hybrid cloud performance to secure any application are already proved individually in different fields. The research team also compares existing architecture and proposes one for evaluation. Hence, adopting this architecture will level up one step ahead for making safe transactions and securing funds and data in this cyber world.",
        "review": {
            "strength": [
                "1. Security of fintech application is well emphasized.\n2. The related work about Hyperledger Fabric and Hybrid Cloud is well researched.",
                "There are no strengths to the paper. The paper claims to focus on securing fintech applications but lacks any detail whatsoever of security protocols. A high-level architecture is proposed with little detail and no implementation or results.",
                "The paper proposes an architecture based on hyperledger fabric in a hybrid cloud environment."
            ],
            "shortcoming": [
                "1. References about related work is enough, but there should be included more references in \u201dExisting Architecture\u201d and \u201cComparison\u201d section. For example, the performance comparison of Node.js framework and Java should be included.\n2. In \u201cExisting Architecture\u201d and \u201cComparison\u201d section, the paper described too simply. There is no detail about existing fintech applications.\n3. Proposed architecture only shows high-level overview. It must need more details about the architecture.\n4. Figure 1, 2 is just part of the figure 3.",
                "- No clear discussion on research issues. \n- the proposed architecture is hardly novel.\n- no specific research discussions. \n- no implementation\n- no evaluations",
                "The proposed architecture is a theoretical approach, there is no simulation nor application nor results."
            ],
            "comment": [
                "1. Recommend spacing paragraph for introduction and proposed architecture part.\n2. Introduction B \u2013 Consortium Blockchain 4th row, The -> the\n3. The order of related work looks too crowded. It should be better to group the same category.",
                "The paper does not read like a research article but rather a high-level magazine article. The authors are urged to read articles published at prior ICBC conferences.",
                "The paper proposes an architecture based on hyperledger fabric in a hybrid cloud environment.\nThe proposed architecture is a theoretical approach, there is no simulation nor application nor results."
            ],
            "score": {
                "Relevance": 2.0,
                "Content and originality": 2.0,
                "Reference": 3.0,
                "Overall recommendation": 1.7,
                "Poster acceptance": 3.0
            }
        },
        "body": "I. INTRODUCTION\n\nIn this era of technology, it is tough to think of even a single day without making any online transactions. Hence, a good number of companies are founded based on financial services. Some offer regular banking services, and some offer more than those. Some financial companies are not typical banks, but they offer core services like cash in, cash out, and real-time transfer of funds. These centralized-based financial services make life easier to live. When COVID-19 hit the sudden world pandemic all over the world, cashless practice becomes more popular. Nevertheless, the fact is that the risk factors of using online or mobile-based financial services are also higher in any number. Service providers may only offer a partial hundred percent secure financial services. It is because the possibility of a safe transaction depends on so many factors. Some of them are absolutely in the hands of the service providers, whereas some depend on the end users. End users\u2019 risk factors can be mitigated by educating them about the latest cyberattacks and a surface-level idea of not falling into the trap of social engineering or other phishing attacks. However, the possibility of a safe transaction highly depends on the security measure of the application of the financial platform. Because of the many options for developing a fintech application, many different offerings and use cases are available there. However, even though there are a lot of tools and technologies out here, the number of architectures for developing a fintech application is a few. Moreover, to host the application, there are mainly only three options \u2013 public, private, or hybrid cloud. The research\n\nstudies different architectures and proposes a new cutting-edge technology, blockchain-based architecture in the hybrid cloud, to adopt for fintech applications.\n\nII. LITERATURE REVIEW\n\nA. Fintech\n\nFintech refers to incorporating technology into financial services provided by financial institutions such as traditional banks, mobile financial services, and e-money providers. The term was likely first used by Citicorp\u2019s chairman John Reed in the 1990s within the context of the Smart Card Forum [1]. The concept of fintech encompasses innovative financial services and business models that enhance the delivery, usage, and pro- cess of financial services [2]. The development of fintech has shifted the focus from internal solutions to customer-centric B2C and B2B solutions and inter-organizational provider- focused B2B solutions [3].\n\nB. Consortium Blockchain\n\nConsortium blockchain refers to a decentralized ledger system in which multiple organizations collaborate to verify transactions and maintain consensus on the network\u2019s transac- tions. In terms of blockchain technology The system combines the efficiency and privacy of private blockchains with the decentralization and transparency of public blockchains [4]. The use of consortium blockchains in the financial sector has improved the speed and efficiency of cross-border payments and reduced the risk of fraud. Several financial institutions, including the R3 consortium, are currently working on devel- oping a blockchain-based platform for cross-border payments [5].\n\nC. Hyperledger Fabric\n\nThe Hyperledger Fabric platform is a permissioned blockchain technology designed to facilitate the developing and deployment of secure, scalable, and highly customizable blockchain applications. In addition to being part of the open-source Hyperledger project family, Fabric provides a robust framework for developing and deploying enterprise- grade blockchain systems [6]. This technology supports the execution of distributed applications written in standard pro- gramming languages, which is one of the key innovations of Fabric. This allows multiple nodes to execute these ap- plications consistently, giving the impression that they are being executed on a single globally distributed blockchain\n\ncomputer. This unique feature differentiates Fabric from other blockchain platforms and makes it a highly attractive option for organizations seeking to implement blockchain solutions [7].\n\nD. Hybrid Cloud\n\nThis technology architecture combines the advantages of both public and private cloud computing. A hybrid cloud com- puting system incorporates public, private, and on-premises infrastructure. This architecture provides a coordinated, man- aged, and portable experience across all components. This configuration allows organizations to benefit from the strengths of both on-premises and public cloud environments, creating a flexible and secure infrastructure [8]. The hybrid cloud com- bines the strengths of public and private cloud environments, leveraging the resource scalability of public clouds and the control of private clouds to create a more cost-effective and flexible solution [9]. In a typical hybrid cloud setup, critical data are hosted on a private cloud, while other data are hosted on a public cloud which offers an effective solution for privacy protection.\n\nE. Related Works\n\nAccording to X. Huang and X. Du, 2013, the commonly used approach for data privacy protection is using crypto- graphic algorithms, which come with the drawback of in- tensive computation. As an alternative, this study suggested implementing a hybrid cloud consisting of public and pri- vate clouds, where sensitive data is separated and only non- sensitive data is outsourced to the public cloud [10]. The research team introduced a novel scheme to ensure data privacy, The scheme\u2019s effectiveness is tested in real-world network environments such as Amazon EC2. In their study, Y.-T. Lee et al. (2020) presented a blockchain- based time bank system built using the Hyperledger Fabric framework. The system utilizes blockchain technology to execute and record services and focuses on using autonomous smart contracts and a Hyperledger Fabric-based banking sys- tem comprising three distinct channels [11]. In another study, McSeth Antwi et al., 2021, evaluated the suitability of private blockchain technologies for healthcare applications. The team conducted experiments using Hyper- Ledger Fabric to test various criteria and use cases for health- care applications. The evaluation results indicated the potential advantages of private blockchain technologies, including com- patibility, scalability, and security [12]. In the study conducted by Elghaish et al. (2022), a new financial management system utilizing Hyperledger fabric and chain code technology was proposed to tackle challenges in financial management practices within construction projects [13]. In another research, Shanmugapriya and Kavitha (2019) inves- tigated the application of big data analytics in the healthcare industry. The study strongly emphasized the importance of implementing hybrid cloud computing for the secure storage of private healthcare data [14]. The proposed model mainly\n\nfocuses on a tri-party authenticated key-agreement protocol based on bilinear pairing cryptography for secure communica- tion and a decoy technique for data protection. In their model, the decoy technique features the display of decoy files to potential attackers while the original data remains hidden and encrypted, providing complete security for patient information. The proposed method is efficient and offers double security by granting access to the original data only to authorized users. The study by Son et al., (2019) showed a novel access control system named \u201dAccess Control Model in Hybrid Cloud for Healthcare Systems,\u201d which is proposed to tackle the threat of cyber crimes and security vulnerabilities in the system [15]. The proposed system comprises two levels of access control: i) safeguarding shared patient data shared among hospitals and ii) securing private patient information that the treating physician can only access. The model was tested in a real- case application and shown to manage security and privacy concerns at both levels effectively. The study conducted by Darwish et al., (2020) introduced a blockchain-based hybrid algorithm to improve privacy in the existing system. The proposed algorithm mainly focuses on a hybrid encryption technique and generates a unique digital signature for data before it is outsourced to data centers [16].\n\nIII. EXISTING ARCHITECTURE\n\nThe existing software development ecosystem is so vast. The availability of many frameworks, libraries, and other tools makes it tougher to pick the suitable one. There is no clear winner of which language, framework, or library is the best for creating software, whether it is a fintech application or anything else. However, among all of them, Node.js, Django, Spring, and ASP.NETCore are the topmost frameworks that are widely used in fintech applications.\n\nA. Blockchain Based Applications\n\nThere are a good number of blockchain-based applications in the industry. Even though blockchain was mainly imple- mented to develop crypto offerings like Bitcoin and Ethereum, nowadays, the usability of blockchain is accepted in almost every niche sector in the fintech ecosystem.\n\nB. Different Categories of Blockchain\n\nThere are mainly four types of blockchains currently available. Some uses cases in fintech and cryptocurrency of blockchains are given below\n\n\u2022 Public Blockchain: Bitcoin, Ethereum\n\n\u2022 Private Blockchain: Ethereum Private Network\n\n\u2022 Hybrid Blockchain: Swisscoin\n\n\u2022 Consortium Blockchain: Hyperledger Fabric\n\nC. Cloud Based Applications\n\nNowadays, it is almost impossible to think of any global or well-recognized app-based fintech service providers without having its backend hosted in any cloud platform. So, it can be said that almost every fintech application has some of its existence in cloud-based platforms.\n\nIV. PROPOSED ARCHITECTURE\n\nThe sole purpose of the study is to propose a new archi- tecture based on Consortium Blockchain, Hyperledger Fabric in Hybrid Cloud. The Core part of the architecture is the implementation of Hyperledger Fabric in the Fintech Platforms or Applications. As discussed in the previous section, one of the best features of Hyperledger Fabric is a permission-based blockchain. Again, due to its modularity, it is possible for the typical financial organization, including fintech organizations and even regular banks, to adapt it for the departments inside the organization. For instance, the following [ Figure: 1 ] shows multiple departments of a fintech organization managed by Hyperledger Fabric.\n\nFig. 1. Single Organization\n\nIn addition, most of the fintech organizations and all the banks are somehow regulated by a country\u2019s central bank. To expand, Hyperledger Fabric is also implementable with a country\u2019s existing banking ecosystem. Because of its permission-based secure architecture, it is elementary for the ecosystem to implement governance regulation, which is important to a country\u2019s traditional banking system. The fol- lowing [ Figure: 2 ] shows how the central bank can regulate the regular bank and financial organizations using the consortium blockchain, Hyperledger Fabric.\n\nFig. 2. Central Bank\n\nHence, the research team shows how Hyperledger Fabric can be implemented in terms of a single organization as well as\n\nthe total banking ecosystem. The following [ Figure: 3 ] shows the combination of previously given two use cases and finally combining those into one.\n\nFig. 3. Central Bank Network\n\nHowever, one of the biggest challenges of any organization, including Fintech, is to secure the data storage volume no matter which architecture it follows. In order to tackle this, some of them use an on-premises data center, and others rely on public cloud offerings. However, the fact is, in both cases, there are some pros and cons. The biggest problem with using an on-premises data center is the initial cost, capital cost, or CAPEX. On the other hand, managing this kind of server or data center is also a challenging task. Lastly, high availability is nearly impossible for on-premises solutions, even after ensuring everything. In terms of the public cloud, it solves a good number of obstacles. Among them, high availability, elasticity, and easily accessible new services are the main concerns that attract the organization for picking public cloud over alternative ones. Nevertheless, the biggest issue with the public cloud is that the primary or the physical location of the data is outside the organization or mostly far from the organization. Furthermore, sometimes it is outside of the organization\u2019s primary country. The research team considers the issue in the topmost position and finally proposes a new proposal where Hyperledger Fabric can be implemented in Hybrid Cloud architecture. The team thinks picking one of the existing offerings for hosting the fintech applications is not optimal. Instead, if the benefits of both on-premises and public cloud can be achieved by ensuring the safety concern of the storage location, then it would be a great combination. To achieve the goal, the research team proposes some parts of the platform to keep on-premises, and some parts should be in the public cloud. In terms of any Fintech application, when any request comes to clients like mobile, browser, or desktop apps, it will first go through the Node.js-based API. The API will handle the router or any other operations and business logic. To host the API, any company may use any preferable hosting service, whether on the public cloud or on-premises. Then, the research team proposes implementing a Hyperledger Fabric network for the end users to make any successful transactions. This permission-based blockchain\n\nwill ensure security while making any transaction. To host Hyperledger Fabric with the help of Kubernetes Cluster, the research team proposes to use public cloud providers like IBM to implement this. It is because the computing power needed for this consortium blockchain is costly enough to set up on-premises. The research considers one of the most significant issues of the public cloud, which is a storage location and proposes to keep persistent volumes in the on- premises private cloud, which is attached to the Kubernetes Cluster. By adopting this architecture, any fintech Organization can ensure its security with the help of Hyperledger Fabric and mitigate the risk of the public cloud. The following [ Figure: 4 ] shows a high-level overview of the blockchain network of the proposed architecture.\n\nFig. 4. Blockchain Network\n\nIn addition, any fintech company may pick microservices over monolithic architecture to implement the proposed archi- tecture. While implementing the architecture in microservices, not all the services may not need Hyperledger Network.\n\nV. COMPARISON The proposed theoretical architecture uses cutting-edge technologies to gain benefits from them and make the fintech applications more secure for end-users.\n\n\u2022 Framework: The proposed architecture uses the Node.js framework, which is famous for its performance. Paypal, one of the vastly used financial service providers, mi- grated to Node.js from Java for better performance [17].\n\n\u2022 Consortium Blockchain: The architecture proposes to implement the application in consortium blockchain, Hy- perledger Fabric, which is a permission-based blockchain, has modularity and pluggable architecture [18].\n\n\u2022 Hybrid Cloud: The research team also proposes hybrid cloud architecture to host the fintech organization to gain the benefits of both public and private clouds. So, the proposed architecture is accepting all the benefits of cutting edge technologies and implement in a comprehensive way, hence, it is suggested to adopt the architecture for securing fintech applications.\n\nVI. FUTURE WORK The given architecture is a theoretical one, so the main future work that the research team focuses on is an industry- ready implementation of the proposed architecture. However,\n\ndue to the use of many cutting-edge technologies, one of the biggest challenges is to lower the cost.\n\nVII. CONCLUSION\n\nThe security of any fintech application is one of the biggest concerns for making a safe transaction nowadays. Even though there are a lot of frameworks and architectures for developing and hosting fintech applications, there are still some obstacles for all the existing architecture. The research team proposes a theoretical architecture that combines one of the fastest frameworks, consortium blockchain and hybrid cloud. Because of combining all of these in a single architecture, the research team proposes a comprehensive architecture for making the fintech applications more secure.\n\nREFERENCES\n\n[1] T. Puschmann, \u201cFintech,\u201d Business &; Information Systems Engineering , vol. 59, no. 1, pp. 69\u201376, 2 2017. [Online]. Available: http: //dx.doi.org/10.1007/s12599-017-0464-6\n\n[2] I. Goldstein, W. Jiang, and G. A. Karolyi, \u201cTo FinTech and Beyond,\u201d The Review of Financial Studies , vol. 32, no. 5, pp. 1647\u20131661, 04 2019. [Online]. Available: https://doi.org/10.1093/rfs/hhz025\n\n[3] A.-L. Mention, \u201cThe future of fintech,\u201d Research-Technology Management , vol. 62, no. 4, pp. 59\u201363, 2019. [Online]. Available: https://doi.org/10.1080/08956308.2019.1613123\n\n[4] O. Dib, K.-L. Brousmiche, A. Durand, E. Thea, and E. B. Hamida, \u201cConsortium blockchains: Overview, applications and challenges,\u201d Int. J. Adv. Telecommun , vol. 11, no. 1, pp. 51\u201364, 2018.\n\n[5] R. B\u00a8ohme, N. Christin, B. Edelman, and T. Moore, \u201cBitcoin: Economics, technology, and governance,\u201d Journal of Economic Perspectives , vol. 29, no. 2, pp. 213\u201338, May 2015. [Online]. Available: https://www.aeaweb.org/articles?id=10.1257/jep.29.2.213\n\n[6] H. Foundation, \u201cAbout \u2013,\u201d 9 2022. [Online]. Available: https: //www.hyperledger.org/about\n\n[7] E. Androulaki, A. Barger, V. Bortnikov, C. Cachin, K. Christidis, A. De Caro, D. Enyeart, C. Ferris, G. Laventman, Y. Manevich et al. , \u201cHyperledger fabric: a distributed operating system for permissioned blockchains,\u201d in Proceedings of the thirteenth EuroSys conference , 2018, pp. 1\u201315.\n\n[8] \u201cWhat is Hybrid Cloud? \u2014 IBM.\u201d [Online]. Available: https: //www.ibm.com/topics/hybrid-cloud\n\n[9] J. Lei, Q. Wu, and J. Xu, \u201cPrivacy and security-aware workflow scheduling in a hybrid cloud,\u201d Future Generation Computer Systems , vol. 131, pp. 269\u2013278, 2022. [Online]. Available: https://www. sciencedirect.com/science/article/pii/S0167739X22000279\n\n[10] X. Huang and X. Du, \u201cEfficiently secure data privacy on hybrid cloud,\u201d in 2013 IEEEInternational Conference on Communications (ICC) , 2013, pp. 1936\u20131940.\n\n[11] Y.-T. Lee, J.-J. Lin, J. Y.-J. Hsu, and J.-L. Wu, \u201cA time bank system design on the basis of hyperledger fabric framework,\u201d in 2020 IEEEInternational Conference on Blockchain and Cryptocurrency (ICBC) , 2020, pp. 1\u20133.\n\n[12] M. Antwi, A. Adnane, F. Ahmad, R. Hussain, M. Habib ur Rehman, and C. A. Kerrache, \u201cThe case of hyperledger fabric as a blockchain solution for healthcare applications,\u201d Blockchain: Research and Applications , vol. 2, no. 1, p. 100012, 2021. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S2096720921000075\n\n[13] F. Elghaish, F. Pour Rahimian, M. R. Hosseini, D. Edwards, and M. Shelbourn, \u201cFinancial management of construction projects: Hyperledger fabric and chaincode solutions,\u201d Automation in Construction , vol. 137, p. 104185, 2022. [Online]. Available:\n\nhttps://www.sciencedirect.com/science/article/pii/S0926580522000589\n\n[14] E. Shanmugapriya and R. Kavitha, \u201cMedical big data analysis: preserving security and privacy with hybrid cloud technology,\u201d Soft Computing , vol. 23, no. 8, pp. 2585\u20132596, 2 2019. [Online]. Available: http://dx.doi.org/10.1007/s00500-019-03857-z\n\n[15] H. X. Son, M. H. Nguyen, H. K. Vo, and T. P. Nguyen, \u201cToward an privacy protection based on access control model in hybrid cloud for healthcare systems,\u201d in International Joint Conference: 12th Interna- tional Conference on Computational Intelligence in Security for Infor- mation Systems (CISIS 2019) and 10th International Conference on EU- ropean Transnational Education (ICEUTE 2019) , F. Mart\u00b4\u0131nez \u00b4 Alvarez, A. Troncoso Lora, J. A. S\u00b4aez Mu\u02dcnoz, H. Quinti\u00b4an, and E. Corchado, Eds. Cham: Springer International Publishing, 2020, pp. 77\u201386.\n\n[16] M. A. Darwish, E. Yafi, M. A. Al Ghamdi, and A. Almasri, \u201cDecentralizing Privacy Implementation at Cloud Storage Using Blockchain-Based Hybrid Algorithm,\u201d Arabian Journal for Science and Engineering , vol. 45, no. 4, pp. 3369\u20133378, 2 2020. [Online]. Available: http://dx.doi.org/10.1007/s13369-020-04394-w\n\n[17] B. Schwartz, \u201cAnalysis of PayPal\u2019s Node-vs-Java benchmarks,\u201d 5 2020. [Online]. Available: https://orangematter.solarwinds.com/2013/ 12/09/analysis-of-paypals-node-vs-java-benchmarks/\n\n[18] \u201cWhat is hyperledger fabric? \u2014 IBM.\u201d [Online]. Available: https: //www.ibm.com/topics/hyperledger"
    },
    {
        "number": 1570886749,
        "title": "Gas Cost Analysis of Fractional NFT on the Ethereum Blockchain",
        "abstract": "With the advent of NFT which proves the ownership of assets, security tokens that enable transactions without intermediaries are becoming a hot topic. By tokenization, there is no need for centralized markets, and it enables fast trades. In addition to tokenization, there are also attempts to increase the liquidity of assets by fractionalizing them. This is called fractional ownership. Even though there are already some platforms in service that use tokenization and fractional ownership, not much research has been done on fractional NFT. Fractional NFT is also still lacking institutionally. For this reason, we analyze fractional NFT in this paper. Since most of the NFTs in the world are minted based on the Ethereum blockchain, we implement fractional NFTs based on ERC standards. We also evaluate the gas cost of the implementation because gas cost plays an important role in providing fractional NFT-related services. Our evaluation results show that the gas cost is the lowest when NFTs of ERC-721 or ERC-1155 are fractionalized into FTs of ERC-20 in the long-term view.",
        "review": {
            "strength": [
                "-The paper presents an interesting empirical analysis of gas costs for Fractional NFTs on the Ethereum Blockchain. \n- Extensive results are generated",
                "Provides a clear explanation of the process and implementation methods for fractional NFTs.\nIncludes a comparison of gas consumption for four different implementation methods.\nIncludes technical details and code examples for smart contract development.\nFocuses on the popular Ethereum blockchain and its ERC standards for NFTs.\nBrings up a very timely topic.",
                "The authors provide insights into the gas of fractional NFT implementation on the Ethereum blockchain. It can be served as a reference for future researchers",
                "- discusses a novel concept, the fractional NFT\n- many experimental results are presented"
            ],
            "shortcoming": [
                "- The topic is a little niche\n- It is interesting to see the results, but the implications are unclear. The question arises - \"So what\" ?",
                "The evaluation could be wider in terms of replicating the experiment and maybe trying different EVM networks, not just Ethereum mainnet.\nDiscussion on The merge and how it influenced the state on gas costs would be anticipated.\nMissing the state-of-the-art thought on fractional NFTs: https://www.paradigm.xyz/2021/10/ricks\nThe suggested concept of paper is not unique, and there were already gas estimation papers, therefore, the novelty could be questionable.",
                "Lack of concrete next action beyond the evaluation of other ERC standards and their gas cost, from the authors",
                "- the motivation for introducing fractional NFT standard is not given"
            ],
            "comment": [
                "This is a nice study but the authors may wish to consider how to take this forward. What insights can be drawn?",
                "The authors should at least mention, if not compare with existing approaches and discuss what new functions or outcomes are provided by the proposed approach and what are the problems which cannot be solved with existing approach but can be addressed by the proposed approach.\nMore research on fractionalization and its different aspects can bring a new point of view.\nMore methodology and technical details on evaluation and testing would be anticipated and also doing deeper comparison between, e.g., different EVM chains.",
                "Can the authors elaborate more on the next steps beyond the evaluation of other ERC standards and their gas cost?",
                "The description of the functions of all well-known Ethereum standard (ER-20, ER-721 and ERC-1155) is not necessary, instead improve Secion III."
            ],
            "score": {
                "Relevance": 2.5,
                "Content and originality": 2.5,
                "Reference": 3.0,
                "Overall recommendation": 3.0,
                "Poster acceptance": 4.0
            }
        },
        "body": "I. INTRODUCTION\n\nNon-fungible tokens (NFTs) [1] are tokens based on blockchain technology that cannot be duplicated, forged or tampered with. NFTs are commonly used for collecting and investment purposes, as well as for proving ownership of dig- ital or physical assets such as paintings and music. NFTs first gained widespread attention with CryptoKitties [2], followed by Axie Infinity [3] and Bored Ape Yacht Club [4]. According to statistics from CoinMarketCap [5], as of February 2023, the market cap of NFTs has reached $440 billion. Furthermore, the entire sales volume of NFTs, as provided by CryptoSlam [6], has reached $47.7 billion, with the Ethereum [7] blockchain accounting for a large portion of $36 billion. The sales volumes of Ronin [8], Solana [9], and Flow [10] were $4.2 billion, $3.7 billion, and $1.1 billion, respectively. However, the rapid rise of NFTs has also led to a sharp increase in their prices, which has coincided with the rise in the price of cryptocurrency. For example, CryptoPunk 5822 [11] was sold for $23 million, setting a new record for the highest price of an NFT, and NFTs valued at over $100,000 are still being traded. This phenomenon has made it increasingly difficult for people to participate in the NFT market, resulting in a decrease in NFT liquidity, as only a small number of\n\nwealthy individuals are able to trade NFTs. One possible solution to this problem is to fractionalize NFTs into multiple pieces, which is known as Fractional NFTs or F-NFTs [12]. To fractionalize an NFT, it is transferred to another smart contract and divided into multiple fungible tokens (FTs) [1] by minting multiple tokens through that smart contract. Each FT owner has ownership rights equal to the proportion of the FTs they own. Since each FT piece is a part of the original NFT, the price of one FT becomes very affordable. Therefore, fractional NFTs increase the liquidity of an asset by fractionalizing its ownership and lowering the price. When fractional NFTs are used, FT owners can exercise their rights in proportion to the amount they own. For example, RealT [13] is a platform that offers fractional real estate investment. It enables FT owners to earn rental income at regular intervals by fractionalizing real estate. In RealT, an FT issued through Ethereum is sold for around $50, and investors can earn about $5 per year through one FT. Investing in products at such a low cost is one of the advantages of fractional NFTs. In some cases, the fractionalized NFTs may need to be taken out of the smart contract when utilizing fractional NFTs. Fractional.art [14], one of the fractional NFT marketplaces, stores NFTs in a vault so that FTs can be issued based on them. These FTs are traded through the platform. Additionally, through Fractional.art, the NFT itself can also be purchased through an auction. If a buyer wants to purchase an NFT, they must pay the desired price through a smart contract, and an auction is held for a certain period of time. Owners who own FTs can vote in proportion to the amount of FT they own, and if more than half of the approval is obtained, the NFT is transferred to the buyer. FT holders can receive rewards by burning their FTs. Similar to Fractional.art, the process of restoring NFTs should also be considered when implementing fractional NFTs. Tokenization and fractional ownership of assets continue to garner a lot of attention. However, to the best of our knowledge, there is no research on fractional NFTs for frac- tional ownership despite the numerous studies on tokenization, such as [15] and [16]. In this paper, we summarize some Ethereum Request for Comment (ERC) [17] standards, which represent the majority of NFTs minted, and analyze how to 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nmint fractional NFTs based on them. We then analyze the pros and cons of each method and the differences in gas cost. Based on the gas cost evaluation, we propose the most efficient method for implementing fractional NFTs. The rest of this paper is organized as follows. In section II, we describe some representative ERC standards used in Ethereum-based blockchains that are required for minting fractional NFTs. In section III, we present and analyze some methods of minting fractional NFTs and their differences. Section IV evaluates the gas cost according to the implemen- tation methods. Section V discusses the evaluation results and limitations, followed by concluding this paper with possible future work.\n\nII. ERCS TANDARDS\n\nThe Ethereum blockchain features Ethereum Improvement Proposals (EIPs) [18], which are proposals aimed at enhancing Ethereum. EIPs can be freely proposed by the community and can be passed through consensus. Ethereum Request for Comment (ERC) is a set of standards passed through EIP that specifies regulations for developers at the application level. When implementing fractional NFT, it is crucial to choose the appropriate ERC standards for minting NFTs and FTs. ERC-20 [19], ERC-721 [20], and ERC-1155 [21] are the most commonly used standards among the many available ERC standards. Therefore, in this paper, we will focus on these three standards.\n\nA. ERC-20\n\nERC-20 is a token standard that deals with FTs and defines token transfer and authority approval. ERC-20 tokens are primarily traded through centralized exchanges (CEX) and decentralized exchanges (DEX) such as Uniswap [22]. Table I outlines some functions that are defined in the ERC-20 document. We can observe that only simple functions, such as transferring tokens or showing balance, are included.\n\nTABLEI ERC-20 FUNCTIONS\n\nFunction Description\n\ntotalSupply() public view returns (balance)\n\nReturns the number of total tokens\n\nbalanceOf( owner) public view returns (balance)\n\nReturns the balance of \u201d owner\u201d\n\ntransferFrom( from, to,\n\nvalue) public returns (bool)\n\nTransfers tokens from \u201d from\u201d to \u201d to\u201d with an amount of \u201d value\u201d\n\nfunction approve( spender,\n\nvalue) public returns (bool)\n\nGive permission to \u201d spender\u201d to transfer tokens of the operator with an amount of \u201d value\u201d\n\nB. ERC-721\n\nERC-721 is a standard for NFTs that is specifically designed for managing unique tokens. In contrast to ERC-20, ERC-721 has functions that are tailored for the ownership of NFTs. Because ERC-721 tokens are non-fungible, they are typically traded on marketplaces such as OpenSea [23]. Some of the\n\nfunctions defined in the ERC-721 standard are presented in Table II. Notably, unlike ERC-20, ERC-721 tokens do not require a value parameter because there can only be one token in an ERC-721 contract.\n\nTABLEII ERC-721 FUNCTIONS\n\nFunction Description\n\nbalanceOf( owner) exter- nal view returns (balance)\n\nReturns the balance of \u201d owner\u201d\n\nownerOf( tokenId) exter- nal view returns (address)\n\nReturns the owner of \u201d tokenId\u201d\n\nsafeTransferFrom( from,\n\nto, tokenId) external payable\n\nTransfers a token which is \u201d tokenId\u201d from \u201d from\u201d to \u201d to\u201d, Checks if \u201d to\u201d is an approved address\n\napprove( to, tokenId) ex- ternal payable\n\nGives permission to \u201d to\u201d to transfer a token which is \u201d tokenId\u201d\n\nsetApprovalForAll(\n\noperator, approved) external\n\nEnables or disables \u201d operator\u201d to transfer a token of \u201d approved\u201d\n\ngetApproved( tokenId) ex- ternal view returns (ad- dress)\n\nReturns all address which has the per- mission of a token which is \u201d tokenId\u201d\n\nisApprovedForAll(\n\nowner, operator) external view returns (bool)\n\nChecks if \u201d operator\u201d has the permis- sion of all tokens of \u201d owner\u201d\n\nC. ERC-1155 ERC-1155 is a standard that supports various types of tokens, including FT, NFT, and semi-fungible tokens that have mutable characteristics. Depending on the number of tokens that are minted, it can be treated as either NFT or FT. With ERC-1155, multiple types of tokens can be minted using only one smart contract, and they can be transferred all at once, resulting in lower transaction costs. While ERC-1155 tokens are also primarily traded in marketplaces like OpenSea, there are token swap protocols specifically designed for ERC-1155 tokens, such as Niftyswap [24]. Table III outlines some of the functions defined in the ERC-1155 document, and it is worth noting that ERC-1155 supports batch transfer, which enables the transfer of multiple tokens with varying values.\n\nTABLEIII ERC-1155 FUNCTIONS\n\nFunction Description\n\nbalanceOf( owner, id) ex- ternal view returns (bal- ance)\n\nReturns the balance of \u201d owner\u201d of \u201d id\u201d\n\nsafeTransferFrom( from,\n\nto, id, value, data) external\n\nTransfers \u201d id\u201d tokens from \u201d from\u201d to \u201d to\u201d with an amount of \u201d value\u201d with \u201d data\u201d\n\nsafeBatchTransferFrom(\n\nfrom, to, ids, values,\n\ndata) external\n\nTransfers multiple \u201d ids\u201d tokens from \u201d from\u201d to \u201d to\u201d with an amount of \u201d values\u201d with \u201d data\u201d\n\nsetApprovalForAll(\n\noperator, approved) external\n\nEnables or disables \u201d operator\u201d to transfer a token of \u201d approved\u201d\n\nisApprovedForAll( owner,\n\noperator) external view returns (bool)\n\nChecks if \u201d operator\u201d has the permis- sion of all tokens of \u201d owner\u201d\n\nIII. FRACTIONAL NFT\n\nA. Minting\n\nThe process of minting fractional NFTs can be divided into three steps, as shown in Fig. 1. The first step is to mint an NFT through a smart contract. The NFT minted in this way must be transferred and stored in the same smart contract that will mint the FTs for fractionalization. If multiple NFTs are stored in a single smart contract, the minted FTs become fractions of the bundle of NFTs. The second step is to mint multiple FTs from the smart contract where the NFTs are stored. This completes the minting process of the fractional NFT. For example, if 1,000 FTs are minted through a smart contract, one FT piece will be worth 1/1,000 of the NFT. FTs issued in this way can be transferred to others through transactions, and owners of FTs can acquire ownership that is proportional to the stake they own.\n\nFig. 1. Fractional NFTMinting Procedure\n\nB. Implementation Methods\n\nAs most NFTs are currently minted using Ethereum, our focus for implementing fractional NFT is on the ERC stan- dards. Specifically, we will be using ERC-721 and ERC-1155 standards to mint NFTs. Although ERC-721 is intuitive, it can be less efficient as only one NFT can be minted in one smart contract. However, it is still widely used. In contrast, ERC- 1155 allows multiple NFTs to be minted in one smart contract and one transaction, making it efficient and cost-effective. For minting FT, we will be using ERC-20 and ERC-1155. ERC-20 tokens can be traded through an exchange or token swap, while ERC-1155 tokens can be traded through a token marketplace. By combining these standards, fractional NFT can be implemented in four different ways.\n\n\u2022 ERC-721 NFT to ERC-20 FT\n\n\u2022 ERC-721 NFT to ERC-1155 FT\n\n\u2022 ERC-1155 NFT to ERC-20 FT\n\n\u2022 ERC-1155 NFT to ERC-1155 FTIt is important to note that the implementation details and associated gas costs may vary depending on the method used for fractional NFT implementation. Therefore, a sufficient\n\nunderstanding of the functions used in smart contracts based on the ERC standard is crucial. For instance, as shown in Table II, if an NFT minted by an ERC-721 contract is transferred to another smart contract using the safeTransferFrom function, the function first verifies whether the address corresponding to\n\nto has been approved. Since the address is a smart contract\u2019s address, it also needs to be checked whether the smart contract is authorized to own the token issued in the ERC-721 smart contract. To satisfy this condition, the smart contract must include the onERC721Received function to store the NFT.\n\nIV. GAS EVALUATION\n\nA. Gas\n\nGas is used in Ethereum to prevent Denial-of-Service (DoS) attacks, and the gas consumption of a transaction represents the amount of resources required to execute the transaction [25]. The gas price can vary depending on factors such as the price of Ethereum and network congestion. When using a DApp [26], users must pay gas fees and transaction costs to execute functions in a smart contract. Therefore, it is crucial to calculate the gas consumption of each function and optimize it when developing smart contracts. In this section, we will implement and measure the gas consumption of the four fractional NFT implementation methods introduced in Section III, and compare their gas efficiency.\n\nB. Environment Setup\n\nFor developing smart contracts and evaluating gas con- sumption, we utilized Hardhat [27], which is an Ethereum development environment that offers a wide range of features, from smart contract implementation to compiling, deploying, and testing. Hardhat also supports additional features through various plugins. To measure the gas consumption of our contracts, we used the \u201dhardhat-gas-reporter\u201d plugin [28]. This plugin facilitates gas evaluation by measuring the amount of gas consumed during the deployment of a smart contract or the execution of a function within a smart contract. For this evaluation, we calculated the gas consumption with the average value obtained by running the test 200 times.\n\nC. Smart Contracts\n\nTo implement the four methods for fractional NFTs, we developed seven smart contracts. First, we implemented an ERC-721 contract and an ERC-1155 contract for minting NFTs. Then, we implemented four types of contracts to transfer the minted NFTs so that FTs could be minted. When using ERC-1155 to fractionalize NFTs, it is possible to handle it within a single smart contract. Therefore, we implemented both the NFT minting function and the FT minting function in the ERC1155a contract to compare the gas cost of using one smart contract versus using two separate contracts. To evaluate the gas cost of each contract, we only implemented the necessary functions. Fig. 2 provides a brief overview of the seven smart contracts.\n\nimport ERC721 . s o l\n\nc o n t r a c t ERC721 {\n\nf u n c t i o n mintNFT ( tokenId )\n\n}\n\n(a) ERC721 Contract\n\nimport ERC1155 . s o l c o n t r a c t ERC1155 {\n\nf u n c t i o n mintNFT ( tokenId )\n\n}\n\n(b) ERC1155 Contract\n\nimport ERC20 . s o l import ERC721 . s o l import ERC721Holder . s o l\n\nc o n t r a c t ERC721toERC20 {\n\nf u n c t i o n mintFT ( nft , totalSupply , tokenId )\n\n}\n\n(c) ERC721 to ERC20 Contract\n\nimport ERC721 . s o l import ERC721Holder . s o l\n\nimport ERC1155 . s o l\n\nc o n t r a c t ERC721toERC1155 {\n\nf u n c t i o n mintFT ( nft , totalSupply , tokenId )\n\n}\n\n(d) ERC721 to ERC1155 Contract\n\nimport ERC20 . s o l import ERC1155 . s o l import ERC1155Holder . s o l\n\nc o n t r a c t ERC1155toERC20 {\n\nf u n c t i o n mintFT ( nft , totalSupply , tokenId )\n\n}\n\n(e) ERC1155 to ERC20 Contract\n\nimport ERC1155 . s o l import ERC1155Holder . s o l\n\nc o n t r a c t ERC1155toERC1155 {\n\nf u n c t i o n mintFT ( nft , totalSupply , tokenId )\n\n}\n\n(f) ERC1155 to ERC1155 Contract\n\nimport ERC1155 . s o l import ERC1155Holder . s o l\n\nc o n t r a c t ERC1155a {\n\nf u n c t i o n mintNFT ( tokenId )\n\nf u n c t i o n mintFT ( nft , totalSupply , tokenId )\n\n}\n\n(g) ERC1155a Contract\n\nFig. 2. Smart Contracts\n\nD. Gas Evaluation in Smart Contract Deployment\n\nIn the first step, we measured the amount of gas con- sumed when deploying the seven contracts. The results are shown in Table IV. The difference in gas cost between the ERC721 contract and the ERC1155 contract that mints NFTs was not significant. However, when ERC-1155 was used for contracts that minted FT, we observed an increase in\n\ngas cost of about 100,000, comparing ERC721toERC20 and ERC721toERC1155 . This is because ERC-1155 has many in- ternal functions, and therefore, a lot of resources are utilized in the distribution process. Specifically, when attempting to store ERC-1155-based NFTs in a contract, the gas cost increased significantly by 500,000, comparing ERC721toERC1155 and ERC1155toERC1155 .\n\nTABLEIV GAS COST IND EPLOYMENT\n\nToken Type Smart Contract Name Average Gas Cost\n\nNFTERC721 1,182,263\n\nNFTERC1155 1,209,787\n\nFTERC721toERC20 699,289\n\nFTERC721toERC1155 816,133\n\nFTERC1155toERC20 1,292,655\n\nFTERC1155toERC1155 1,294,419\n\nNFT+FTERC1155a 1,306,984\n\nE. Gas Evaluation in Token Minting\n\nNext, we measured the gas consumption when minting NFTs and FTs in each contract. Table V shows that when NFTs were minted based on ERC-1155, the gas cost was about 20,000 less than using ERC-721, comparing ERC721 and ERC1155 . Similarly, for FTs, the gas cost of ERC-1155 was also about 20,000 less than using ERC-20, comparing ERC721toERC20 and ERC721toERC1155 . During the minting process, the cost of minting FTs was higher than the cost of minting NFTs. This is because the cost of minting FTs includes the cost of transferring NFTs into the contract.\n\nTABLEV GAS COST INM INTING\n\nToken Type Smart Contract Name Average Gas Cost\n\nNFTERC721 68,355\n\nNFTERC1155 47,054\n\nFTERC721toERC20 107,655\n\nFTERC721toERC1155 87,090\n\nFTERC1155toERC20 102,600\n\nFTERC1155toERC1155 81,968\n\nNFTERC1155a 47,143\n\nFTERC1155a 79,467\n\nF. Gas Evaluation in Token Approval\n\nWhen an NFT is stored in a contract for fractionalization, the contract becomes the owner of the NFT. Therefore, in order to later take the NFT out of the contract, it is necessary to pre-approve the address of the contract. After measuring the amount of gas consumed in this process, Table VI shows that a smaller amount of gas was consumed in the ERC-1155 token. The gas cost was approximately 49,000 for the ERC- 721 token and about 46,000 for the ERC-1155 token.\n\nTABLEVI GAS COST INA PPROVAL\n\nToken Type Smart Contract Name Average Gas Cost\n\nNFTERC721 48,719\n\nNFTERC1155 46,199\n\nNFTERC1155a 46,155\n\nG. Gas Evaluation in Token Transfer\n\nIn the final step, we measured the gas cost of transferring NFTs and FTs in each contract. In DApps that use fractional NFTs, the contract deployment and token minting processes are executed only once during the initial phase. However, token transfers are frequently called for trading purposes or storing tokens in smart contracts. Therefore, the transfer function is a crucial factor in the overall gas cost. Table VII shows that similar amounts of gas were consumed when transferring the same type of token. The gas cost for ERC-20 tokens was about 46,500, for ERC-1155 tokens it was about 52,000, and for ERC-721 tokens it was about 55,000 gas.\n\nTABLEVII GAS COST INT RANSFER\n\nToken Type Smart Contract Name Average Gas Cost\n\nNFTERC721 55,324\n\nNFTERC1155 52,036\n\nFTERC721toERC20 46,600\n\nFTERC721toERC1155 52,048\n\nFTERC1155toERC20 46,541\n\nFTERC1155toERC1155 52,070\n\nNFT+FTERC1155a 52,070\n\nH. Overall Gas Evaluation\n\nTable VIII summarizes the gas costs for the four fractional NFT implementation methods. When minting NFTs based on ERC-1155, a significant amount of gas is consumed for the initial contract deployment. Although the gas cost for the remaining parts is lower than ERC-721, the overall gas cost for ERC-1155 is still higher than ERC-721. When minting FTs based on ERC-1155, the cost is lower than ERC-20 in the minting or approval process. However, the gas cost of ERC-20 is lower than ERC-1155 in the FT transfer process. For minting both NFTs and FTs with ERC-1155, using one contract or two contracts did not show a big difference except for the gas cost of deployment.\n\nV. DISCUSSION\n\nA. Summary\n\nIn summary, the gas cost for each fractional NFT imple- mentation method was analyzed, and it was found that minting both NFT and FTs with ERC-1155 is the least costly. However, this method has limitations when it comes to fractionalizing NFTs minted by different smart contracts, and the gas cost of\n\nFT transfer is the most important factor to consider for the overall gas cost. Therefore, minting NFTs with either ERC- 721 or ERC-1155 and minting FTs with ERC-20 can be a good alternative for long-term cost-effectiveness.\n\nB. Limitation\n\nIt should be noted that our gas evaluation was based on the assumption that only one NFT is minted in each smart contract. However, ERC-1155 allows for the minting of multiple NFTs and FTs in one contract, enabling batch transfers of multiple types of tokens in a single transaction. Thus, when minting multiple types of tokens in one contract and trading them simultaneously, it may be more advantageous to use ERC-1155 for minting FTs. While this paper focused on ERC-20, ERC-721, and ERC- 1155 as the most representative ERC standards, there are other standards available for minting NFTs and FTs. For instance, ERC-777 [29] has been introduced as a replacement for ERC- 20, while ERC-998 [30] extends the functionality of ERC-721. Therefore, further analysis and evaluation will be necessary for these other standards in the future.\n\nVI. CONCLUSION\n\nAs tokenization and fractional ownership of assets gain increasing attention, there is a need for detailed research and discussions on their implementation. This paper provides a summary of fractional NFT and outlines four methods for implementing it using ERC-20, ERC-721, and ERC-1155. We also evaluated the gas costs of each method and found that the most profitable approach is to mint NFTs with ERC-721 or ERC-1155 and FTs with ERC-20. However, since not all ERC standards are covered in this paper, our future work includes providing broader information on fractional NFT, investigating other ERC standards, and evaluating gas costs in different environments. Additionally, we plan to add more functions, such as burning FTs and reconstructing NFTs, to our implementation and explore other metrics for evaluation. We hope that our analysis will contribute to further research on fractional NFT.\n\nACKNOWLEDGMENT\n\nThis work was supported by Coinone and Smart HealthCare Program(www.kipot.or.kr) funded by the Korean National Po- lice Agency(KNPA, Korea) [Project Name: Development of an Intelligent Big Data Integrated Platform for Police Officers\u2019 Personalized Healthcare / Project Number: 220222M01]\n\nREFERENCES\n\n[1] Wang, Qin, et al. \u201dNon-fungible token (NFT): Overview, evaluation, opportunities and challenges.\u201d arXiv preprint arXiv:2105.07447 (2021).\n\n[2] Evans, Tonya M. \u201dCryptokitties, cryptography, and copyright.\u201d AIPLAQJ 47 (2019): 219.\n\n[3] Alam, Omar. \u201dUnderstanding the economies of blockchain games: An empirical analysis of Axie Infinity.\u201d (2022).\n\n[4] Lee, Edward. \u201dThe bored ape business model: Decentralized collabora- tion via blockchain and nfts.\u201d Available at SSRN 3963881 (2021).\n\n[5] CoinMarketCap, [Online]. Available: https://coinmarketcap.com/ (Ac- cessed: 02.03.2023)\n\nTABLEVIII OVERALL GAS COST\n\nFractional NFTDeploy Mint Approve NFTTransfer FTTransfer\n\nERC-721 to ERC-20 1,881,552 176,010 48,719 55,324 46,600\n\nERC-721 to ERC-1155 1,998,396 155,445 48,719 55,324 52,048\n\nERC-1155 to ERC-20 2,502,442 149,654 46,199 52,036 46,541\n\nERC-1155 to ERC-1155(two contracts) 2,504,206 129,022 46,199 52,036 52,070\n\nERC-1155 to ERC-1155(one contract) 1,306,984 126,610 46,155 52,070 52,070\n\n[6] CryptoSlam, [Online]. Available: https://www.cryptoslam.io/ (Accessed: 02.03.2023)\n\n[7] Wood, Gavin. \u201dEthereum: A secure decentralised generalised transaction ledger.\u201d Ethereum project yellow paper 151.2014 (2014): 1-32.\n\n[8] Ronin, [Online]. Available: https://litepaper.roninchain.com/ (Accessed: 02.03.2023)\n\n[9] Solana, [Online]. Available: https://solana.com/ (Accessed: 02.03.2023)\n\n[10] Flow, [Online]. Available: https://flow.com/ (Accessed: 02.03.2023) [11] Lyubchenko, Irina. \u201dNFTs and Digital Art: 21st Century Avant-Garde Impulse?.\u201d M/CJournal 25.2 (2022).\n\n[12] Herian, Robert, et al. \u201dNFT\u2013Legal Token Classification.\u201d EUBlockchain Observatory Forum, 2021.\n\n[13] RealT, [Online]. Available: https://realt.co/ (Accessed: 02.03.2023) [14] Fractional.art, [Online]. Available: https://fractional.art/ (Accessed: 02.03.2023)\n\n[15] Konashevych, Oleksii. \u201dGeneral concept of real estate tokenization on blockchain.\u201d European property law journal 9.1 (2020): 21-66.\n\n[16] Saari, Anniina, Jussi Vimpari, and Seppo Junnila. \u201dBlockchain in real estate: Recent developments and empirical applications.\u201d Land Use Policy 121 (2022): 106334.\n\n[17] Ethereum Request for Comment, [Online]. Available: https://eips.ethereum.org/erc (Accessed: 02.03.2023)\n\n[18] Ethereum Improvement Proposals, [Online]. Available: https://eips.ethereum.org/ (Accessed: 02.03.2023)\n\n[19] ERC-20, [Online]. Available: https://eips.ethereum.org/EIPS/eip-20 (Ac- cessed: 02.03.2023)\n\n[20] ERC-721, [Online]. Available: https://eips.ethereum.org/EIPS/eip-721 (Accessed: 02.03.2023)\n\n[21] ERC-1155, [Online]. Available: https://eips.ethereum.org/EIPS/eip-1155 (Accessed: 02.03.2023)\n\n[22] Lehar, Alfred, and Christine A. Parlour. \u201dDecentralized exchanges.\u201d Available at SSRN 3905316 (2021).\n\n[23] OpenSea, [Online]. Available: https://opensea.io/ (Accessed: 02.03.2023)\n\n[24] Niftyswap, [Online]. Available: https://niftyswap.io/ (Accessed: 02.03.2023)\n\n[25] Signer, Christopher. Gas cost analysis for ethereum smart contracts. MS thesis. ETHZurich, Department of Computer Science, 2018.\n\n[26] Buterin, Vitalik. \u201dA next-generation smart contract and decentralized application platform.\u201d white paper 3.37 (2014): 2-1.\n\n[27] Hardhat, [Online]. Available: https://hardhat.org/ (Accessed: 02.03.2023) [28] hardhat-gas-reporter, [Online]. Available: https://github.com/cgewecke/hardhat-gas-reporter (Accessed: 02.03.2023)\n\n[29] ERC-777, [Online]. Available: https://eips.ethereum.org/EIPS/eip-777 (Accessed: 02.03.2023)\n\n[30] ERC-998, [Online]. Available: https://eips.ethereum.org/EIPS/eip-998 (Accessed: 02.03.2023)"
    },
    {
        "number": 1570886790,
        "title": "A Referable NFT Scheme",
        "abstract": "Existing NFTs confront restrictions of one-time incentive and product isolation. Creators cannot obtain benefits once having sold their NFT products due to the lack of relationships across different NFTs, which results in controversial profit sharing. This paper proposes a referable NFT solution to extend the incentive sustainability of NFTs. We construct the referable NFT (rNFT) network to increase exposure and enhance the referring relationship of inclusive items. We introduce the DAG topology to generate directed edges between each pair of NFTs with corresponding weights and labels for advanced usage. We accordingly implement and propose the scheme under Ethereum Improvement Proposal (EIP) standards, indexed in EIP-XX. Further, we provide the mathematical formation to analyze the utility for each rNFT participant. The discussion gives general guidance among multi-dimensional parameters. The solution, as a result, shape the recognition of potential values hidden in isolated NFTs and raise the interest of communities toward the discovery of NFT derivatives. To our knowledge, this is the first study to build a referable NFT network, explicitly showing the virtual connections among NFTs.",
        "review": {
            "strength": [
                "1. This paper proposes a referable NFT scheme for reference relationship between NFTs\n2. This paper well explains the design and implementation of the protocol, and its incentive analysis\n3. Contributions, challenges, and possible solutions are well-organized",
                "The paper presents a study of a referable NFT network that explicitly shows virtual connections between NFTs. The papier is well written and the idea is new.",
                "This paper proposes a way to create a cross-reference relationship between NFTs and share profits based on this. The idea presented is novel and there are no technical shortcomings in embodying this idea to a level that can be implemented and used on the blockchain.",
                "rNFT is a good idea for NFT profit sharing.This paper proposed a referable NFT(rNFT) solution to extend the incentive sustainability of NFTs, which build a referable NFT network showing the virtual connections among NFTs. Also, this paper  analyzed the utility for each rNFT participant by using a mathematical formation, and  provide the a couple of applicaitons of rNFT."
            ],
            "shortcoming": [
                "- The functions in this paper are not labelled",
                "The authors need to divide section 1 into two sections. The authors also need to explain how their proposal can help today in The paper presents 70% of similarities and for this reason, even it is a good paper, i cannot accept it.",
                "Fig. 1 contains the core of the idea presented. However, there is no explanation for the right part of the figure in the text. Adding an explanation for this will help the reader understand the paper.",
                "Any experiment or simulations results is not provided to prove the proposed rNFT works well and the participants gets benefits from the NFT network, even though the author implemented it. also, It is needed a comperison with other solutions for a NFT sharing."
            ],
            "comment": [
                "1. It would be better to add labels for the functions\n2. The introductions sections seems a little lengthy\n3. The sentence after income functions seems doesn\u2019t have to be italic",
                "The paper presents a study of a referable NFT network that explicitly shows virtual connections between NFTs. The papier is well written and the idea is new. \nThe authors need to divide section 1 into two sections. The authors also need to explain how their proposal can help today in the world of NFT.\nThe paper presents 70% of similarities and for this reason, even it is a good paper, i cannot accept it.",
                "In Section III, the incentive analysis is well done. Additionally, presenting examples of the use of parameters would be more intuitive than understanding them as formulas, which would benefit the reader.",
                "rNFT is a good idea for NFT profit sharing.This paper proposed a referable NFT(rNFT) solution to extend the incentive sustainability of NFTs, which build a referable NFT network showing the virtual connections among NFTs. Also, this paper  analyzed the utility for each rNFT participant by using a mathematical formation, and  provide the a couple of applicaitons of rNFT.\n\nAny experiment or simulations results is not provided to prove the proposed rNFT works well and the participants gets benefits from the NFT network, even though the author implemented it. also, It is needed a comperison with other solutions for a NFT sharing."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 3.5,
                "Reference": 3.5,
                "Overall recommendation": 3.3,
                "Poster acceptance": 3.3
            }
        },
        "body": "I. INTRODUCTION\n\nNon-fungible tokens (NFTs) [ 1 ] is built as EIP-721 [ 2 ] to exchange unique digital assets in the Ethereum platform [ 3 ]. It digitalizes on-chain assets into tokens, and specifies each token with a unique identifier tokenID within smart contracts. This significantly encourages and extends the on-chain token exchange from fungible to non-fungible ones which, not surprisingly, is now leading a wave of the next generation of a wide variety of applications covering virtual collectables, online tickets, digital arts, etc. Besides, NFT can be seamlessly incorporated with the protocols in decentralized finance (DeFi) [ 4 ] and the governance in blockchain communities [ 5 ]. To date 1 , a total of 33 , 651 , 380 of NFT sales has led to the traded volume reaching up to 20 billion USD. The phenomenal trading activities reflect a sharp shift from traditional markets into the new Web3 world [ 6 ]. However, the lack of relationships between an NFT and its owner in existing NFT standards could result in controversial profit sharing if the creation of a new NFT refers to previ- ous NFTs. The trades of NFTs are one-time in transferring and isolated across different users. An NFT creator cannot continuously obtain profits for his intellectual property once sold. The permanent reference relationship between NFTs, thus, becomes increasingly important. The reference topology will assist in establishing a sustainable incentive mechanism\n\n1 Data captured from https://nonfungible.com/reports [Q1-Q3 2022].\n\nto economically inspire more and more users to devote their contributions to using, creating, and promoting NFTs. To fill the gap, we propose EIP-5521 that defines a referable NFT token (rNFT) standard. It extends the static NFT into a virtually extensible NFT network. Users under clear ownership inheritance do not have to create work completely independent from others, avoiding reinventing the same wheel. Here, we summarise contributions as follows: Protocol Design (Sec. II ). Our referable NFT scheme estab- lishes the reference of ancestors when minting a new NFT with the reference relationship including both the referring and referred relationships, thus shaping a Direct Acyclic Graph (DAG) to represent the reference information. The scheme can provide reliable, trustworthy, and transparent historical records that every agreement can refer to in terms of profit sharing. Meanwhile, users are allowed to query, trace and analyze their relationship. Standard Implementation (Sec. II ). We implement a very succinct version and propose it to the Ethereum standard Git repository, indexed by EIP-5521 . Our simplified proposal is a smart-contract driven standard used as a system-level function on blockchains. It builds and retains the backward reference relationship between old works and new works and is compatible with existing mainstream standards. At the time of writing, rNFT has attracted consistent dis- cussions and attention on forums [ 7 ] and by several in- production projects (e.g., Briq [ 8 ]). Incentive Analysis (Sec. III ). We provide a clear and exact mathematical expression of the utility function of an rNFT user. rNFT helps to integrate multiple upper-layer incentive models and also involves multi-dimensional parameters. We accordingly analyze the payoff function under different pa- rameters. Chasing an optimal strategy for players is possible but without certainty. Further Discussions (Sec. IV ). We provide an in-depth discus- sion of our proposed scheme in terms of its opportunities and challenges. rNFT can promote a wide range of new NFT derivatives that requires historical relations but also confronts many pending aspects for discovery such as multi- contract or CC0 license development.\n\nAn Intuitive Instance. The constructed relationship topology between each NFT forms a DAG. By adding the referring indicator, users can mint new NFTs (e.g. C, D, E) by referring to existing NFTs (e.g. A, B), while referred enables the referred NFTs (A, B) to be aware that who has quoted it (e.g. A \u2190 D ; C \u2190 E ; B \u2190 E & A \u2190 E ). createdTimestamp is an 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nindicator, based on block timestamp, used to show the creation time of NFTs (A, B, C, D, E).\n\nExtending NFTDerivatives. Similar to traditional financial derivatives that are based on stocks, commodities, or other underlying assets, NFT derivatives mainly refer to financial instruments that center around the value of an underlying NFT asset. The key feature of these derivatives is to allow users to invest in NFTs without actually holding the physical NFT asset in the forms such as options, futures, swaps, and other financial instruments that are used for the trading or hedging of the underlying NFT asset\u2019s price. However, this requires a relatively comprehensive history of records and credits. rNFT provides a foundation for atop derivative protocols, as siting to offer more complex investment strategies and risk man- agement tools by establishing a reliable relationship among multiple linkable NFTs. The extension of NFT derivatives is an ongoing process and our solution gives an example for better connections.\n\nIntegration. Our scheme can be further integrated with main- stream techniques. We list two examples as the enlightenment. Firstly, the new rNFT can be combined with Graph Neural Network (GNN) [ 9 ] to achieve efficient queries and predictions of NFT. This is particularly useful for conducting automated labeling by NFT platforms such as OpenSea [ 10 ], or for NFT viewers to find more NFTs of the same kind. Secondly, AI detection [ 11 ] can be imported into the system for plagiarism detection, path recommendation, and strategy optimization. Due to the blur edges between the original artwork and copy-work, figure classification and identification in artificial intelligence is a fundamental tool for the detection of a rapidly growing NFT markets.\n\nBackward Compatibility. As in Sec. II , an rNFT implements the existing ERC-721 interfaces [ 2 ] to enable the backwards compatibility. This allows the proposed rNFT to be seam- lessly implemented on existing blockchain platforms such as Ethereum [ 3 ] where those existing ERC-721-compatible NFTs, such as the composable NFT: EIP-998 [ 12 ], can be referred by any subsequent rNFTs.\n\nRelated Standards (Tab. I ). A series of NFT-related stan- dards 2 haves been intensively proposed. We highlight the ones entering the final and last call stages due to their deterministic probability of being accepted by communities. (EIP-)3525 proposes the concept of semi-fungible token by introducing a triple scalar \u27e8 id, slot, value \u27e9 . ID acts the way as the 721 standards while additionally adding a quantitative feature value . 1155 proposes a multi-token standard that can combine either fungible tokens, non-fungible tokens, or other configurations (e.g. semi-fungible tokens). 2981 focuses on the royalty payment transferred between a buyer and a seller voluntarily. 4907 and 5006 propose rental NFTs by extending original settings with an additional role of user and a timing feature of expire . A user can only use an NFT within the expire duration, rather than transferring it. 2309 implements\n\n2 Captured from Ethereum ERCs https://eips.ethereum.org/erc [Dec 2022].\n\na consecutive transfer extension that enables batch creation, transfer, and burn methods by contract creators. The users can quickly and cheaply mint at most 2 256 tokens within one transaction. 4400 extends 721\u2019s customer role of being able to, for instance, act as an operator or contributor. 5007 introduces the functions of startTime and endTime set a valid duration that automatically enables and disables on-chain NFTs. 4906 extends the scope of Metadata that allows tracking changes by third-party platforms. 5192 proposes the idea of soulbound that binds an NFT to a single account, achieving special ap- plications such as non-transferable and socially-priced tokens. Besides, we also provide more related standards with indirect impacts on NFTs in Tab. I ).\n\nTABLEI: Summary of Token Standards\n\nStandard Platform Feature Application\n\nEIP721 Ethereum Non-Fungible Token Artwork/IPEIP777 Ethereum Token Approval EIP1155 Ethereum Adding an attribute for groups Game EIP3525 Ethereum Additional attribute for semi-fungible Finical Market EIP2981 Ethereum Retrieving the royalty payment info Royalty Payments EIP4907 Ethereum Adding a new role and timer Rental Market EIP5006 Ethereum Adding the new role of user Rental Market EIP2309 Ethereum Consecutive token identifiers Consecutive event EIP4400 Ethereum Extend the consumer\u2019s functionalities Authorization EIP5007 Ethereum On-chain time management Lend Market EIP4906 Ethereum Enable token metadata\u2019s update Upgrade EIP5192 Ethereum Bound to a single account Soulbound Items This work Ethereum Referable connections NFTGraph\n\nEIP20 Ethereum Token API / Fungible Token Vote/ICOEIP223 Ethereum Token Recovery EIP998 Ethereum Composable Non-Fungible Token Game/Ownership EIP1238 Ethereum Non-Transferrable Non-Fungible Token Badge EIP1594 Ethereum Security Token Standard Financial Securities EIP1400 Ethereum Security Token Standard Securities EIP1404 Ethereum Simple Restricted Token Standard Securities EIP1410 Ethereum Partially Fungible Token Standard EIP1462 Ethereum Base Security Token Securities\n\nBEP20 Binance Fungible Token Vote/Wrap Token BEP721 Binance Non-Fungible Token IPProducts ARC721 Avalanche Fungible Token Wrap Other Tokens\n\nII. PROTOCOL DESIGN ANDI MPLEMENTATION\n\nIn this section, we present the rNFT protocol, construction, and implementation, respectively.\n\nNotations. The notations used in this paper are listed as follows. t is the timestamp of the block header. TR means a transaction that packs a particular rNFT and B h,t is a block at the height of h released at time t . R represents the set of rNFTs, while R i,t, \u0398 is an rNFT released by user- i at time t with a set of \u0398 that contains both the referring and referred relationship, respectively, i.e., \u20d7 \u0398 and\n\n\u20d7\n\n\u0398 . Specifically, \u20d7 \u0398 represents a collection of referring relationships made by an rNFTR i,t, \u0398 that connects several previous rNFTs such as R i,t \u2032 , \u0398 where t \u2032 < t , denoted by the blue arrows in the rNFT-DAG, and\n\n\u20d7\n\n\u0398 follows the same notation with t \u2032 > t , and is accordingly updated when this gets referred by any future rNFTs. Note that the rNFT with | \u0398 | = 0 generally indicates an (claimed to be) original item. A i,j,k,... is an agreement involving user i , j , k , etc. The set of rNFTs R i,t, \u0398 constitutes a growing rNFT-DAGD as depicted at the bottom of Fig. 1 . Here, D merely represents a logical relationship graph (or topology) rather than an actual DAG network. Matched color\n\n2\n\nbetween the nodes R in rNFT-DAGD and the blocks B on-chain indicates each R is expected to be packed in the corresponding block with the same color as time goes by.\n\nProtocol Design. The rNFT protocol aligns with the narrative of any same kind of smart contract (SC-)supported protocols. We extract the core processes and highlight our contributions. Parameter Setup: The algorithm is used to create initial identities for users. The algorithm takes as input the se- curity parameter \u03ba , and outputs a key pair ( sk, pk ) and corresponding address es addr .\n\nsk \u2190 KeyGen sk (1 \u03ba ) , pk \u2190 KeyGen pk ( sk ) ,\n\naddr \u2190 AddressGen ( pk ) .\n\nTransaction Creation: This algorithm takes as input the user\u2019s private key sk , the transaction metadata md , the payload pd , and outputs the created transaction T that contains the signature sig from the creator.\n\nsig \u2190 Sign ( sk, md, pd ) ,\n\nT \u2190 TranGen ( sig, md, pd ) .\n\nContract Execution: The algorithm takes as input the created transaction T , and the state s , and contract that contains the operating logic, and outputs the transited state s .\n\ns \u2190 ContractExec ( s, T , contract ) ,\n\nThe state s includes the newly minted rNFTR i,t, \u0398 with the current state of referred relationships\n\n\u20d7\n\n\u0398 . Here, a pre-released rNFTR i,t, \u0398 is expected to be included in a transaction TR that will be subsequently packed by a valid block B h,t on a growing chain with finalization at the height of h at time t . State Consensus: This algorithm takes as input the transaction T , the smart contract contract and the state s to be tran- sited, and outputs the confirmed state s \u2032 , and the confirmed transaction T \u2032 .\n\n( s \u2032 , T \u2032 ) \u2190 Consensus ( s, T , contract ) .\n\nWe can observe that as soon as one from the community as the publisher i at time t publishes a new rNFTR i,t, \u0398 with a bunch of referring relationships collected in \u0398 , and the corresponding emitted transaction TR is finalized by a valid block B on the blockchain, any agreement A will be able to enjoy a reliable, trustworthy, and transparent historical record about the items, referring relationships, and profit sharing to guarantee the fair trading later on.\n\nImplementation. We implement the rNFT scheme by follow- ing the ERC standards, and propose the entire solution as indexed in EIP-5521 , which is an extension of the ERC-721 protocol. Our solution adds two types of referable indicators, referring and referred , and a time indicator createdTimestamp in a new structure Relationship . The referring indicator (im- plemented by setNodeReferring and referringOf ) enables a user, as the child, to inherit the ancestor NFTs. The referred indicator (by setNodeReferred and referredOf ) makes a parent\n\nNFT builder be able to check who has referenced him. Also, we provide two optional advance indicators labels and profit- Sharing for additional functions like incentive distribution and attributes establishment. The time indicator is a block-level timestamp that assists in solving disputes. Specifically, we set five indicators as the parameter to implement the proposed scheme, as shown in Algorithm. 1\n\nAlgorithm 1: rNFTStandard Interfaces\n\n1 interface ERC721 {\n\n2 function ownerOf (uint256 tokenI) external view returns (address);\n\n3 function transferFrom (address from, address to, uint256 tokenId) external payable; ... }\n\n4 interface EIP-5521 {\n\n5 function setNode (uint256 tokenId, uint256[] memory tokenIds) external;\n\n6 function referringOf (uint256 tokenId) external view returns(uint256[] memory);\n\n7 function referredOf (uint256 tokenId) external view returns(uint256[] memory); ... }\n\n8 struct Relationship {\n\n9 uint256[] referring ;\n\n10 uint256[] referred ;\n\n11 uint256 createdTimestamp ;\n\n12 extensible parameters }\n\n13 function setNode (uint256 tokenId, uint256[] memory\n\ntokenIds) public virtual override {\n\n14 setNodeReferring (tokenId, tokenIds);\n\n15 setNodeReferred (tokenId, tokenIds); }\n\n- referring : an out-degree indicator, showing the users this NFT refers to.\n\n- referred : an in-degree indicator, showing the users who referred this NFT.\n\n- createdTimestamp : a time-based indicator, comparing the timestamp of mint.\n\n- labels (Advanced): a list recording the attributes or cate- gories of the rNFT.\n\n- profitSharing (Advanced): a list recording the profit shar- ing of referring , thus the size of profitSharing equaling to that of referring . Here, we can observe that customizable attributes are also added following the referable indicators, for instance, a string array of labels can store a series of attributes given to a particular NFT, such as artwork , song , movie , animation , subtitle , screenshot , etc. Another optional but useful one could be a list recording the profit sharing among the owners whose NFTs have referred to this NFT. By complying with the record of profit sharing, fair and transparent on-chain or off- chain agreements can be achieved. Then, we also have six corresponding methods for the implementation.\n\n- safeMint : mint a new rNFT. - setNode : set the referring list of an rNFT and update the referred list of each one in the referring list.\n\n3\n\nrNFT-DAG\n\n\u2026\u2026\n\nt\n\n\u2026\u2026\n\nBlockchain\n\nCommunity\n\nPublisher\n\n\u2460 Publish a new rNFT\n\n\u2462 Profit sharing complied with the rNFT\n\n\u2461 Create agreements\n\nExternal users Regulators\n\n10\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n11\n\n12\n\n21\n\n22\n\n23\n\n24\n\n25\n\n26\n\nrNFT-11\n\n60%\n\nrNFT-25\n\n20%\n\nrNFT-21\n\n20%\n\nProfit Sharing of rNFT-26\n\nFig. 1: This figure shows the system overview throughout the item authentication workflow based on the proposed rNFT.\n\n- setNodeReferring : set the referring list of an rNFT. - setNodeReferred : set the referred list of the given rNFTs. - referringOf : get the referring list of an rNFT. - referredOf : get the referred list of an rNFT. Based on the above functions, EIP-5521 makes involved rNFTs form a DAG that can explicitly show their relationship and entanglement. The protocol increases the incentive of existing NFTs where an NFT owner can obtain more revenues from the followers. In the next part, we give our theoretical analysis of incentive optimization within the rNFT ecosystem.\n\nIII. INCENTIVE ANALYSIS\n\nIn this section, we discuss the incentive analysis. In total, we majorly consider three orthogonal principles . From the horizontal view (count by in/out degree ), an rNFT that have been referred more times should gain much more incentives. From the vertical view (count by depth ), an rNFT with a deeper reference index should accumulate more revenues. For the profit distribution , we additionally introduce the weight to ensure the distribution will be ended within finite rounds. We also set \u03c3 to measure the descending rate according to its depth d for the subsequent users. Specifically, we set the following parameters:\n\n- Referring bandwidth ( I ) : measure the number of rNFTs that refer to this NFT at the same block height.\n\n- Referring depth ( d ) : measure the number of attached children in every single path of the branch. Here, d is calculated by d = \u2206 h = h expire \u2212 h init .\n\n- Threshold ( \u03bb ) : set the initial pay rate (anchoring its initial value p 0 ) when minting a new rNFT.\n\n- Weight ( \u20d7w ) : set the weight for each referring edge (w.r.t. referring list \u20d7 \u0398 ).\n\n- Rate ( \u03c3 ) : adjust the descending rate of the income as the depth increases. We consider the payoff function of each single existing rNFT user.\n\nDefinition 1: The payoff function U of a user i releasing an rNFTR i,h, \u0398 at the block height h is made by\n\nU ( R i,h, \u0398 ) = IR i,h, \u0398 \u2212OR i,h, \u0398 ,\n\nwhere I represents accumulated income revenues during the following rounds while O is the cost of minting this rNFT. For the outcome, O i,h, \u0398 indicates the costs paid to the network. We can see that R i,h, \u0398 is minted at the round h (according to its block height), with the minting fees of p 0 . Here, he can optionally pay a part of (measured by \u03bb ) the entire charge at \u03bbp 0 . But accordingly, the rest of the payment needs to be completed within the next d rounds, where d is calculated by d = g (1 \u2212 \u03bb ) and g is a constant. The delayed payment will accompany by an interest rate r . Instead of relying on a simple average assignment, we relate r with individual weights w i of each rNFT. Specifically, we define w 0 as the weight of self-references with w i being the weights of all other cross- references \u2200 i > 0 . We first give details for calculating the initial price p 0 . The initial paid p 0 is one-off . It contains a ratio list, where d previous rNFTs are referred with w i being the ratio of profit sharing for i -th rNFT in the referring list \u20d7 \u0398 . Note that having to allocate the w 0 implies that a constant expense \u02c6 O > 0 is mandatory for releasing each rNFT regardless of the size of the referring list \u20d7 \u0398 . We obtain the calculation of p 0 as\n\np 0 = \u02c6 O \u00d7 [ w 0 , w 1 , w 2 , . . . , w | \u20d7 \u0398 | ] , with\n\n| \u20d7 \u0398 | X\n\ni =0 w i = 1 and w i \u2208 R + 0 .\n\nAccordingly, the outcome function with compound interest is stated as\n\nOR i,h, \u0398 = \u03bbp 0 + (1 + r ) p 0 (1 \u2212 \u03bb )\n\nd + (1 + r ) 2 p 0 (1 \u2212 \u03bb )\n\nd + ...\n\n+ (1 + r ) d p 0 (1 \u2212 \u03bb )\n\nd\n\n= \u03bbp 0 +\n\nh + d X\n\nj = h (1 + r ) d p 0 (1 \u2212 \u03bb )\n\nd ,\n\nwhere r \u221d \u03b1\n\n| \u20d7 \u0398 | X\n\ni =1 w i with \u03b1 \u2208 [0 , 1] .\n\nFor the income, I i,h, \u0398 can obtain the accumulated rewards from all participants\u2019 payments. The income is to collect same-\n\n4\n\nheight income (the horizontal dimension) iteratively for all valid rounds (the vertical dimension), where each round of in- come relates to actual participants I . Also, we use the descend- ing rate \u03c3 to adjust the valid rounds for profit distribution, which is set to be an inversely proportional relation. Based on the targeted rNFT\u2019s position on-chain, we calculate its accumulated incomes from each following round. At the round h +1 , the relevant new set of minted rNFT that refer to R i,h, \u0398 is I ( i +1) and the descending rate for each round is given by \u03c3 = 1\n\nw 0 + \u03b2 with \u03c3 \u2208 [0 , 1] and \u03b2 is a non-zero constant. We note that the settings of r and \u03c3 can be effectively used to adjust the trade-off between the income I i,h, \u0398 and outcome O i,h, \u0398 , hence leading to the payoff function U . The higher weight of the self-reference, the lower the interest rate r can be offered to encourage creative and original works. The higher weight of the cross-reference, the lower descending rate \u03c3 can be offered to works with various cross-references which are commonly acknowledged as mature products. Then, we calculate round revenues. The revenue of the round h + 1 is calculated as k\u03c3 |I ( i +1) | where k is a constant. Similarly, the income at the round h + 2 is k\u03c3 2 |I ( i +2) | . We thereby have the income function as\n\nIR i,h, \u0398 = k\u03c3 |I ( h +1) | + k\u03c3 2 |I ( h +2) | + ... + k\u03c3 d |I ( h + d ) |\n\n=\n\nh + d X\n\nj = h k\u03c3 d |I ( h + d ) | .\n\nwhere d is the depth for measuring valid rounds of profit distribution, calculated by d = g (1 \u2212 \u03bb ) . Based on the above equations, we obtain the payoff function as\n\nUR i,h, \u0398 =\n\nh + d X\n\ni = h k\u03c3 d |I ( h + d ) | \u2212 \u03bbp 0 \u2212\n\nh + d X\n\ni = h (1 + r ) d p 0 (1 \u2212 \u03bb )\n\nd\n\n=\n\nh + d X\n\ni = h k\u03c3 d |I ( h + d ) | \u2212 p 0\n\n\"\n\n\u03bb +\n\nh + d X\n\ni = h (1 + r ) d g \u2212 1 #\n\n\u221d d [ \u03c3 d |I| \u2212 (1 + r ) d ] .\n\nIntuitively, we can conclude that the payoff revenues of each minted rNFT are positively proportional to the accumula- tive participants (namely, P\n\nd |I| ) or valid references ( | \u0398 | ), whereas negatively proportional to the round interest r if not set to be 0 . The more a user paid for the initial price (say \u03bb ), the less round he needs to pay to the previous rNFTs. Similarly, the higher descending rate (cf. \u03c3 ) is set, the fewer rounds ( d ) can last for creating benefits. However, the overall payoff function relates to all parameters including |I| , \u03bb , d , w and \u03c3 is complicated. It is unpredictable to decide the dominant parameter since a surge of participants ( |I| ) may crowd into a certain round, causing significant impacts overwhelming to any other parameters. The surge of participants might be closely dependent on external stimulates which are unknown to the system view. We further investigate the concavity of the payoff function. Let A = \u2202 2 U\n\n\u2202\u03c3 2 , B = \u2202 2 U\n\n\u2202\u03c3\u2202r , C = \u2202 2 U\n\n\u2202r 2 . Note that d is an integer\n\nand always greater than 0, \u03c3 and r are both between 0 and 1, hence AC \u2212 B 2 \u2271 0 and non-convex. This is an NP-hard problem that cannot be solved by typical convex optimization approaches. We omit the concrete exploration in this brief analysis but provide some possible solutions such as the Monte Carlo method or deep learning algorithms.\n\nIV. APPLICATIONS ANDD ISCUSSIONSA. Applications and Opportunities Fair Incentive Design. The proposed rNFT scheme is particu- larly useful for scenarios where cross-references among NFTs are essential during the process of on-chain and off-chain profit sharing. A fair distribution mechanism must be established on top of existing observable relationships including inheritance, reference, and extension. For example, an artist may develop his NFT work based on a previous NFT: a DJ may remix his record by referring to two pop songs, or a movie may include existing pieces of clips, etc. Explicit reference rela- tionships for existing NFTs and enabling efficient queries on cross-references make much sense to the markets for renting, exchanging and trading. Broader Functionalities for NFTMarkets. NFT provides basic functionalities covering mint and exchange . This merely supports limited scenarios that are based on in-time and one- time trades. rNFT extends the sustainability and usability of tokens that enable consecutive transactions and long-term re- trieving. positively fostering interaction between NFT creators, collectors, and enthusiasts. Promotion for More Integration. Aligning with the rapid NFT development, our solution can follow and promote a series of emerging trends and capabilities. Mature technologies. As discussed in Sec. I , rNFT can be integrated with GNN for establishing NFT classification and predictions and with AI for plagiarism detection. Not sur- prisingly, rNFT can also be used to combine with traditional blockchain technologies such as off-chain (or layer-two [ 13 ]) executions for portable usage, or cross-chain bridges for trading between different networks. Verifiable ownership&provenance. rNFT can be used to se- curely store and share information about the origin and history of an asset, as well as providing strong connections for proof of ownership. DeFi/GameFi integration. rNFT can be designed for more NFT and DeFi derivatives due to its strong attachments to previous history. The users/players will get trusted much more easily. Using rNFT to represent in-game items or to provide a new level of ownership and scarcity in gaming experiences is a promising direction. Physical goods and services. rNFT can help to Link NFTs to tangible goods and experiences, such as collectible mer- chandise, event tickets, and access to exclusive services, which is good to build a full view of user\u2019s profile.\n\nB. Challenges and Potential Solutions Towards Cross-contract Invoke. Our protocol is imple- mented based on a singly invoked contract, which means that\n\n5\n\nall minted NFTs should follow the same contract instruc- tions. Each project can merely establish a topological graph within its project, rather than arbitrarily other contracts that require cross-invoke. As in an initial stage, our preliminary implementation gives a demo for expanding the potential usage scope and facilitating the development of the following protocols/standards. To realize a cross-contract target, we plan to implement a series of additional functions that are backward compatible with several existing standards (e.g., EIP-998). A good start is that our single-invoke implementation can be seamlessly extended to the next cross-invoke stage.\n\nWays of Feeding Price. The price oracle provides in-time prices feed to SC-enabled applications (e.g. DeFi protocols [ 4 ]). While many oracle designs have been implemented to provide data for fungible token prices, few attempts have been made to construct a price oracle for NFTs. NFTs are generally less frequently traded, therefore creating difficulties for third parties to observe and retrieve price data. Our proposed scheme can normally operate without incentive indicators, independent of the price oracle. But with advanced incentive designs, price oracle is critical for users who make trades and obtain rewards. The price will impact both the initial price p 0 and round interest r , as well as will affect the behavioral trend from users. Embedding a secure and efficient oracle for feeding prices is of great importance.\n\nIntegrated Verification. The rNFT-DAG in our protocol can merely be used for reference only when rights need to be determined and certified without any compulsory measures in force in its current form. There could be risks that malicious rNFT publishers do not obey the protocol by not claiming the correct relationships with existing rNFT items, although the community could find out the mistakes in long-term observation. A potential solution is to have an automated verification scheme integrated into our protocol where the peers have the ability to conduct mutual verification, as well as the incentive scheme associated with the malicious reference can be accordingly established. Deterministic Records with Low Latency. The created- Timestamp of each rNFT only covers the block-level times- tamp (based on block headers), which does not support fine- grained comparisons such as transaction-level. The rNFT-DAG highly relies on the EIP-5521 -driven smart contracts that run on blockchain (Ethereum in our context). The block interval of a dozen seconds if the Proof-of-Work (PoW) is used by default needs to be reduced to achieve lower latency. This is significantly important when ones aim at preemptive regis- tration of rNFTs. On the other hand, PoW is a probabilistic consensus algorithm that commonly causes a rollback of the state of smart contracts, which lengthens the waiting period until the reference relationship takes effect. A workaround is to use deterministic consensus algorithms such as the Proof- of-Authority (PoA) or any other Ethereum-compatible BFT algorithms (e.g., Quorum [ 14 ]).\n\nComplementary to CC0 License. CC0 refers to \u201cCreative Commons 0\u201d \u2013 a license that for the first time allows NFT\n\nholders to waive copyrights and other IP protections and significantly encourages the creation and extension of NFT derivatives associated with the original works [ 15 ]. This has been widely committed and adopted by many Web3 projects due to its attempt of eliminating the possible legal conse- quences associated with reference relationships between differ- ent NFT items and bring the items to a permissionless public domain \u2013 the spirit of true Web3. However, it becomes difficult for one, especially those who are large-scale, well-established, or have a well-deserved reputation, to build commercial brands on top of a CC0-based NFT once opting for CC0 License as he/she has no right to exclude others from using the same origin (the CC0-based item). Our proposed rNFT protocol fills the gap for these NFT holders and can be considered complementary to the existing CC0 License due to its explicit indication of reference relationships.\n\nV. CONCLUSION In this paper, we propose a referable NFT (rNFT) scheme to improve the exposure and enhance the reference relationship of inclusive NFTs. We implement the scheme and propose the corresponding EIP-5521 standard to the community. We further establish the mathematical utility function to express the rNFT releasing and referring process. As far as we know, this is the first study that establishes a referable NFT network. By traversing it, a truly decentralized reference network comes to life to protect intellectual property and copyright and incentivizes creativity towards a fairer environment.\n\nREFERENCES\n\n[1] Q. Wang, R. Li et al. , \u201cNon-fungible token (NFT): Overview, evaluation, opportunities and challenges,\u201d arXiv preprint arXiv:2105.07447 , 2021.\n\n[2] E. William, S. Dieter, E. Jacob, and S. Nastassia, \u201cEip-721: Non-fungible token standard,\u201d Jan. 2018. [Online]. Available: https: //eips.ethereum.org/EIPS/eip-721\n\n[3] G. Wood et al. , \u201cEthereum: A secure decentralised generalised trans- action ledger,\u201d Ethereum project yellow paper , vol. 151, no. 2014, pp. 1\u201332, 2014.\n\n[4] S. M. Werner, D. Perez, L. Gudgeon, A. Klages-Mundt, D. Harz, and W. J. Knottenbelt, \u201cSoK: Decentralized finance (DeFi),\u201d ACMAdvances in Financial Technologies (AFT) , 2022.\n\n[5] A. Kiayias and P. Lazos, \u201cSoK: Blockchain governance,\u201d ACMAdvances in Financial Technologies (AFT) , 2022.\n\n[6] Q. Wang, R. Li et al. , \u201cExploring Web3 from the view of blockchain,\u201d arXiv preprint arXiv:2206.08821 , 2022.\n\n[7] \u201cForum discussion on referable NFT,\u201d Available: https: //ethereum-magicians.org/t/eip-x-erc-721-referable-nft/10310 , 2022.\n\n[8] \u201cBriq NFT,\u201d Available: https://briq.construction/ , 2022. [9] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini, \u201cThe graph neural network model,\u201d IEEETransactions on Neural Networks (TNN) , vol. 20, no. 1, pp. 61\u201380, 2008.\n\n[10] \u201cOpensea,\u201d Available: https://opensea.io/ , 2022. [11] G. Kumar, K. Kumar, and M. Sachdeva, \u201cThe use of artificial intelligence based techniques for intrusion detection: a review,\u201d Artificial Intelligence Review , vol. 34, pp. 369\u2013387, 2010.\n\n[12] J. S. Matt Lockyer, Nick Mudge, \u201cEIP-998: ERC-998 composable non- fungible token standard,\u201d https://eips.ethereum.org/EIPS/eip-998 , 2022.\n\n[13] L. Gudgeon, P. Moreno-Sanchez, S. Roos, P. McCorry, and A. Gervais, \u201cSoK: Layer-two blockchain protocols,\u201d in Financial Cryptography and Data Security (FC . Springer, 2020, pp. 201\u2013226.\n\n[14] Consensys, \u201cQuorum blockchain service,\u201d https://consensys.net/docs/ qbs//en/latest/, accessed 19-October-2022.\n\n[15] Flashrekt and S. D. Kominers, \u201cWhy NFT creators are going CC0,\u201d\n\nhttps://a16zcrypto.com/cc0-nft-creative-commons-zero-license-rights, accessed 19-October-2022.\n\n6"
    },
    {
        "number": 1570886810,
        "title": "Identity-Based Key Agreement Algorithm for Smart Meter Technology to ensure Anonymity",
        "abstract": "A smart meter is a device that can collect and transfer data about power use to the Smart Grid System (SGS). The Smart Grid System (SGS) allows electricity generators and customers to communicate in two directions. Smart Meters can be installed on both ends to facilitate communication. However, data leaks from smart meters might pose a serious threat to users' privacy. Despite the fact that some technique for key establishment has been provided, these protocols are subject to a variety of security risks. This paper will examine the previously presented solutions and attempt to identify their flaws. We will try to design an Identity-Based Cryptographic solution for key agreements for smart meters based on the findings, which will assure the users' anonymity.",
        "review": {
            "strength": [
                "The authors proposed an algorithm that ensures to overcome security weaknesses of existing methods.",
                "This paper presents a solution for key agreement for smart meters. This paper has no relevance to this workshop. The paper does not use blockchain at all. I am not sure why the authors would submit their paper to this venue.",
                "The paper addresses an actual problem related to data security on smart meter systems.",
                "The proposed solution enhanced the existing security flaws with decent low computational costs in smart meter technology."
            ],
            "shortcoming": [
                "- Topic is out-of-scope. This work does not related to blockchain or cryptocurrency exchanges.\n- The length of the manuscript is too short for full paper.",
                "This paper presents a solution for key agreement for smart meters. This paper has no relevance to this workshop. The paper does not use blockchain at all. I am not sure why the authors would submit their paper to this venue.",
                "1. The paper has a very high similarity rating.\n2. The paper is not properly-organized. In addition, submission is not blinded.\n3. The proposed approach implements an established key generation and distribution mechanisms. However, lack of details on the proper implementation. \n4. The paper has many errors, including reference to \"7676395\" (mentioned several times).\n5. References were not dated properly",
                "The reference list does not include the publication sources and years of publication. Can clarifies figure ??"
            ],
            "comment": [
                "This paper topic is out-of-scope. This work seems to be suitable for other conferences mainly related to cryptography.",
                "This paper presents a solution for key agreement for smart meters. This paper has no relevance to this workshop. The paper does not use blockchain at all. I am not sure why the authors would submit their paper to this venue.",
                "The paper presents a work on the design and implementation of identity-based key agreement algorithm for smart meter systems to ensure data anonymity.\nThe work carried out in this paper is not within the scope of the workshop and need to be revised and resubmitted to a more specific conference related to data security. \nThe proposed design and implemented does not carry any significant weight towards the use of NFT, blockchain or cryptocurrencies. \nIt is best to add this theme to the paper.",
                "The reference list does not include the publication sources and years of publication. Can clarifies figure ??"
            ],
            "score": {
                "Relevance": 1.3,
                "Content and originality": 2.8,
                "Reference": 2.5,
                "Overall recommendation": 1.5,
                "Poster acceptance": 1.8
            }
        },
        "body": "I. INTRODUCTION\n\nThe electric grid is a complicated system that distributes electricity produced from power plants to customers. Smart Grid was introduced to make this distribution system more efficient. SGS (Smart Grid System) enables two-way com- munication between power plants and consumers. This com- munication can be done by installing Smart Meter on both ends. Unlike traditional meters that record monthly total power consumption, smart meters can record detailed usage info. In a word, Smart Meter is a smart device that can record electricity consumption data and send the readings to the SGS. However, information leaks from the smart meter may create a severe issue for consumers\u2019 privacy. Therefore, collecting data efficiently while providing privacy is essential. Furthermore, Establishing communication, i.e., sessions within the system is still a problem. Though some mechanism was proposed for key establishment, these protocols are vulnerable to various security threats. This paper will study the previously proposed solutions and try to find their limitations. Based on the find- ings, we will try to develop an Identity-Based cryptographic solution for key agreements for smart meters that ensure anonymity, unlinkability, undetectability, and unobservability of the users. In this paper, we organized as follows: In Section II, a detailed review of previously established protocols. In\n\nIdentify applicable funding agency here. If none, delete this.\n\nSection III, our proposed algorithm is discussed briefly. A detailed performance analysis is given in section IV. Section V is the conclusion and future research direction based on our idea.\n\nII. BACKGROUND\n\nDemand for energy consumption has increased with the development of cities and nations, and the traditional grid is no longer helpful and inconsistent for energy management [16]. Therefore, the Smart Grid system (SGS) is proposed to make efficient electricity generation, transmission, and distribution. A modified and upgraded electric grid supports two-way communication between service providers and consumers. It is computerized and automated, able to manage the complexity of electricity distribution, and is quick to respond to changing electric demand [18], [19]. Smart Grid is a very complex system, often referred to as the system of micro-systems. Smart Grid collects data from households and powerplants in real-time. Due to many endpoints and controlling the real-time data, the smart grid introduces Smart Meter. It is one of the primary real-time data sources in the smart grid. Smart Meter has the feature of two-way communication also. By collecting the energy consumption data of consumers in near real-time, smart meters helps the SG system to operate efficiently [21]. Advanced Metering Infrastructure (AMI) is proposed as an integral system of the smart grid system responsible for collecting and analyzing the data of energy consumption of households by communicating with smart meters [14]. As more and more research is going on the smart grid, the privacy of consumers and other parties becomes a severe issue, especially in AMI. Privacy in AMI becomes essential for the smart grid\u2019s basic foundation. In order to achieve data confidentiality or privacy and efficient authentication in AMI, various protocols using cryptographic algorithms are proposed [20]. One of the major problems in achieving privacy in AMI is establishing a connection between the smart meter and the service provider. However, few works have been conducted for authentication in AMI. Nevertheless, most proposals did\n\nnot address the distribution of keys [22], [23]. They focused more on authentications than key establishments. a) : In 2011, Nicanfar et al. first proposed an authen- tication protocol for key establishment and installation of keys for smart meters [6]. However, this protocol has some security flaws which make it vulnerable. In another paper, they proposed another protocol for key exchange. They com- bined the classic Diffie-Hellman protocol with Eliptive Curve Cryptography (ECC) and developed the key exchange protocol named ECC-based Password Authenticated Key Exchange (EPAKE) [7]. This protocol is not efficient as it has a high computational cost. Later, Nicanfar et al. proposed a modified Secure Remote Password (SRP) protocol for key agreement in smart grid and managed to reduce message exchange cycle number [8]. Liu et al. suggested a key management framework based on key graphs [9]. Wan et al. developed an end-to- end key establishment protocol on session key named Scalable Key Management (SKM). However, this protocol also has very high computational costs [10]. A different approach also proposed a few different frame- works. Wu and Zhou used a combination of Public Key Infras- tructure (PKI) and Trusted Authority (TA) [11]. Benmalek and Challah developed a new key management scheme based on multi-group key graph techniques [12]. Later, Mohammadali et al. proposed a lightweight identity-based key establishment method with two variations ( NIKE and NIKE + ) for dif- ferent Advanced Metering Infrastructure (AMI) setups [1].\n\nIII. PROPOSED ALGORITHM\n\nThe proposed algorithm is based on the Discrete Logarithm Problem (DLP) and Elliptic Curve Cryptography (ECC).\n\nA. Proposed Protocol\n\nAMI will be given an identity-based key establishment procedure that does not need pairing. Setup, Installation, and Key Agreement are the three stages, and their explanations are provided below 7676395.\n\n1) Setup Phase : The smart meter chooses a k-bit prime number, master key, and two hash functions to start the setup session. After choosing the smart meter\u2019s parameter, publish the system parameter but keep the master key secret.\n\n2) Installation Phase : In the installation phase, AMI-head- end (AHE) system and Smart Meter (SM) will register with Trusted Authority(TA) using a secure communica- tion channel. First, TA does some processes for each AHE with the identifier IDAHE . In the second step, TA goes through some procedures for each meter with the identifier ID i . At the end of these steps, each meter will have it\u2019s own SM , RM , y M , r M and each AHE will have y AHE , r AHE . The factory making the meters and AHE can play the role of TA. TA goes offline after the installation phase.\n\n3) Key Agreement : We will reduce the computation cost from smart meters by sending some tasks to TA. At the end of the session establishment phase, the key\n\nFig. 1. Identity-based key establishment procedure\n\nStart Setup Session\n\nChosse k-bit prime, master key & two hash functions\n\nPublish system parameter & keep master key secret\n\nSetup phase done\n\nSmart meter registration\n\nAHES registration\n\nInstallation done\n\nClean up setup phase\n\nSmart Meter(SM) send to AMIHead End(HE)\n\nHE verify messages from SM\n\nSession Established\n\nClean up registration phase\n\nYes\n\nNo\n\nYes\n\nNo\n\nSetup phase Installation phase Key agreement phase\n\nagreement phase SM will send a message to AHE. After that, AHE will verify the message from SM. Finally, the session will be established between SM and AHE. After establishing the session, the algorithm will reduce the computational cost as multiplications moved from SM to AHE. We also use smart hashing to make the system more secure. The preceding stages are described in the procedure shown in Figure 1.\n\nB. Reduce the Computational cost\n\nReducing the computational effort on the side of the meter is highly desired. The suggested protocol contains a one-of-a- kind feature that allows the processing burden to be shifted from one side to the other. In fact, 75% of the meter\u2019s expensive multiplications may be shifted to AHE, leaving just\n\nTABLEI PROPOSED KEY ESTABLISHMENT PROTOCOL\n\nMeter AHE\n\nGenerate a \u2208 Z \u2217 q IDM , a, RM A \u2032 = a + RM ,\n\n\u2192 T \u2032 m = A \u2032 P\n\nGenerate b \u2208 Z \u2217 q\n\nT x = b + r AHET AHE = T x P\n\nKM \u2192 AHE = ( S m + a ) TAHE\n\nTAHE , KAHE \u2192 M = T x ( RM + H 2 ( IDM , YAHE ) P pub + TM )\n\nIDAHE , M 1 M 1 = H 1 (0 , KAHE \u2192 M )\n\n\u2190\n\nKM \u2192 AHE = ( SM + a ) TAHE M \u2032 1 = H 1 (0 , KM \u2192 AHE )\n\nCheck M 1 = M \u2032 1\n\nM 2 = H 1 (1 , KM \u2192 AHE ) M 2\n\nComputes K = H 1 ( IDM || IDAHE , KM \u2192 AHE )\n\n\u2192 M \u2032 2 = H 1 (1 , KAHE \u2192 M ) Check M 2 = M \u2032 2\n\nComputes K = H 1 ( IDM || IDAHE , KM \u2192 AHE )\n\none for the meter. Our proposed protocol, which is seen in figure ?? .\n\n\u2022 Step 1 : First, the meter selects a \u2208 Z \u2217 q as a random integer and then sends a, IDM and RM to AHE.\n\n\u2022 Step 2 : When AHE receives the meter\u2019s initiation mes- sage, it executes the following:\n\n1) Compute A \u2032 = a + RM and T \u2032 m = A \u2032 P . Then it will chosse a random number b \u2208 Z \u2217 q and calculates T x = b + r AHE , TAHE = T x P and KAHE \u2192 M = T x ( RM + H 2 ( IDM , YAHE ) P pub + TM )\n\n2) Computes M 1 = H 1 (0 , KAHE \u2192 M ) and sends M 1 , IDAHE , TAHE to the meter.\n\n\u2022 Step 3 : In the meter side, meter compute KM \u2192 AHE = ( S m + a ) TAHE & TAHE and M \u2032 1 = H 1 (0 , KM \u2192 AHE ) is. Compare M 1 and M \u2032 1 if both are equal then authenticate AHE and sets K = H 1 ( IDM || IDAHE , KM \u2192 AHE ) as the key.\n\n\u2022 Step 4 : Meter computes M 2 = H 1 (1 , KM \u2192 AHE ) and send it to the AHE.\n\n\u2022 Step 5: AHE receive M 2 and compute M \u2032 2 = H 1 (1 , KAHE \u2192 M ) . If M 2 = M \u2032 2 then it authenticate the meter and takes K = H 1 ( IDM || IDAHE , KM \u2192 AHE ) as the session key.\n\nIV. PERFORMANCE EVALUATION\n\nThe suggested procedure is evaluated, and its results are compared to those of rivals. The active attacker is considered to be capable of eavesdropping, altering, and inserting mes- sages in the analysis 7676395.\n\nA. Analysis of the security of the protocol by discussion\n\n1) MITMAttacks: In a MITM attack [1], the attacker surreptitiously relays and maybe modifies communica- tion between two participants, giving the impression that they are conversing directly while really conversing via the attacker. The meter checks the legitimacy of the received messages by confirming M 1 andM \u2032 1 . M 1 . M1serves a second function by acting as a message authentication code in the same way the HMAC standard does. An HMAC is a form of message authentication code that uses a cryptographic hash function and a secret cryptographic key in cryptography [17]. AHE is testing M 2 = M \u2032 2 in the same way. The MITM attack is defeated via mutual message authentication.\n\n2) Replay Attack: The adversary eavesdrops on the traded communications in a replay attack [1]. Then, at his option, he may republish them. Each side challenges the other in the suggested method. Meter produces a new nonce a and expects something back in the second message that fits what it expects from the secret key it was created with. AHE is performing the same thing with the newly selected b. As a result, any attempt to persuade either side to accept an old message based on ancient nonces is futile.\n\n3) Desynchronization: An attacker might (partially) block messages sent between AHE and a meter, causing them to lose key synchronization for good. They will no longer be able to speak with one another as a conse- quence of this. The (session) key in our prototype is built using the primary secrets and newly generated nonces. We haven\u2019t established any link between the freshly created key and the prior session keys. As a result, desynchronization is impossible, and even if the third message is stopped, resynchronization may be achieved by rerunning the protocol [1].\n\nB. Analysis Performance\n\nThe proposed protocols\u2019 performance will be evaluated from two perspectives: computing and communication.\n\nTABLEII COMPARISON OFTHE PROTOCOL COMPUTATION TIMES\n\nProtocol Meter AHETA meter Total\n\nXia and Wang\u2019s [13] 0.80s 0.57ms 1.04ms 0.80s\n\nNicanfar et al.\u2019s [8] 25.4s 34.2ms NA 25.4s\n\nWu and Zhon\u2019s [15] 43.8s NA 17.0ms 43.8s\n\nKamto et el\u2019s [14] 1.59s 1.15ms NA 1.59s\n\nNIKE [1] 4.9s 5.46 NA 4.91s\n\nNIKE+ [1] 2.45s 7.28ms NA 2.46s\n\nProposed Protocol 2.46s(app.) 5.46ms(app.) NA 2.46s\n\n1) Computational Cost: In NIKE, the meter, and AHE need to do two and three-point multiplications, respectively. In addition, the meter and AHE should do three and four hash operations, respectively. However, hash operation cost can be ignored in comparison to the cost of ECC point multiplication. Nearly half of the computational\n\ncost at the meter has been moved to AHE in NIKE+. Because AHE does not have many resource constraints, the total calculation time has been significantly lowered. In our proposed algorithms the computational cost of 75% at the meter has been moved to AHE 7676395. The entire computation time has been greatly reduced because of AHE\u2019s lack of resource limitations. The computational cost of various key setup techniques is shown in Table II.\n\n2) Communication Cost : Three communications between a meter and AHE are required under the proposed protocols. In NIKE and NIKE+, they correspond to the exchange of seven and six messages, respectively, and similar three communication like our proposed protocol required. The communication costs of all the protocols are listed in Table III.\n\nTABLEIII COMPARISON OFTHE COMMUNICATION COSTS\n\nProtocol Communication# Messages#\n\nXia and Wang\u2019s [13] 5 8\n\nNicanfar et al.\u2019s [8] 3 10\n\nWu and Zhon\u2019s [15] 2 6\n\nKanto el\u2019s [14] 4 10\n\nNIKE [1] 3 7\n\nNIKE+ [1] 3 6\n\nProposed Protocol 3 7\n\nV. CONCLUSION From a security and overhead standpoint, we analyzed some major setup protocols in this study\u2019s context of smart grids. We will try to find out their serious security vulnerabilities. With two modifications for distinct AMI configurations, we suggested a safe and lightweight identity-based key estab- lishment technique. Our proposed algorithm will ensure to overcome these security weaknesses. Also, this algorithm will provide security features like anonymity, unlinkability, undetectability, and unobservability with high performance and low computational cost. In the future, we will design a key management system for unicast, multicast, and broadcast communications in smart grids based on these protocols.\n\nREFERENCES\n\n[1] Mohammadali, Amin and Sayad Haghighi, Mohammad and Tadayon, Mohammad Hesam and Mohammadi-Nodooshan, Alireza, \u201dANovel Identity-Based Key Establishment Method for Advanced Metering In- frastructure in Smart Grid\u201d\n\n[2] Khalid Mahmood and Jehangir Arshad and Shehzad Ashraf Chaudhry and Saru Kumari, \u201dAn enhanced anonymous identity-based key agree- ment protocol for smart grid advanced metering infrastructure\u201d\n\n[3] Nian Liu and Jinshan Chen and Lin Zhu and Jianhua Zhang and Yanling He, \u201dAKey Management Scheme for Secure Communications of Advanced Metering Infrastructure in Smart Grid\u201d\n\n[4] H. Nicanfar and Paria Jokar and K. Beznosov and Victor C. M. Leung, \u201dEfficient Authentication and Key Management Mechanisms for Smart Grid Communications\u201d\n\n[5] Xia, Jinyue and Wang, Yongge, \u201dSecure Key Distribution for the Smart Grid\u201d\n\n[6] Nicanfar, Hasen and Jokar, Paria and Leung, Victor C.M., \u201dSmart grid authentication and key management for unicast and multicast communications\u201d\n\n[7] Nicanfar, Hasen and Leung, Victor C. M., \u201dMultilayer Consensus ECC- Based Password Authenticated Key-Exchange (MCEPAK) Protocol for Smart Grid System\u201d\n\n[8] Nicanfar, Hasen and Jokar, Paria and Beznosov, Konstantin and Leung, Victor C. M, \u201dEfficient Authentication and Key Management Mecha- nisms for Smart Grid Communications\u201d\n\n[9] Liu, Nian and Chen, Jinshan and Zhu, Lin and Zhang, Jianhua and He, Yanling, \u201dAKey Management Scheme for Secure Communications of Advanced Metering Infrastructure in Smart Grid\u201d\n\n[10] Z. Wan and Guilin Wang and Yanjiang Yang and Shenxing Shi, \u201dSKM: Scalable Key Management for Advanced Metering Infrastructure in Smart Grids\u201d\n\n[11] Wu, Dapeng and Zhou, Chi, \u201dFault-Tolerant and Scalable Key Manage- ment for Smart Grid\u201d\n\n[12] Benmalek, Mourad and Challal, Yacine, \u201deSKAMI: Efficient and Scal- able Multi-group Key Management for Advanced Metering Infrastruc- ture in Smart Grid\u201d\n\n[13] Jinyue Xia and Yongge Wang, \u201dSecure Key Distribution for the Smart Grid\u201d\n\n[14] Kamto, Joseph and Qian, Lijun and Fuller, John and Attia, John, \u201dLight-weight key distribution and management for Advanced Metering Infrastructure\u201d\n\n[15] Wan, Zhiguo and Wang, Guilin and Yang, Yanjiang and Shi, Shenxing, \u201dSKM: Scalable Key Management for Advanced Metering Infrastructure in Smart Grids\u201d\n\n[16] Maria Lorena Tuballa and Michael Lochinvar Abundo, \u201dA review of the development of Smart Grid technologies\u201d\n\n[17] Wikimedia Foundation, \u201dhttps://en.wikipedia.org/wiki/HMAC\u201d [18] Smart Grid, \u201dhttps://www.smartgrid.gov\u201d [19] Fang, Xi and Misra, Satyajayant and Xue, Guoliang and Yang, Dejun, \u201dSmart Grid \u2014 The New and Improved Power Grid: ASurvey\u201d\n\n[20] https://www.energy.gov, \u201dAMISystem Security Requirements\u201d [21] Xue Han and Shi You and Thordarson, Fannar and David Victor Tackie and Sisse Merete \u00d8stberg and Pedersen, Ole Michael and Bindner, Henrik W. and Nordentoft, Niels Christian, \u201dReal-time measurements and their effects on state estimation of distribution power system\u201d\n\n[22] Ye Yan and Yi Qian and Hamid Sharif, \u201dA secure and reliable in- network collaborative communication scheme for advanced metering infrastructure in smart grid\u201d\n\n[23] Matsumoto, T. and Kobayashi, T. and Katayama, S. and Fukushima, K. and Sekiguchi, K.\u201dInformation-theoretic approach to authentication codes for power system communications\u201d"
    },
    {
        "number": 1570886863,
        "title": "Design and Development of m-Commerce Application with Integrated Stablecoins Cryptocurrency Payment Model",
        "abstract": "Stablecoins have been widely accepted as a stable form of digital currencies. Nevertheless, its design and development are still being considered as an on-going task in the field of cryptocurrency research. This study presents the work-in-progress design and development of a mobile commerce (m-Commerce) application that integrates a stablecoins cryptocurrency payment model. The aim of the application is to provide a seamless and secure payment experience for users, while also addressing the volatility issues associated with traditional cryptocurrencies. The proposed application will be built using industry-standard technologies and frameworks, and the stablecoins payment model will be implemented using smart contract technology on a blockchain network. The aim of this work is to demonstrate the possibility of incorporating different types of stablecoins that values are pegged to different forms of assets, including fiat currency and commodities. The application can be further used for a proof-of-concept for online applications that are based on stablecoins cryptocurrencies.",
        "review": {
            "strength": [
                "This paper utilize stablecoins for m-Commerce application to prevent unpredictable fluctuation of price in cryptocurrency.",
                "- The topic is interesting: improving user experience is the first step toward the full acceptance of cryptocurrencies\n- good classification of current stablecoins",
                "This paper presents a case of implementing m-Commerce that pays using Stablecoin. It was appropriate to analyze trends or raise the need for research on integration into Stablecoin and m-Commerce.",
                "This study provides a categorization of the different types of stable crypto money. Immediately displayed the app in its mobile view."
            ],
            "shortcoming": [
                "1. It\u2019s not new at all that we apply stablecoins to the e-commerce system.\n2. There is a lack of detail about the implementation of the entire system.\n3. The classification of stablecoins is not related to this paper\u2019s goal.\n4. It is unclear which stablecoin was used, and according to figure 6, not only tether but also Bitcoin and Ethereum are available.",
                "- Poor technical content\n- The architecture of the application is only sketched\n-",
                "This paper is still in the implementation stage to confirm the concept, and lacks academic depth.\nit is necessary to check the characteristics of the proposed framework through comparative analysis with existing implementation cases made for the same purpose, referring to related papers[15,16]",
                "The author only shows the stable coin account and wallet on mobile devices. There are no technical notes pertaining to the work. The work is not of acceptable quality."
            ],
            "comment": [
                "1. The authors propose an m-commerce application with stablecoin to prevent unpredictable fluctuation of price in cryptocurrency. It\u2019s a good attempt for utilizing cryptocurrency. But, It\u2019s not new at all. You can also find it in overstock.com.\n2. It seems that including more details of design would be better.\n3. The classification of stablecoins is not related to this paper\u2019s goal. So It should be change to other characteristics of stablecoin or more details of implementation.\n4. This paper includes a few misspelling and unnecessary elements. Please correct some of them by referring comments as below.  \n- In the figure 2,  \u201cBullman\u201d to \u201cBullmann\u201d.\n- In the section 4, \u201cstablecoin-based cryptocurrencies\u201d seems to mean just \u201cstablecoin\u201d",
                "- The work is too preliminary to be accepted in the workshop. \n- The application presents to the user data related to the main stablecoins. How these data are collected? Which are the services exploited to collect the data? Which kind of statistics on stablecoin are meaningful?",
                "In terms of technology development, research is progressing in the right direction.\nHowever, in-depth technical considerations should precede implementation.\nThe purpose to be obtained through this implementation must be presented in detail, and what needs to be checked as a result of the implementation must be organized in advance..\nIt's trivial, but you have to pay more attention to the figures. The letters in the figure are small or blurry, making it less readable.",
                "A comprehensive literature review is lacking.\nFigure 1's crypto cube is not able to illustrate your classification in any way,\u00a0\u00a0 Only Figure\u00a02 is sufficient.\nJustify your work since Figure 2 claims that \"Tokenized Funds\" lack \"decentralization of responsibility\", although tokens operate on decentralized platforms.\nThis work only defines a domain class diagram; no explanation of development is provided. only the mobile view is represented."
            ],
            "score": {
                "Relevance": 2.8,
                "Content and originality": 1.5,
                "Reference": 2.5,
                "Overall recommendation": 1.5,
                "Poster acceptance": 2.3
            }
        },
        "body": "I. INTRODUCTION\n\nAs the world is heading towards cryptocurrencies, cities around the world are finding new ways to integrate this type of digital currency into different kinds of applications. Major cities such as Dubai, is attempting to lead this initiative by adopting a strategy aimed at building a smart and sustainable city. According to Khan et al. [1], financial regulators in Dubai are working on crypto regulations and cryptocurrency laws. In addition, the Ministry of Economy has identified that the crypto and asset tokenization will be the basis of fundamental support for doubling the size of the economy within the next decade. The smart city initiative will mainly be focusing on open and easy access to data, smart transportation, smart parks and beaches and police smartphone apps. This is intended to make Dubai more accessible to tourists and investors. Recent development in blockchain technologies have en- abled a number of public-related industries such as tourism industry to adopt cryptocurrency as the mean for payments and other financial transactions. According to Treiblmaier et al. [2], many tourism vendors have been accepting cryptocur- rencies in travel-as a mean for payment currency for travelers. Nevertheless, there is an existing challenge in the acceptance of cryptocurrency for such activities. Having a global standard form of cryptocurrency will be beneficial to many people, especially tourists and investors since people will not be needing to exchange currencies. This could also benefit Dubai by being the central hub of this type of new monetary system.\n\nBitcoin is one of the earliest digital cryptocurrency that has been conceptualized, with the aim of replacing the fiat cur- rency issued by authorized and sovereign entities [3]. Bitcoin has been developed based on the distributed ledger technology, which mainly relies on cryptographic hashing function. The value of bitcoin has rose from below $5,000 in 2017 to surpass $19,000 before the end of that year. However, the price has remained extremely volatile, it has decreased from the prior highs observed last year and even to a low of roughly $6,000. This highlights one of the main drawbacks of using cryptocurrencies in transactions and reduces the currency\u2019s usability [4]. What made cryptocurrencies attractive was their privacy, convenience, and the security they provided. However, cryptocurrencies are also volatile and do not offer the stability of fiat money as being observed. This made cryptocurrency a very risky investment as people could lose most of their money in a brief period.\n\nThe crypto community has been working on developing a stable form of cryptocurrency. As a result, stablecoins have been proposed. Essentially, stablecoins are digital dollars on a blockchain network. It aims to provide safety in relation to the major currencies [5]. The use of stablecoins as a form of currency basically directed towards increasing the level of stability of cryptocurrency exchanges through the concept of tokenized funds or securities. This type of cryptocurrency pegged their value to a collateral, either in the form of fiat money, commodities, real estate or other cryptocurrencies [6].\n\nIn this paper, we present a review on the current use of stablecoins, as well as work-in-progress on the development of mobile-commerce (m-Commerce) application that enables the user to use a set of consolidated cryptocurrencies, including stablecoins to perform online purchases. The work aims to provide a workable platform for conducting research on retail business transactions using cryptocurrency.\n\nThis paper is divided into 4 sections. Section II provides an overview of stablecoin cryptocurrency and reviews of its application in business transactions. The current work- in-progress design model of our proposed mobile commerce application that incorporates stablecoin currencies for online transactions is presented in Section III. Finally, Section IV concludes the paper.\n\nII. STABLECOINS : CONCEPT , DESIGN ANDC LASSIFICATIONS\n\nOne of the important features of stablecoins is that it combines the advantages of cryptocurrency model of financial transactions with the price stability and broad market accep- tance of fiat currency. According to Ante et al. [7], there are about at least 566 stablecoin issuances with the value of at least 1 million USD dollars for seven different stablecoins, in- cluding USDCoin (USDC), Huobi USD (HUSD), and Tether USD (USDT) between April 2019 and March 2020. This shows significant acceptance level of stablecoins as a form of currency for online transactions. In addition, stablecoins can be pegged to different form of fiat currency and physical commodities. According to Bullmann et al. [5], stablecoins could be classified according to the basis of what backing their values. These include whether the stablecoin is supported by funds (tokenized funds), by other traditional asset classes (off-chain collateralized stablecoins), by assets (on-chain collateralized stablecoins), or by users\u2019 expectations (algorithmic stable- coins). They also introduced the concept of \u201ccrypto cube\u201d that distinguishes between the stablecoin classes according to the following criteria:\n\n\u2022 The existence or absence of an issuer that is responsible for verifying any attached claim..\n\n\u2022 The decentralization of responsibilities over the stable- coin initiative.\n\nFig. 1 shows the crypto cube representation that is used to classify the different types of stablecoin-based crypto-assets.\n\nFig. 1. Crypto cube representation for classifying stablecoin cryptocurrencies.\n\nThe crypto cube can be used to generate the classification of stablecoins based on the aforementioned criteria. Fig. 2 illustrates the output of the classification process made using the crypto cube. In the process of identifying suitable stablecoins to be im- plemented in the proposed m-Commerce application, we have made a preliminary review of each class of stablecoins. The following subsection give a brief overview of different types of stablecoins based on the study that has been performed.\n\nFig. 2. Results of the classification of stablecoins based on the criteria as described by Bullman et al [5].\n\nA. Tokenized Funds\n\nTokenized funds are considered as units of monetary value that are electronically stored in a distributed ledger format in the form of a claim on the issuer and are issued on the receipt of funds (transactions). Stablecoins that are based on tokenized funds model are not usually being considered as a new type of assets, rather merely representing existing currency units. In 2021, the market value of stablecoins has raised up significantly in line with the rise of decentralized finance (DeFi) [8]. Fig. 3 shows the process of issuance of stablecoin using tokenized funds approach.\n\nFig. 3. Issuance of stablecoin based on the tokenized funds model.\n\nThe tokenized funds basically utilizes the distributed ledger technology (DLT) that holds information on asset issuance and transaction. Tether is one of the earliest and widely used stablecoin cryptocurrencies that implements tokenized funds approach [9]. Tether was initially known as Realcoin and founded in 2014 by Brock Pierce, Craig Sellars and Reeve Collins. It is pegged to US dollars, hence minimizing the price volatility of cryptocurrencies. As of December 2019, more than 4.1 billion Tether tokens are in market circulation [10].\n\nB. Collateralized Stablecoins\n\nSimilar to tokenized funds approach, collateralized stable- coins use units of an asset are multiple assets as their currency reference. However, they are backed by assets whose price in the corresponding currency of reference fluctuates over time. Ito et al. [11] described collateralized stablecoins as having two different classes, namely commodity-collateralized (off- chain) stablecoin and crypto-collateralized (on-chain) stable- coin. The commodity-collateralized stablecoin uses commod- ity (e.g., gold, oil) as collateral, and implements the same process as the tokenized funds (See Fig. 3). DigixDAO [12] is an example of a stablecoin that is backed by commodity.\n\nIt is pegged to the gold value. On the other hand, crypto- collateralized stablecoin uses cryptocurrency such as bitcoin as collateral. Fig. 4 shows the issuance process for crypto- collateralized stablecoin.\n\nFig. 4. Issuance of stablecoin based on the on-chain crypto-collateralized model.\n\nNote that user needs to first create his/her account via the smart contract, in order to create his/her cryptographic vault ( p1 and p2 ). The use of such crypto-collateralized approach can be seen in the implementation of Dai stablecoin [13], in which the currency is pegged to US dollar, but collateralized by the Ethereum [14] cryptocurrency.\n\nC. Algorithmic Stablecoins\n\nAlgorithmic stablecoins could be considered as a work-in- progress and collectively taken as a theoretical possibility, rather than reality [5]. Algorithmic stablecoins have been proposed on the basis of using mathematical algorithms to adjust the supply of stablecoin units in order to maintain price stability in the currency of reference, without being backed by any form of funds or collaterals. In this paper, we consider the use of stablecoin currencies for making online purchases through the proposed mobile application. The work-in-progress design model of the appli- cation will be presented in the next section.\n\nIII. DESIGN MODEL FORS TABLECOINM -COMMERCE APPLICATION\n\nThe proposed mobile commerce application aims to enable the online transactions involving payment and purchase to be conducted using selected stablecoins as the form of cryp- tocurrency. Some of the developments of mobile applications with cryptocurrency support could be seen in the reviews and surveys done in [15], [16]. Our proposed application will enable users to create their account and link their crypto assets, specifically the stablecoins. In order to achieve this, there is a need to consider the different level of decentralization of issuance and redemption authority for the crypto-assets used.\n\nFig. 5 shows the proposed structural framework of our m- Commerce application that utilizes stablecoin as currency for online retail purchases.\n\nFig. 5. Proposed structural framework of the m-Commerce application for retail purchases using stablecoin cryptocurrencies.\n\nFig. 6 shows some of the conceptual design of our mo- bile application interfaces. Note that the design follows the minimalist instruction framework as described in [17]. The proposed application would also allow users to get update on the current market value of the selected stablecoins, and keeping track of its fluctuation (if any), using the chart feature.\n\nFig. 6. Interface design for the m-Commerce application with stablecoin payment options.\n\nFig. 7 presents the structural model of the proposed appli- cation using class diagram representation. Note that we adopt the use of Model-View-Controller (MVC) architectural design for the proposed m-Commerce application. The proposed development of this mobile application plat- form with security features and a blockchain integration technique, will allow people to exchange stablecoins in an easy and an effective way in order to promote cryptocurrency and blockchain usage in the development of a new financial system.\n\nIV. CONCLUSIONS In this paper, we present our work-in-progress on the design and development of mobile commerce application that incor-\n\nFig. 7. Domain class diagram representation for the proposed application.\n\nporate stablecoin payment option. We have conducted a review on existing concept and features of stablecoin cryptocurrencies and how different types of stablecoin can be used in online financial transactions within a decentralized environment. The proposed m-Commerce application would further be used as a proof-of-concept for fully online commercial applications that are based on stablecoin-based cryptocurrencies.\n\nREFERENCES\n\n[1] S. Khan, M. Shael, M. Majdalawieh, N. Nizamuddin, and M. Nicho, \u201cBlockchain for governments: The case of the dubai government,\u201d Sustainability , vol. 14, no. 11, p. 6576, 2022.\n\n[2] H. Treiblmaier, D. Leung, A. O. Kwok, and A. Tham, \u201cCryptocurrency adoption in travel and tourism\u2013an exploratory study of asia pacific travellers,\u201d Current Issues in Tourism , vol. 24, no. 22, pp. 3165\u20133181, 2021.\n\n[3] Z. LING, C. LIU, and E. YUAN, \u201cA bitcoin valuation model assuming equilibrium of miners\u2019 market\u2013based on derivative pricing theory,\u201d 2019.\n\n[4] M. Choi and G. Rocheteau, \u201cMoney mining and price dynamics,\u201d American Economic Journal: Macroeconomics , vol. 13, no. 4, pp. 246\u2013 94, 2021.\n\n[5] D. Bullmann, J. Klemm, and A. Pinna, \u201cIn search for stability in crypto- assets: are stablecoins the solution?\u201d ECBOccasional Paper , no. 230, 2019.\n\n[6] B. Eichengreen, \u201cFrom commodity to fiat and now to crypto: what does history tell us?\u201d National Bureau of Economic Research, Tech. Rep., 2019.\n\n[7] L. Ante, I. Fiedler, and E. Strehle, \u201cThe influence of stablecoin issuances on cryptocurrency markets,\u201d Finance Research Letters , vol. 41, p. 101867, 2021.\n\n[8] P. Bains, A. Ismail, F. Melo, and N. Sugimoto, \u201cRegulating the crypto ecosystem: The case of stablecoins and arrangements,\u201d FinTech Notes , vol. 2022, no. 008, 2022.\n\n[9] G. Hileman, \u201cState of stablecoins (2019),\u201d Available at SSRN 3533143 , 2019.\n\n[10] A. Lipton, A. Sardon, F. Sch\u00a8ar, and C. Sch\u00a8upbach, \u201cFrom tether to libra: Stablecoins, digital currency and the future of money,\u201d arXiv preprint arXiv:2005.12949 , 2020.\n\n[11] K. Ito, M. Mita, S. Ohsawa, and H. Tanaka, \u201cWhat is stablecoin?: A survey on its mechanism and potential as decentralized payment systems,\u201d International Journal of Service and Knowledge Management , vol. 4, no. 2, pp. 71\u201386, 2020.\n\n[12] S. Wang, W. Ding, J. Li, Y. Yuan, L. Ouyang, and F.-Y. Wang, \u201cDecen- tralized autonomous organizations: Concept, model, and applications,\u201d IEEETransactions on Computational Social Systems , vol. 6, no. 5, pp. 870\u2013878, 2019.\n\n[13] A. Berentsen and F. Sch\u00a8ar, \u201cStablecoins: The quest for a low-volatility cryptocurrency,\u201d The economics of Fintech and digital currencies , pp. 65\u201375, 2019.\n\n[14] C. Dannen, Introducing Ethereum and solidity . Springer, 2017, vol. 1.\n\n[15] A. R. Sai, J. Buckley, and A. Le Gear, \u201cPrivacy and security analysis of cryptocurrency mobile applications,\u201d in 2019 fifth conference on mobile and secure services (mobisecserv) . IEEE, 2019, pp. 1\u20136.\n\n[16] H. Jang, S. H. Han, J. H. Kim, and K. Kown, \u201cIdentifying and improving usability problems of cryptocurrency exchange mobile applications through heuristic evaluation,\u201d in International Conference on Applied Human Factors and Ergonomics . Springer, 2020, pp. 15\u201321.\n\n[17] M. Fr\u00a8ohlich, C. Kobiella, A. Schmidt, and F. Alt, \u201cIs it better with onboarding? improving first-time cryptocurrency app experiences,\u201d in Designing Interactive Systems Conference 2021 , 2021, pp. 78\u201389."
    },
    {
        "number": 1570886945,
        "title": "OrderBookVis: A Visualization Approach for Comparing Order Books from Centralized Crypto Exchanges",
        "abstract": "Trading for a currency pair on centralized crypto exchanges is organized via an order book, which collects all open buy and sell orders at any given time and thus forms the basis for price formation. Usually, the exchanges provide basic visualizations, which show the accumulated buy and sell volume in an animated 2D representation. However, this visualization does not allow the user to compare different order books, e.g., several order book snapshots. In this work, we present OrderBookVis, a 2.5D representation that shows a discrete set of order books comparatively. For this purpose, the individual snapshots are displayed as a 2D representation as usual and placed one after the other on a 2D reference plane. As possible use cases, we discuss the analysis of the temporal evolution of the order book for a fixed market and the comparison of different order books across multiple markets.",
        "review": {
            "strength": [
                "The paper suggests a 2.5D representation that shows discrete sets of order books which allows users to compare different order books.",
                "The paper addresses the topic of visualisation of centralised crypto exchange data in a novel and innovative way. The methodology (2.5D representations) provides a middle ground between the limited 2D order books from centralised exchanges and the more complex social network representations of user and transaction data. The proposed visualisation technique allows for important analysis of the evolution of individual order books over time, and comparisons of order books from multiple exchanges.",
                "Overall: A good paper for outlining the domain and the paper's contribution for the uninitiated; lucid overview\nAbstract: Gives an apt outline of the paper (can be seen as a glimpse of each of the constituent sections); abstract is therefore correctly representative of the writing.\nFormalisation of technicalities: Systemisation equation (Reference [3]), Figure 3 (Reference [16]).\nScope of related work: Reference to financial crime, mining pool, analytics.\nNo plagiarism - excellent.",
                "1. Paper presents OrderBookVis, a 2.5D visualization for representing a discrete set of order books composed of several depth charts placed one after the other in a reference plane.\n2. The background was presented well to make it easy to understand the proposed idea in the paper, and related works were well-researched and analyzed."
            ],
            "shortcoming": [
                "It seems that the visibility is a bit low to identify the difference between the order books shown through the graph and use it for efficient trading.",
                "The main shortcoming is that a scalable implementation is still to be developed. The main concern would be with regards to the speed and efficiency, especially when presented in a dashboard.",
                "Although the paper does mention what the contribution is, the impact and benefits of this contribution are not clear. Does this work only bridge a gap, or is this platform completely novel, or is it a manifestation of consolidation of needs and ideas from multiple perspectives? The 'value added' by this paper, if more explicit, could help the readers understand the purpose of this writing; at present, it comes across an introduction to the contribution rather than a comprehensive description of the contribution itself. \nRelated work: Is not in-depth. The categorisation of the related work can be more structured; the themes briefly introduced (e.g. mining pool, analytics) can serve as subheadings to this section where more work is referenced and analysed for pros, cons, and gaps. This section should ideally also be more in depth (i.e. citing either more papers, so as to give more insights; or conducting a thorougher analysis of the work already cited in this section). Because this section is not categorised by themes in related work, the process of its comparison with the method proposed by this paper becomes less succinct. \nBasics: The figures are not referred to chronologically (in numerical order) in the text - the order of reference followed is Figure 1, 3, 2, 4 (the ideal order being 1, 2, 3, 4 - thereby pointing to a need for renumbering and re-organising existing figures). \nIII A: 'complexity' in terms of what, has not been elucidated. A table might be better to represent/consolidate the information in this section, or overall section III.\nIII C: Although this is a technical section, no further substantiation is provided regarding it. e.g. the Python script for reading and transferring data, if relevant, could be given as a code snippet. Although a relevant consideration to have here would be what field the intended audience of the paper is supposed to be: is it an academician audience in a technical field, or a more industry-oriented audience? The substantiation can then be according given in respective terms. Presently, it is not.\nIV B: 'favourable at Binance' - unclear if this is an insight (derived by the authors through study and/or experience) or a direct description that stands true regardless of perspective.",
                "1. Low contribution. It is judged that the contribution of simply overlapping and visualizing the order book data is somewhat weak.\n2. It is difficult to find out what value the graph representing the result means, and it is difficult to find a novelty that is sufficiently convincing on how to utilize the research results."
            ],
            "comment": [
                "-The visualization approach that integrates and shows the order books of multiple exchanges can be said to be novel, but the visibility is too low to actually use it. Introducing other visualization methods that make it easy to understand the difference between order books rather than simply visualizing order book graphs by overlapping them seems to help improve the completeness of the system.\n- It would be better to unify the expression for 2.5 or 3 dimensions of the depth chart.",
                "The paper addresses the topic of visualisation of centralised crypto exchange data in a novel and innovative way.  The methodology (2.5D representations) provides a middle ground between the limited 2D order books from centralised exchanges and the more complex social network representations of user and transaction data. It would be great to see an implementation of the visualisation system, and also to know (if possible) more details regarding the frequency at which data can be retrieved and processed by the system.",
                "In some way, the intended audience should either be mentioned or implied.- mention determines technical scope\nAdequate premises for and connection between the combination disciplines of finance and cryptocurrency should be made clearer. This can be done by defining a terminology section at the beginning of the second section. For example, terms from IV A can be defined here, instead of doing it later. This can also be used for further detailing the scope in terms of audience: which is important and should ideally dictate the tone, depth, and structure of the paper, for maximum utility.\nA clearer distinction should be made within and between sections. A better organised paper is better understood.\nA more explicit expression of the paper's contribution, as precisely as possible, makes the readers aware about its purpose - therefore the purpose of the very act of reading the paper itself.",
                "- A more detailed analysis of whether the data can be utilized seems necessary. It would be good to think about what kind of use case there will be in terms of efficiently trading cryptocurrency in practice.\n- Also, the visibility of the graph is poor. Other visualization mechanisms need to be considered."
            ],
            "score": {
                "Relevance": 2.5,
                "Content and originality": 2.3,
                "Reference": 2.8,
                "Overall recommendation": 2.8,
                "Poster acceptance": 3.5
            }
        },
        "body": "1 Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam, Germany 2 XUExponential University, Potsdam, Germany { adrian.jobst, daniel.atzberger, willy.scheibel, juergen.doellner } @hpi.uni-potsdam.de mail@roberthenker.com\n\nAbstract \u2014Trading for a currency pair on centralized crypto exchanges is organized via an order book, which collects all open buy and sell orders at any given time and thus forms the basis for price formation. Usually, the exchanges provide basic visualizations, which show the accumulated buy and sell volume in an animated 2D representation. However, this visualization does not allow the user to compare different order books, e.g., several order book snapshots. In this work, we present OrderBookVis, a 2.5D representation that shows a discrete set of order books comparatively. For this purpose, the individual snapshots are displayed as a 2D representation as usual and placed one after the other on a 2D reference plane. As possible use cases, we discuss the analysis of the temporal evolution of the order book for a \ufb01xed market and the comparison of different order books across multiple markets. Index Terms \u20142.5DVisualization, Centralized Exchanges, Or- der Book\n\nI. INTRODUCTION\n\nWhen trading cryptocurrencies or derivatives based on them, buy and sell orders are gathered in an order book. At any time, the bid side (offers to buy) and the ask side (offers to sell) consist of several levels, sorted by price in descending or ascending order. In addition to the price, each level is speci\ufb01ed by a volume, called size, which describes the tradable quantity for a level. A purchase/sale always requires a corresponding sale/purchase by a counterparty; if the size offered by a single level is not suf\ufb01cient, the price is determined as a weighted average of the entries in the order book. Especially for large orders, this can lead to signi\ufb01cant deviations. [1]. Figure 1 shows an excerpt from the \ufb01rst four levels of an order book. The trading interfaces of the various exchange operators are essentially similar and are limited in their representations to basic 2D diagrams. The accumulated volumes are displayed in a so-called depth chart, i.e., two polygons that re\ufb02ect the total volume for a price both for the bid and ask sides. Since the order book changes with each transaction, the Depth Chart is displayed in animated form. Although the visualization shows basic liquidity measures, e.g., the spread, a deep analysis is not possible. For example, it is not possible to track the\n\nFig. 1. Excerpt from the order book of the XBTUSD future contract from the exchange Bitmex . The \ufb01rst table shows the \ufb01rst four levels of the ask side, the second table the \ufb01rst four levels of the bid side. The total volume measured in USD is furthermore visualized as an bar chart in the third column. The Depth Chart shows the accumulated total volume at any price for both sides.\n\ndevelopment of an order book over time for a \ufb01xed market or to compare several order books, e.g., of a currency pair on different exchanges. In this paper, we present OrderBookVis , an extension of the widely used depth charts with an additional dimension. The idea of OrderBookVis is to arrange single depth charts, i.e. snapshots of an order book, in juxtaposition to allow the comparison of a discrete set [2]. The resulting visualization 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nFig. 2. Illustration of OrderBookVis for the currency pair BTC/USD on Binance. The individual slices represent the \ufb01rst ten levels for the bid and ask side as a depth chart for different points in time. The individual slices are arranged parallel to the shared price axis at equidistant intervals.\n\nemploys small multiples of individual 2D ridgeline plots on a 2D reference plane with graphical primitives embedded into the third dimension, i.e., its dimensionality can be systemized as A 3 \u2297R 2 [3], resulting in a 2.5D visualization. This idea originates from the ridgeline plot representation, but is extended by an additional height scale [4]. OrderBookVis allows the analysis of the temporal development of an order book, for example over a day. Alternatively, other categorical properties, such as the exchange, can be used as selection criteria for the order books. In this paper we focus on the visual mapping and the discussion of application scenarios. The remainder of this paper is structured as follows. Sec- tion II presents previous work on visualizing data from the \ufb01nancial domain, in particular data related to cryptocurrencies. Our method together with some implementation details is detailed in Section III. We discuss two application scenarios in Section IV that show the bene\ufb01t of our approach compared to existing techniques. Section V completes our exposition with conclusions and directions for future work.\n\nII. RELATED WORK\n\nThe visualization of \ufb01nancial data is an active research \ufb01eld targeting a variety of application domains [5]. A browsable survey of existing work is presented by Dumas et al. [6]. In our presentation of the related work, we focus on visualizations of order book data and aspects of cryptocurrencies, primarily Bitcoin . The visualization of order book data is primarily done using depth charts. Other 2D visualizations have been proposed for showing selected aspects of an order book but have yet to be used by domain experts [7]. We, therefore, decided to extend\n\nthe depth charts using a third dimension rather than developing another 2D variant. In doing so, we were inspired by the work of Brath and Matusiak [8]. Their approach 3Dify , extrudes common 2D charts with time series data thus generating surfaces embedded in 3D. The authors applied their approach to histograms, scatterplots, and bar and line charts, but not on depth charts for order books. Unlike 3Dify, our approach focuses on discrete data rather than continuous time series. Many visualization approaches that deal with cryptocurrency data examine market participants\u2019 transaction networks. Sun et al. presented BitVis , a 2D dashboard to capture the relationships of individual Bitcoin accounts [9]. For this purpose, data on transactions, such as price and volume, are displayed when an account is selected, which in turn is represented as a node in a social network graph. Through various interaction options, e.g., \ufb01ltering or details-on-demand, BitVis supports regulators in monitoring \ufb01nancial crime. Zhong et al. presented Silkviser , a more detailed transaction data viewing tool [10]. Besides information regarding transactions and addresses, their data processing pipeline also analyses the underlying blockchain and single blocks, which are presented on four different pages. An alternative approach was proposed by Kinkeldey et al., whose technique allows the exploration of the transaction timeline for a set of \ufb01ltered or clustered entities in the Bitcoin network [11]. A visualization framework for investigating the particular case of transactions between exchanges was proposed by Yue et al. [12]. Tovanich et al. developed MiningVis , a visual analytics tool for exploring the dynamics of the Bitcoin mining network [13]. Their approach combines various 2D visualizations for dis- playing statistics on the most active mining pools and news\n\nFig. 3. Model of a visualization pipeline: First, the raw data is undertaken through pre-processing and \ufb01ltering; second, the pre-processed data is mapped to a geometrical representation; third, the geometrical representation is rendered as an image [16].\n\nrelated to Bitcoin. By different interaction techniques, a user can investigate different analytics tasks, e.g., identifying the signi\ufb01cant miner\u2019s migration \ufb02ow between mining pools. Over the last decade, cryptocurrencies have gained much attention from professional and retail investors, as they provide high volatility. Conforti et al. developed a visual analytics tool, CryptoComparator , to support users in making invest- ment decisions [14]. Their dashboard is designed to identify promising trends in the price movements and correlations between different cryptocurrencies by utilizing basic 2D charts. However, popular trading strategies that rely on trends have proven unsuccessful in other works [15].\n\nIII. VISUALIZATION\n\nOur description of the visualization follows the stages of the visualization pipeline, as depicted in Figure 3. We \ufb01rst detail the processing stage to extract order book data from centralized crypto exchanges. We then describe the data mapping on geometric primitives and the layout. The rendering stage and its implementation details are presented at the end of this section.\n\nA. Processing and Filtering\n\nWe retrieve the order book from the APIs of the exchanges. For our considerations, receiving a snapshot of an order book at selected points in time is suf\ufb01cient via the corresponding RESTAPIs. For Binance , these are output as a json \ufb01le. By merging multiple lines, we get a ndjson that collects the discrete set of order books. For professional trading, exchanges also provide the ability to request incremental updates. The development of such a system would be accompanied by a signi\ufb01cant increase in complexity, which is why we refrain from doing so in our work.\n\nB. Mapping\n\nAt the end of the \ufb01rst stage, we are given a discrete set of order books D = { D 1 , ..., D n } that can be grouped into slices according to one or a combination of categorical or numerical attributes, e.g., trading pair, timestamp, or exchange. Each element within D is therefore given by an order book snapshot at a given time for a speci\ufb01c market and can thus be displayed as a 2D depth chart. In a 2D depth chart, the ask and bid sides are displayed as polygons whose top line originates from the total volume for a given price. The sum of all volumes of the levels below the price gives the total volume for a price. The price is shown on the horizontal axis and the\n\nFig. 4. Order book snapshots of the \ufb01rst ten levels for the currency pair BTC/USD of six different exchanges. The view allows an easy comparison of the best ask/bid across exchanges, as well as a comparison of market depth.\n\nvolume on the vertical one. Usually, the area of the ask side is displayed in red, and the area of the bid side in green. The individual depth charts are oriented on a shared price axis. The distances between the individual 2D charts can be chosen equidistantly, e.g., if they were chosen according to a nominal value, or might inherit a meaning themselves, such as time intervals.\n\nC. Rendering and Interaction\n\nThe rendering is based on the software Blender , an open- source computer graphics software 1 . The data is read and transferred through a Python script to corresponding geometric primitives. Materials are assigned to each object, i.e., each surface, the axes, and the text, and with it, a shader. Blender\u2019s rendering engine (Cycles) creates the \ufb01nal image. Blender supports basic interaction options within the development environment, e.g., zoom or rotation.\n\nIV. APPLICATION SCENARIOS\n\nIn the following, we discuss two use cases of OrderBookVis. First is the representation of the evolution of the order book for one market, followed by comparing order books across different exchanges.\n\nA. Evolution of an Order Book\n\nFigure 2 shows an example visualization for our \ufb01rst use case. Each slice shows the Depth Chart for a snapshot of the order book at \ufb01ve-minute intervals. In particular, two basic liquidity measures can be derived from each slice: the spread and the market depth. The spread is the difference between the best ask and best bid and is particularly relevant for small investors who only place small volumes. The height in the Depth Chart re\ufb02ects the market depth for a price. The so-called \u201dwalls\u201d are particularly interesting here, i.e., sudden increases in market depth. A wall forms a hurdle or support for the price development since a large size of a level would have to be cleared to move the price. From the \ufb01gure, it can be derived that the reference price, i.e., the average price between the\n\n1 www.blender.org/\n\nbest ask and best bid, remains almost constant over the period shown. The spread also mostly stays the same. It is noticeable that between 3:10 and 3:15, a wall at level 6 arises from the placement of limit orders.\n\nB. Comparison of Multiple Exchanges\n\nIn addition to time points, other categorical attributes can be used to select order books. Figure 4 shows an example of six order books describing the currency pair BTC/USD but from different exchanges. From the comparative representation, the trading venue with the best characteristics for placing an order can be directly identi\ufb01ed. For example, a sale of small volumes is most favorable at Binance. Furthermore, large sell orders can be placed on Binance, Kraken, Coinbase, and Bitmex exchanges as they have walls as support. Furthermore, similarities can also be seen across the different marketplaces, such as walls at similar price levels on the ask side.\n\nV. CONCLUSIONS\n\nVisualizations can help users explore complex data interac- tively. In \ufb01nance, simple 2D representations are usually used to visualize simple data, e.g., price movements using line charts. The order book is the central source of information for various use cases. Traders and investors need knowledge about the structure and dynamics of an order book to recognize market phases with high liquidity, in which trading is possible with minor price distortions. Furthermore, the order book enables the detection of prohibited market activities, e.g., wash trading, and is therefore also of interest to regulatory authorities. To support users in exploring order book dynamics, we present OrderBookVis, a 2.5D visualization for representing a discrete set of order books composed of several depth charts placed one after the other in a reference plane. OrderBookVis allows the comparison of several order book snapshots to analyze the evolution of a single order book. As another application, order books for one currency pair across different exchanges can be compared. For future work, we plan to develop a scalable implemen- tation using WebGL, enabling more interactions, e.g., details- on-demand. This will be presented in a dashboard together with other data visualizations, such as an analysis of relevant Twitter data. Subsequently, we plan to conduct a user study with professional investors whose activities focus on crypto exchanges.\n\nACKNOWLEDGMENT\n\nPart of this research work is supported by a PhD grant from the HPIResearch School for Service-Oriented Systems Engi- neering at the Hasso Plattner Institute for Digital Engineering, University of Potsdam. The funding is gratefully acknowledged.\n\nREFERENCES\n\n[1] Martin Angerer, Marius Gramlich, and Michael Hanke. Order book liquidity on crypto exchanges. In Proceedings of the 3rd Crypto Asset Lab Conference , CAL \u201921. Crypto Asset Lab, 2021.\n\n[2] Sehi L\u2019Yi, Jaemin Jo, and Jinwook Seo. Comparative layouts revisited: Design space, guidelines, and future directions. IEEETransactions on Visualization and Computer Graphics , 27(2):1525\u20131535, 2021.\n\n[3] Steve D \u00a8 ubel, Martin R \u00a8 ohlig, Heidrun Schumann, and Matthias Trapp. 2d and 3d presentation of spatial data: A systematic review. In Proceedings of the VISInternational Workshop on 3DVis , 3DVis \u201914, pages 11\u201318. IEEE, 2014.\n\n[4] Claus O. Wilke. Introduction to ggridges, 2022. URL : cran.r- project.org/web/packages/ggridges/vignettes/introduction.html.\n\n[5] Sungahn Ko, Isaac Cho, Shehzad Afzal, Calvin Yau, Junghoon Chae, Abish Malik, Kaethe Beck, Yun Jang, William Ribarsky, and David Ebert. A survey on visual analysis approaches for \ufb01nancial data. Computer Graphics Forum , 35(3):599\u2013617, 2016.\n\n[6] Maxime Dumas, Michael McGuf\ufb01n, and Victoria Lemieux. Financevis. net-a visual survey of \ufb01nancial data visualizations. In Poster Abstracts of IEEE conference on visualization , 2014. URL : http://\ufb01nancevis.net/.\n\n[7] Mark Paddrik, Richard Haynes, Andrew Todd, William Scherer, and Peter Beling. Visual analysis to support regulators in electronic order book markets. Environment Systems and Decisions , 36:167\u2013182, 2016.\n\n[8] Richard Brath and Martin Matusiak. 3Dify: Extruding common 2D charts with timeseries data. In Proceedings of the International Conference on Virtual Reality and 3DUser Interfaces Abstracts and Workshops , VRW \u201922, pages 606\u2013607. IEEE, 2022.\n\n[9] Yujing Sun, Hao Xiong, Siu Ming Yiu, and Kwok Yan Lam. Bitvis: An interactive visualization system for bitcoin accounts analysis. In Proceedings of the Crypto Valley Conference on Blockchain Technology , CVCBT \u201919, pages 21\u201325. IEEE, 2019.\n\n[10] Zengsheng Zhong, Shuirun Wei, Yeting Xu, Ying Zhao, Fangfang Zhou, Feng Luo, and Ronghua Shi. SilkViser: A visual explorer of blockchain- based cryptocurrency transaction data. In Proceedings of the Conference on Visual Analytics Science and Technology , VAST \u201920, pages 95\u2013106. IEEE, 2020.\n\n[11] Christoph Kinkeldey, Jean-Daniel Fekete, and Petra Isenberg. Bitconduite: Visualizing and analyzing activity on the bitcoin network. In Posters Track of the Eurographics Conference on Visualization , EuroVis \u201917. EG, 2017.\n\n[12] Xuanwu Yue, Xinhuan Shu, Xinyu Zhu, Xinnan Du, Zheqing Yu, Dim- itrios Papadopoulos, and Siyuan Liu. Bitextract: Interactive visualization for extracting bitcoin exchange intelligence. IEEETransactions on Visualization and Computer Graphics , 25(1):162\u2013171, 2019.\n\n[13] Natkamon Tovanich, Nicolas Souli \u00b4 e, Nicolas Heulot, and Petra Isenberg. Miningvis: Visual analytics of the bitcoin mining economy. IEEETransactions on Visualization and Computer Graphics , 28(1):868\u2013878, 2022.\n\n[14] Pietro Manganelli Conforti, Matteo Emanuele, Pietro Nardelli, Giuseppe Santucci, and Marco Angelini. CryptoComparator: A visual analytics environment for cryptocurrencies analysis. In Proceedings of the EuroVis Workshop on Visual Analytics , EuroVA \u201922. EG, 2022.\n\n[15] Kin-Hon Ho, Tse-Tin Chan, Haoyuan Pan, and Chin Li. Do candlestick patterns work in cryptocurrency trading? In Proceedings of the International Conference on Big Data , BigData \u201921, pages 4566\u20134569. IEEE, 2021.\n\n[16] Matthew OWard, Georges Grinstein, and Daniel Keim. Interactive data visualization: foundations, techniques, and applications . AKPeters/CRCPress, 2010."
    },
    {
        "number": 1570886964,
        "title": "DEEPER: Enhancing Liquidity in Concentrated Liquidity AMM DEX via Sharing",
        "abstract": "This paper presents DEEPER, a design for a decentralized exchange that enhances the average active liquidity via reserve sharing. By doing this, it addresses the problem of shallow liquidity in low trading volume token pairs. DEEPER allows liquidity providers of multiple trading pairs against a common token to share liquidity. This is achieved by creating a common reserve pool for the shared token that is accessible by each trading pair. Independent from the shared liquidity, providers are free to add liquidity to individual token pairs without any restriction. The trading between one token pair does not affect the price of other token pairs even though the reserve of the shared token changes. The proposed design is an extension of concentrated liquidity market maker-based DEXs that is simple enough to be implemented on smart contracts. Experiments show that for a batch consisting of 8 trading pairs, DEEPER enhances liquidity by over 2.6 \u2212 5.9\u00d7. This enhancement in liquidity can be increased further by increasing participating tokens in the shared pool.",
        "review": {
            "strength": [
                "1. This paper explains 2 types of AMM (CPAMM, CLAMM) details with formula.\n2. This paper propose the mechanism of shared liquidity based on Uniswap DEX V3, and it shows significant liquidity boost rather than original.",
                "- the paper presents the design of a decentralized exchange characterized by a novel idea: it manages a shared reserve with a common currency and allows providers of multiple tokens to assemble and share their liquidity for the common currency. The idea is novel and the paper is very interesting.\n- a set of experiments showing the feasibility of the approach is presented\n- the topic is fully in line with the workshop's topics",
                "This paper provides new design for DEX that enhances the average liquidity via reserve sharing among multiple tokens of shallow liquidity. The  solution is logically worthy and is also justified to prove it.",
                "- This paper points out the problem well about the difference when the each trading token pair don't have similar amount of liquidity.\n- It defines liquidity provisions to shared and individual, and well defined."
            ],
            "shortcoming": [
                "1. In protocol design section, it\u2019s hard to understand the concept because there is no figure of design.\n2. Also, in this paper, the symbol of token and time looks same, and it makes confusing.",
                "- Some parts of the paper are tough for a non-expert reader, and the readability could be improved",
                "It makes sense that it is a smart contract-friendly solution. However, it would be nice if more discussions could be made on the matters to be considered when implementing the proposed method in DEX.",
                "- It should include related research about the introduced AMM and current exchange's relationship.\n- There is no future work about this protocol's apply plan.\n- When using the symbols of time and token, it looks too similar to distinguish"
            ],
            "comment": [
                "At last paragraph of section 3.A, it should be better that adding references on \u2018Expanding on the las point, with the explosion of DeFi and other ecosystems in blockchain and the reduced trust in CEXs, it has become crucial for on-chain DEXs to sustain a fair market for thousnads of token pairs.",
                "- I think the paper is very interesting, but a bit tough to read. I understand that the topic requires both computer science and economic knowledge, anyway, I suggest that the authors present if the paper will be accepted,  a brief introduction to the main concepts.",
                "It makes sense that it is a smart contract-friendly solution. However, it would be nice if more discussions could be made on the matters to be considered when implementing the proposed method in DEX.",
                "- In protocol evaluation part, it only simulated with Uniswap's historical data. It needs more evaluation with real operation of DEX with this paper's protocol.\n- Details of each trading pairs (each liquidity or trading volume) and tendency of some cases like when the trading assets are consist with low trading volume, etc can be also helpful to evaluate the result."
            ],
            "score": {
                "Relevance": 3.0,
                "Content and originality": 4.0,
                "Reference": 3.3,
                "Overall recommendation": 3.8,
                "Poster acceptance": 4.0
            }
        },
        "body": "I. INTRODUCTION\n\nFollowing the success of Ethereum [1], blockchains are fostering the promise of decentralization by remov- ing central points of failure and bringing trustlessness in traditional technology sectors. This includes revolution- izing Financial Technology (FinTech) with Decentral- ized Finance (DeFi) [2], research platforms with decen- tralized science [3], gaming with game finance [4], web services [5], supply chains [6], and social engagement platforms [7]. A key aspect in the design of a decentral- ized model is an economic incentive that is enabled using cryptocurrency tokens [8]. Apart from incentives, tokens can provide utility in web applications, governance rights via voting, or tokenization of real-world assets [9]. These tokens can be traded on a Centralized Exchange (CEX) that adopts the traditional Central Limit Order Book (CLOB) mechanism or a Decentralized Exchange (DEX) running Automated Market Making (AMM) al- gorithms. In AMMs, liquidity providers (LPs) deposit a pair of assets that other traders can swap. For every swap, the trader pays a fee proportional to the swap amount that goes to the LPs. Traders prefer an asset pair with significant liquidity because otherwise, it can lead to unconventional price movements (also known\n\nas \u201cslippage\u201d) where the trading pair\u2019s price becomes vulnerable to manipulation. At the same time, LPs are not incentivized to provide significant liquidity when the trading volume of a pair is very low since fewer fees will be distributed to them. Therefore, a new design of a marketplace is needed where tokens that have a low trading volume also enjoy significant liquidity without incurring additional costs to the LPs to acquire more token reserves. This paper presents DEEPER , a design for a decen- tralized exchange that allows LPs of multiple tokens against a common currency to assemble and share their liquidity for that common currency. Unlike other multi- token pool platforms like Balancer [10], DEEPER re- mains a sovereign AMMDEX and does not depend on arbitrageurs to adjust the price of a token when a trade is made between other tokens in the pool. DEEPER extends a concentrated liquidity AMM with the functionality of shared reserve for the common currency in a batch of multiple trading pairs. The shared reserve access mecha- nism ensures that the reserves in the shared pool never go negative. Sharing currency reserves is optional and does not prevent LPs to provide concentrated liquidity for individual trading pairs. Lastly, the design of DEEPER is kept simple enough making it practical to implement it on EVM-based smart contracts. Experiments presented here on historic price move- ments of low trading volume tokens show that DEEPER can enhance the liquidity for a trading pair in a batch of 8 assets by a factor of up to 5 . 9 \u00d7 . In doing so, LPs do not need to provide any additional reserves of tokens compared to the contemporary AMM designs. This increased liquidity can be enhanced further by increasing the number of pooled tokens in a batch or by frequently updating liquidity profiles. The paper is organized as follows: Section II gives preliminaries on AMMs and concentrated liquidity, Sec- tion III describes the problem statement and gives an overview of the solution, Section IV presents the design of DEEPER DEX and comments on divergence loss for LPs and finally, the paper is concluded in Section VI.\n\nII. BACKGROUND A. Constant Product Automated Market Makers (CPAMMs) CPAMM was the first successful algorithmic market maker introduced by the Uniswap DEX [11], which is 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nT a reserves\n\nBefore swap\n\nT b reserves\n\nAfter swap\n\nToken reserves\n\nr a (p)\n\nr b (p)\n\n\u0394r a\n\n\u0394r b\n\n(a) Token reserves during a swap\n\nLiquidity = L\n\nT a reserves\n\nT b reserves\n\nToken reserves\n\nLiquidity = L\u2019\n\nr a (p)\n\nr b (p)\n\n\u0394r a\n\n\u0394r b\n\n(b) Token reserves during liquidity provision\n\nPrice = p 0 Price = p 1\n\nT a reserves\n\nT b reserves\n\n\u0394r a\n\n\u0394r b\n\nToken reserves\n\nr a (p 0 )\n\nr b (p 0 )\n\nr a (p 1 )\n\nr b (p 1 )\n\nInactive reserves\n\n(c) Token reserves in concentrated liquidity\n\nFig. 1: (a) and (b) illustrate token reserves during a swap and liquidity provision respectively in CPAMM. (c) illustrates real token reserves during a swap in concentrated liquidity AMM.\n\ngoverned by the constant product formula . In a nutshell, consider a trading pair consisting of tokens T a and T b such that the price of T a with respect to T b is p . Then, the liquidity pool of the above pair has active token reserves as a function of price comprising r a ( p ) , and r b ( p ) units of T a and T b respectively, such that r a ( p ) r b ( p ) = L 2 , where L does not depend on p . The constant L is called the liquidity of the pool. As derived in [12], the marginal price p turns out to be the ratio of the current token reserves i.e. p = r b ( p ) r a ( p ) . This can be interpreted as the equivalent amount of T b per unit amount of T a in the reserves. The expression for token reserves can therefore be derived as follows:\n\nr a ( p ) = p\n\nr a ( p ) r b ( p )\n\ns\n\nr a ( p ) r b ( p ) = L \u221a p\n\nr b ( p ) = p\n\nr a ( p ) r b ( p )\n\ns\n\nr b ( p ) r a ( p ) = L \u221a p\n\n(1)\n\nWhen a trader swaps \u2206 r a units of T a at price p , then (1 \u2212 \u00b5 )\u2206 r a is collected as liquidity fees for LPs where \u00b5 \u2208 [0 , 1] and is set close to 1 . In return, the trader\n\nreceives \u2206 r b units of T b following the constant product rule, i.e.\n\n( r a ( p ) + \u00b5 \u2206 r a )( r b ( p ) \u2212 \u2206 r b ) = L 2 (2)\n\nAn illustration of token reserves before and after the swap for \u00b5 = 1 is shown in Figure 1a. Furthermore, LPs can alter liquidity by adding or removing token reserves. If an LP provides \u2206 r a and \u2206 r b of T a and T b respectively at price p , then the following needs to hold: \u2206 r a \u2206 r b = r a ( p )\n\nr b ( p ) (3)\n\nHere \u2206 r a , \u2206 r b should either be both positive (mint) or negative (withdraw). The new liquidity L \u2032 can now be calculated as ( r a ( p ) + \u2206 r a )( r b ( p ) + \u2206 r b ) = ( L \u2032 ) 2 . Figure 1b gives an illustration of token reserves when liquidity increases in the pool. Although in CPAMM liquidity does not change with the price of the tokens, this is not the case in concentrated liquidity AMM as presented next.\n\nB. Concentrated Liquidity AMM (CLAMM)\n\nConsider Figure 1c where the price of T a increases from p 0 to p 1 , T a reserves reduce by \u2206 r a while T b reserves increase by \u2206 r b . In this price interval, only \u2206 r a of T a and \u2206 r b of T b are actively swapped while the rest of the reserves (marked with dashes) remain inactive. This is the key idea behind CLAMMs where LPs can provide liquidity in a price interval [ p 0 , p 1 ] by only supplying \u2206 r a units of T a and \u2206 r b units of T b . Meanwhile, the liquidity in CLAMM is the same as CPAMM, i.e. L 2 = r a ( p ) r b ( p ) . When the price is outside the above price interval, the liquidity becomes inactive. Hence in a CLAMM, r a ( p ) , r b ( p ) are called virtual reserves . The real reserves of T a , T b at price p \u2208 [ p 0 , p 1 ] , denoted by r \u2032 a ( p ) , r \u2032 b ( p ) can therefore be calculated in terms of virtual reserves as follows:\n\nr \u2032 a ( p ) = r a ( p ) \u2212 r a ( p 1 ) = L ( 1 \u221a p \u2212 1 \u221a p 1 )\n\nr \u2032 b ( p ) = r b ( p ) \u2212 r b ( p 0 ) = L ( \u221a p \u2212\u221a p 0 ) (4)\n\nWe used the result from Equation 1 to derive the expressions for virtual reserves in terms of liquidity and price. Observe that at the boundaries of the interval, i.e. p \u2208{ p 0 , p 1 } , the real reserves consist of either only T a or T b . L remains constant within a price interval but can vary across intervals. Concentrated liquidity, therefore, allows LPs to add arbitrary liquidity in different price intervals. Figure 2 shows an example liquidity profile by an LP across price intervals. The liquidity at price p is denoted by L ( p ) . Figure 3 presents the corresponding real reserves provided for each price interval. The active price interval is marked with circled ticks and consists of both T a and T b reserves. The inactive price intervals consist of only T a or T b for prices higher or lower than the current price.\n\nPrice\n\nL(p)\n\nFig. 2: Liquidity distribution during interval T.\n\nPrice\n\nT a real reserves\n\nT b real reserves\n\nReal Reserves\n\nFig. 3: Illustration of real reserves distribution of an LP in concentrated liquidity DEX.\n\nIII. WORK MOTIVATION A. Capital Efficiency and Fair Markets As mentioned in Equation 2, the revenue of an LP comes from the trading fee that is charged as a constant fraction of the tokens swapped. Problems arise when the trading volume of a token pair T / T c ( T c is a highly liquid currency) is orders of magnitude lower than other trading pairs. This can be caused due to the following reasons: T is a newly launched token and its underlying utility has not gained traction among users; T has a seasonal utility ( e.g. , a DAO token used for voting in a protocol [13], an access token for a real-world event [7], or a football club fan token); the overall market has low liquidity due to the high cost of acquiring capital, i.e. high borrowing rates; T targets a small niche of users ( e.g. , T represents an LP token of a Uniswap V2 pool). One or more of the above conditions leads to a lower trading volume of the T / T c pair that causes the following cascading consequences:\n\n1) As lower trading volume leads to lower LP fees, this reduces the incentive for an LP to participate. Moreover, this exposes them to the risk of an overall loss if their impermanent loss (as discussed later in Section IV-D) dominates the trading fees. If the trading fee is set high enough to increase the LP\u2019s incentives, it discourages the token users, and traders including arbitrageurs to trade T .\n\n2) If the T / T c pair ends up with low liquidity, then it is subject to unfavorable economic events of high volatility and high slippage. Moreover, low\n\nliquidity also makes a trading pair vulnerable to price manipulations since low capital is now required to manipulate reserve ratios and hence the prices. This also gives room to DeFi attacks such as sandwich attacks [14] where an attacker sandwiches a buy order for T with a large buy and sell order respectively of equal amounts and the swapper ends up paying a higher price for their trade. These consequences can seriously damage the integrity of a platform whose operation relies on the fairness of the token price, for example, when T represents a DAO or a voting token.\n\n3) Despite their exposure to impermanent loss, if an LP provides deep liquidity to a low-volume trading pair, this approach is not capital efficient. This is because the liquidity capital stays idle for the majority of the time and suffers opportunity costs. Expanding on the last point, with the explosion of DeFi and other ecosystems in blockchain and the re- duced trust in CEXs, it has become crucial for on-chain DEXs to sustain a fair market for thousands of token pairs [15]. This requires a mechanism that enhances the liquidity profile while consuming low input capital ( i.e. , real reserves). Furthermore, the solution design should be easily implementable on common blockchain environments such as the Ethereum virtual machine or EVM.\n\nB. Evaluation Metric In this paper, we consider N trading pairs of tokens T 0 , T 1 . . . TN \u2212 1 against a digital currency T c with high liquidity ( e.g. , ETH). We profile the liquidity on an AMM and the price of these trading pairs in a constant time interval I . Such a time interval gives a finite range of prices that are processed. The price of the token at time t is denoted by p ( t ) . The price of each T i is divided into intervals of uniform width. We assume that during I , no LP mints or withdraws their liquidity. Let L i ( p ( t )) denote the liquidity profile for T i at price p ( t ) at a given instance t . At t = 0 , the total real reserves of T i , T c for the pair i are denoted by r \u2032 i , r \u2032 i , c respectively. Suppose there are two LPs with their proposed liquidity profiles L i ( p ) and L \u2032 i ( p ) with respect to the price for each trading pair. Then for each pair, we compare the two profiles by calculating the metric z i as follows:\n\nI \u00b7 z i = ZI\n\n0\n\nL i ( p ( t )) L \u2032 i ( p ( t )) dt (5)\n\nThe above metric informs, on average, the enhancement in experienced liquidity when the liquidity profile is L ( p ) in comparison to L \u2032 ( p ) for a trading pair i . The total initial real reserves for T c provided collectively by the LPs equals:\n\nr \u2032 total , c =\n\nN \u2212 1 X\n\ni = 0 r \u2032 i , c (6)\n\nFormally, our objective is to maximize the average increase in liquidity z i for each trading pair without changing the total initial currency reserves r \u2032 total , c and token reserves r \u2032 i for T i .\n\nC. DEEPER Overview DEEPER is a DEX design that allows LPs of different trading pairs against a common currency to gather and pool their currencies to enhance the available liquidity of each of the trading pairs. Given a batch of N trading pairs T i / T c on DEEPER , each pair gets real T c reserve for liquidity provision in one of the two ways:\n\n1) Individual reserves for concentrated liquidity in each price range (same as in CLAMM).\n\n2) Shared reserves where an LP provides initial liq- uidity profiles for the inactive price intervals of each pair, and deposits a lump sum T c in the shared reserves pool accessible by all pairs. Let R denote the amount of T c in the shared pool at a given instance. During the time interval [0 , T ] , if the price of T i increases activating a higher price inactive interval that consists of only T i , then the accumulated T c from the recently inactivated interval is added to the shared reserves pool and R increases. Likewise, if the price of T i decreases such that a lower price inactive interval requiring only T c becomes active, then those tokens are withdrawn from R and allocated to the newly activated interval. The reserves allocation from the shared pool is designed such that the shared reserve pool never goes negative. In the unlikely event of reducing T i prices leading to a dried-up shared reserves pool, the individual concentrated liquidity provision per token pair starts to dominate. This serves as a fail-safe mechanism when the price crash of one trading pair consumes significant shared reserves.\n\nIV. PROTOCOL DESIGN DEEPER is a CLAMM-based DEX design that allows LPs of several trading pairs with a common currency to come together and share their currency reserves. This, however, does not prevent an LP to provide individual liquidity to just one pair. Thus, for each asset pair T i / T c , we define two kinds of liquidity provisions: shared and individual . The shared liquidity provision is explained below.\n\nA. Shared Liquidity Provision The total available shared reserves of T c represented by R is split between busy reserves or R b and available reserves or R a so that R = R a + R b . The virtual liquidity profile, for shared liquidity pro- vision, of a trading pair i is divided into intervals of prices of uniform width. Each interval is mapped to an integer tick such that if an interval [ p 0 , p 1 ) has tick k , then p [ k ] = p 0 . Similarly, L i [ k ] and r \u2032 i,c [ k ] represent the liquidity and the corresponding T c reserves (either active or inactive) in tick k at a given instance. Let K i be the tick of the currently activated interval with K i being its value at the beginning, i.e. t = 0 for each trading pair T i / T c . Liquidity provision using shared T c reserves consists of the following specifications:\n\n1) To provide shared T c at t = 0 , LPs need to (i) provide liquidity profile for each trading pair i , i.e. L i [ k ] \u2200 k \u2264 K i ; (ii) deposit r \u2032 i , c units of T c\n\nreserves in accordance with the above liquidity profile for each i . For shared provision, we call L i the skeleton liquidity profile because it will be used to calculate the actual liquidity of a price interval. Similarly, r \u2032 i , c are called the skeleton T c reserves. Since sharing LPs can only provide T c reserves, the skeleton liquidity is positive in price ticks that are less than the activated ticks and zero elsewhere. The skeleton liquidity in each interval remains constant unless some LP mints or burns their shared liquidity.\n\n2) The actual liquidity of pair i in the active price interval is denoted by L i and it remains constant when the price of T i lies within the active price interval. Swaps that do not change the price inter- val are executed based on CLAMM with L i as the virtual liquidity of the active interval.\n\n3) When the price of T i decreases such that the tick transitions from K i to K i \u2212 1 with the new interval having r \u2032 i , c [ K i \u2212 1] skeleton T c reserves, the following events occur:\n\n\u2022 The new active interval secures r \u2032 i,c [ K i \u2212 1] units of T c from available reserve pool such that:\n\nr \u2032 i,c [ K i \u2212 1] = R a ( r \u2032 i , c [ K i \u2212 1]\n\nPK i \u2212 1 j =0 r \u2032 i , c [ j ] ) (7)\n\nThis is secured by reducing the available reserves pool and increasing the busy reserves pool. Since r \u2032 i,c [ K i \u2212 1] is always a fraction of the available reserves R a , it never goes neg- ative after the operation. The actual liquidity can be derived from real reserves using the relation in Equation 4.\n\n\u2022 The token T i in the tick K i becomes inactive with its amount stored in memory and it reac- tivates in the future when the tick transitions from K i \u2212 1 to K i as discussed next.\n\n4) When the price of T i increases and the tick crosses from K i to K i +1 , then the accumulated T c in the newly inactive tick K i is transferred from busy reserves to available reserves and any T i reserves stored in the memory are released for tick K i +1 . Lastly, if the price of a pair T i goes all the way down to tick 0 , then this pair consumes all available shared T c . In such a case, individual reserves become dominant. The shared reserves, however, are restored when the price of this pair starts to increase. Therefore, the available shared T c can be potentially secured by any trading pair, and the first one to access it secures T c while the quota per price interval of every other pair reduces.\n\nB. Shared Liquidity Withdrawal & LPFees LPs can withdraw their shared T c reserves at any point. In doing so, they receive the proportion of avail- able reserves and any inactive T i that belongs to them, and the skeleton liquidity provided by them is removed for each pair. Further, any trading fee that is accrued in a price interval is distributed amongst the LPs in proportion to their skeleton liquidity.\n\nC. Individual Liquidity An LP is free to provide individual liquidity in any price range by providing T i or T c or both depending on the active state of the interval of interest. Since they cannot provide shared reserves for T i for liquidity, individual liquidity is the only way to serve this purpose.\n\nD. Divergence Loss for Shared Liquidity Providers Divergence loss is defined as the opportunity cost for an LP to provide token reserves as liquidity compared to just holding them. In CPAMM and CLAMM, given an initial liquidity profile (for e.g. , Figure 2), the divergence loss is a function of the token price [16]. Since an LP can recover any accrued losses when T i trades back at the initial price (when liquidity was provided), divergence loss is not permanent. Therefore, it is also referred to as impermanent loss . In the case of DEEPER , however, the divergence loss is not a function of just the token price, because the total T c reserves owned by an LP depend on the relative order of securing T c from the shared reserves pool by the trading pairs. However, the divergence loss still remains imperma- nent for an LP. This is described in the lemma below:\n\nLemma IV.1. The divergence loss of an LP providing shared reserves for T c at price p i for token T i with respect to T c and subsequently withdrawing their liq- uidity at the same initial price for each token is zero and independent of any intermediary price movements.\n\nProof. Suppose LPs provide a total R reserve of shared T c and a skeleton liquidity profile L i at an initial price p i for each pair i . Then, this profile is defined for the ticks less than the current active tick K i for each pair. We prove that the shared reserve for T c equals R when the price of T i becomes p i for all i . When the current tick transitions from k to k \u2212 1 and secures T c from the shared pool, the amount of shared reserves secured by tick k \u2212 1 is stored in its memory which serves as its history. Eventually, when the tick transitions back from k \u2212 1 to k , the shared T c that was withdrawn earlier is added back to the shared pool. Therefore, when the final prices become the same as the initial prices, the initial and final active ticks become the same for all the pairs. Therefore, any borrowed T c from the shared reserve pool is released back. The LPs can now withdraw exactly the initially supplied T c from the shared pool. Any T c or T i that was supplied as part of individual liquidity remains the same since individual liquidity reserves are a function of token prices. Since the LP can withdraw exactly the same amount of reserves that they supplied initially and at the same initial price, the total divergence loss suffered is zero.\n\nE. Smart Contract Friendliness A smart contract [17] is a Turing-complete program that is deployed on a blockchain. A blockchain account can asynchronously trigger functions in these programs by paying gas fees that are charged per contract oper- ation during a call. Therefore, an ideal smart contract\n\ndesign performs the minimal amount of updates in the state ( i.e., variables) of the contract during a function call. Without loss of generality, our implementation of DEEPER DEX is an extension to Uniswap V3 [18]. We add the following parameters on top of the previous design to include shared liquidity:\n\n1) We define skeleton liquidity that remains invariant throughout the period of no deposit or withdrawal of liquidity. This is implemented exactly how liquidity is implemented in Uniswap. Further, we differentiate skeleton liquidity from actual liquid- ity. Actual liquidity can be of one of two forms: active and inactive.\n\n2) Each tick (as implemented in Uniswap) keeps track of \u2206 L which is the change in skeleton liquidity. At the same time, it keeps track of the cumulative skeleton T c below the active tick and total available T c or R a . This allows it to calculate the r \u2032 i,c for a range using Equation 7 when the price decreases and a tick is crossed. The actual liquidity of the current tick is calculated using the linear relationship of L and r \u2032 i,c at the interval edge as shown in Equation 4. The value of the frozen T i is stored for all ranges crossed from the above tick. Every time when a tick is crossed, R a is updated accordingly.\n\nV. PROTOCOL EVALUATION In this section, we evaluate the benefits of the DEEPER DEX and study the parameters that optimize them. Our experiments attempt to answer the following questions: (i) What is the average increase in the experienced liquidity of our shared liquidity model compared to the individual liquidity model? (ii) What is the relationship between the shared liquidity boost and the number of trading pairs in a shared batch? (iii) How can LPs optimize their enhanced liquidity by varying I ?\n\nA. Methodology For the purposes of this evaluation, we use the his- torical price data from the month of December 2022 of trading pairs from the Uniswap V3 DEX. Each of the trading pairs exhibits the following two properties: ( i ) they are traded against Wrapped ETH, and ( ii ) had an average daily volume between $0\u201350 k. Such a trading pair with a trading fee of 0 . 3% generates a total revenue of $0\u2013150 per day for all the LPs collectively. We create three batches each containing 3, 5, and 8 trading pairs. We use three time periods of 1 day, 7 days, and 14 days for I during which the skeleton liquidity profiles remain constant. For a given token batch and time period I , we simulate the liquidity environment by initializing liquidity between the minimum and maximum price during that month. For the shared ETH, we input the skeleton liquidity profile and the corresponding ETH reserves for each pair. The skeleton liquidity peaks at the start price and decays slightly from there. For prices above the start price, we initialize individual liquidity by providing the asset token in each price interval. This liquidity decreases as price increases similar to ETH. We also create, for comparison, a model where ETH\n\n0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nETH fraction\n\n0.8\n\n1.0\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2.0\n\n2.2\n\nAverage liquidity boost\n\nBATBETA DAR\n\n(a) Batch of 3 assets\n\n0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nETH fraction\n\n1.0\n\n1.5\n\n2.0\n\n2.5\n\n3.0\n\nAverage liquidity boost\n\nBATBETA DARDENT GAL\n\n(b) Batch of 5 assets\n\n0.2 0.4 0.6 0.8 1.0\n\nETH fraction\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nAverage liquidity boost\n\nBATBETA DARDENT GALHOT OMGSLP\n\n(c) Batch of 8 assets\n\nFig. 4: Average liquidity per initial ETH boost for different asset batches\n\n0.2 0.4 0.6 0.8 1.0\n\nETH fraction\n\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\n2.5\n\n3.0\n\n3.5\n\n4.0\n\nAverage liquidity boost\n\n0.5\n\n0.9\n\n1.3\n\n1.6\n\n2.0\n\n0.8\n\n1.2\n\n1.6\n\n2.1\n\n2.5\n\n0.8\n\n1.3\n\n1.7\n\n2.2\n\n2.6\n\nI=14 days I=7 days I=1 day\n\nFig. 5: Liquidity increase for multiple values of I .\n\nis provided via individual liquidity with equal ETH allocation to each pair.\n\nB. Summary of Results Liquidity boost: Figure 4a shows the average increase in liquidity ( z in Equation 5) for a batch consisting of 3 trading pairs and I set to 1 day. The x-axis represents the total amount of initial ETH deposited as a fraction of the ETH used in the individual liquidity provision. The graph is plotted for three values of ETH fractions: 1 3 , 2 3 , 1 . We can observe that the shared liquidity is more than 80% of its individual counterpart while costing only a third of ETH reserves. Moreover, the amount of initial ETH required reduces by 55 . 1% , 60 . 2% , and 60 . 9% for the three trading pairs respectively to achieve the same average liquidity as in the individual model. When the initial ETH reserves are increased so as to consume the same ETH as the individual model, the experienced liquidity increases by 1 . 6 \u00d7 , 2 . 1 \u00d7 , 2 . 2 \u00d7 for the three trading pairs respectively. Therefore, DEEPER DEX significantly increases liquidity without consuming any surplus asset reserves. Batch size: Figures 4b, 4c illustrates the liquidity in- crease with respect to the ETH reserves used for a batch of size 5 , and 8 assets respectively. For these batches, the cost of initial ETH reduces by 70 . 0\u201378 . 2% and 75 . 6\u201383 . 2% respectively to achieve the same liquidity as the contemporary model. The corresponding average liquidity increase is between 2 . 2\u20133 . 3 and 2 . 6\u20135 . 9 respec- tively. This shows that as more trading pairs pool their\n\nETH, the liquidity per pair increases while the cost of ETH to achieve similar levels of liquidity decreases. Variation with I : Figure 5 shows the liquidity boost averaged over all the trading pairs for different values of I i.e. 1 day, 7 days, and 14 days respectively. The key observation here is that the liquidity increase decreases over longer values for I . This is because when a trading pair consumes the available ETH, there is less ETH left in the shared pool for other pairs. This becomes dominant in longer time intervals in a market scenario with decreasing prices. Therefore, LPs should either update their skeleton liquidity profiles more frequently or provide the skeleton liquidity over a longer price range to observe high shared liquidity enhancement.\n\nVI. CONCLUSION ANDF UTUREW ORKThe experimental results for DEEPER shows that reserve sharing significantly enhances average liquidity. With its shared reserve allocation mechanism and simple design, DEEPER is a practical solution to the problem of shallow liquidity provision in low trading volume trading pairs. Future work includes accounting for LP earnings from trading fees and impermanent loss when calculating the common currency allocation to a trading pair\u2019s pool.\n\nREFERENCES\n\n[1] V. Buterin, \u201cEthereum: A next-generation smart contract and decentralized application platform,\u201d 2014, https://ethereum.org/en/whitepaper/.\n\n[2] S. M. Werner, D. Perez, L. Gudgeon, A. Klages-Mundt, D. Harz, and W. J. Knottenbelt, \u201cSok: Decentralized finance (defi),\u201d arXiv preprint arXiv:2101.08778 , 2021.\n\n[3] W. Ding, J. Hou, J. Li, C. Guo, J. Qin, R. Kozma, and F.-Y. Wang, \u201cDesci based on web3 and dao: A comprehensive overview and reference model,\u201d IEEETransactions on Computational Social Systems , vol. 9, no. 5, pp. 1563\u20131573, 2022.\n\n[4] J. Proelss, S. Sevigny, and D. Schweizer, \u201cGamefi-the perfect symbiosis of blockchain, tokens, defi, and nfts?\u201d Tokens, DeFi, and NFTs , 2023.\n\n[5] Z. Liu, Y. Xiang, J. Shi, P. Gao, H. Wang, X. Xiao, B. Wen, Q. Li, and Y.-C. Hu, \u201cMake web3. 0 connected,\u201d IEEE transactions on dependable and secure computing , vol. 19, no. 5, pp. 2965\u20132981, 2021.\n\n[6] P. Dutta, T.-M. Choi, S. Somani, and R. Butala, \u201cBlockchain technology in supply chain operations: Applications, challenges and research opportunities,\u201d Transportation research part e: Logistics and transportation review , vol. 142, p. 102067, 2020.\n\n[7] (2022) Friends with benefits. https://www.fwb.help/events. [8] M. C. Ballandies, \u201cTo incentivize or not: Impact of blockchain- based cryptoeconomic tokens on human information sharing behavior,\u201d IEEEAccess , vol. 10, pp. 74 111\u201374 130, 2022.\n\n[9] L. Oliveira, L. Zavolokina, I. Bauer, and G. Schwabe, \u201cTo token or not to token: Tools for understanding blockchain tokens.\u201d ICIS, 2018.\n\n[10] M. Ottina, P. J. Steffensen, and J. Kristensen, \u201cBalancer,\u201d in Automated Market Makers: APractical Guide to Decentralized Exchanges and Cryptocurrency Trading . Springer, 2023, pp. 69\u2013116.\n\n[11] H. Adams, N. Zinsmeister, and D. Robinson, \u201cUniswap v2 core,\u201d 2020.\n\n[12] G. Angeris, H.-T. Kao, R. Chiang, C. Noyes, and T. Chitra, \u201cAn analysis of uniswap markets,\u201d arXiv preprint arXiv:1911.03380 , 2019.\n\n[13] L. Liu, S. Zhou, H. Huang, and Z. Zheng, \u201cFrom technology to society: An overview of blockchain-based dao,\u201d IEEEOpen Journal of the Computer Society , vol. 2, pp. 204\u2013215, 2021.\n\n[14] P. Z\u00a8ust, \u201cAnalyzing and preventing sandwich attacks in ethereum,\u201d 2021.\n\n[15] A. J. Morales, S. Somin, Y. Altshuler, and A. Pentland, \u201cUser behavior and token adoption on erc20,\u201d arXiv preprint arXiv:2005.12218 , 2020.\n\n[16] S. Loesch, N. Hindman, M. B. Richardson, and N. Welch, \u201cIm- permanent loss in uniswap v3,\u201d arXiv preprint arXiv:2111.09192 , 2021.\n\n[17] Z. Zheng, S. Xie, H.-N. Dai, W. Chen, X. Chen, J. Weng, and M. Imran, \u201cAn overview on smart contracts: Challenges, advances and platforms,\u201d Future Generation Computer Systems , vol. 105, pp. 475\u2013491, 2020.\n\n[18] H. Adams, N. Zinsmeister, M. Salem, R. Keefer, and D. Robin- son, \u201cUniswap v3 core,\u201d Tech. rep., Uniswap, Tech. Rep. , 2021."
    },
    {
        "number": 1570887007,
        "title": "Price Arbitrage for DeFi Derivatives",
        "abstract": "We address the under-documented area of derivative trading in Decentralized Crypto Exchanges (DEXs). We focus on explaining the price arbitrage implementation in the decentralized exchange Mycelium, which uses Chainlink and its own oracles. The price information for the Mycelium oracle is derived from a three-way median system of Centralized Exchanges (CEXs) such as Binance, FTX, and Bitfinex, to guard against local fluctuations. Additionally, we provide an analysis of historic prices during high and low volatility trading days, introduce the concept of magnitude, and discuss the potential drawbacks of the current pricing protocols.",
        "review": {
            "strength": [
                "1. This paper explains about DeFi derivative trading\n2. The prices of some crypto assets in some CEXs and Mycelium are well analyzed",
                "The paper addresses an under-documented area of the literature on derivatives trading in decentralised crypto exchanges (DEXs), which is particularly relevant due to rise in DeFi. The paper provides a good background to the problem and presents a simple but interesting method. The results highlight the significant impact on the stability and resilience of DEXs during large market events.",
                "The work-in-progress analyzes the stability and resilience of Decentralized Exchanges (DEXs) during market events, finding that a three-way median system can protect against local fluctuations but low update rates can result in vulnerabilities."
            ],
            "shortcoming": [
                "1. There are no labels for paragraphs\n2. There is no related work",
                "The paper only contains 3 references, which are cited in the conclusion. There appears to be a lack of relevant references to topics such as price arbitrage and DEXs/DeFi.",
                "- The authors should add more data for the analysis. The authors only analyzed two dates."
            ],
            "comment": [
                "1. The reason for choosing Mycelium is not clear\n2. Why BTC and ETH is not considered for price analysis?\n3. Add labels for paragraphs following IEEE format",
                "There are a number of small errors that seem to have come in when compiling the pdf - e.g. Page 2, first sentence of the last paragraph, the inverted question mark should be an inequality sign. These should be corrected to help the reader to understand the results in addition to the plots.",
                "I found the work quite interesting although, the authors should add more data for the analysis. The authors only analyzed two dates."
            ],
            "score": {
                "Relevance": 3.0,
                "Content and originality": 3.0,
                "Reference": 2.0,
                "Overall recommendation": 3.3,
                "Poster acceptance": 4.0
            }
        },
        "body": "I. INTRODUCTION While trading derivatives on the traditional stock market is commonplace these days, it is still a new trend in Decentrilized Finance (DeFi). Finan- cial derivatives are securities with prices that are dependent upon or derived from one or more un- derlying assets. Crypto assets are intangible digital assets whose issuance, sale or transfer are secured by cryptographic technology and shared electronically via a distributed ledger. In this study, we analyze a well-known platform for trading derivative products such as Decentral- ized Crypto Exchange (DEX) Mycelium (mycelium. xyz) together with Chainlink (chain.link) oracle and Centralized Crypto Exchanges (CEXs), namely Bi- nance , Bitfinex and former FTX . DEX operates on a blockchain network, allowing users to trade directly from their wallets without the need for a third party to hold their funds. DEXs offer greater control and privacy, as users are in control of their own private keys and the trades are executed on a decentralized network. However, DEXs typically have less liquidity and a slower trading experience than CEXs. CEX is a traditional type of exchange where a third party holds the user\u2019s funds in custody and is responsible for matching orders and executing trades. We present a comparison of the performance of crypto exchange platforms based on the five most popular assets at two different dates, November, 1 2022 with regular and November 8 2022 with intense volatility. The latter date corresponds to the crash of\n\nFTX exchange 1 . Our objective is to bring to light the potential flaws in the implementation protocols for DeFi derivatives tradings that combine the lack of regulation with the lack of guarantees by a central- ized body. In the next section, we provide a brief overview of the current status of decentralized derivatives trading. In Section III, we present the data set we collected and our findings. We raise open questions for future research in Section IV.\n\nII. DE FI DERIVATIVES\n\n1) DeFi derivative trading: Derivatives in tradi- tional finance refer to agreements between multiple parties that derive their value from the performance of an underlying item such as an asset, commodity, index, interest rate, or even another derivative. These contracts were originally created to ensure balanced exchange rates for internationally traded goods. When holding a long position, an increase in the instrument\u2019s price results in profits, while a short position profits from a decrease. Two common crypto derivatives are perpetual futures and swaps, which are cryptocurrency- based derivatives traded on exchanges. These resemble traditional futures contracts but lack an expiration, allowing for indefinite holding. With high leverage, traders have the potential to earn significant profits with small investments. Perpetual futures and swaps are generally traded against the underlying cryptocur- rency\u2019s spot price and settled in the cryptocurrency itself. They can be utilized for both speculating on the asset\u2019s price or protecting against price fluctuations. In DeFi world there are already a number of platforms facilitating derivative trading with GMX (gmx.io) and Mycelium among the most popular ones. Unfortunately, despite its popularity, DeFi trading is not well documented. To gain an understanding of how crypto-derivative trading operates, a thorough research was conducted through the analysis of code, transactions, and even hands-on testing with personal assets. The following section provides an example of a DeFi trading platform, Mycelium . 2) DeFi trading platform example: Mycelium uti- lizes a shared asset pool managed by the Mycelium Perpetual Swaps protocol 2 , allowing users to trade on leveraged long or short positions in crypto assets.\n\n1 en.wikipedia.org/wiki/Bankruptcy of FTX 2 swaps.docs.mycelium.xyz 979-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\n2\n\nUsers can access the decentralized application ( dApp ) through a web interface to open a position. When go- ing short, the trader borrows the token they are betting on and sells it immediately, and then buys it back and returns it when the position is closed. If the price has decreased, the trader wins, otherwise it\u2019s considered a loss. The trader sets the margin when opening the position, and the protocol continually assesses whether the margin is adequate to cover potential losses in case the position is closed. If a price change results in a margin call, the protocol automatically closes the position, known as liquidation. The source of the price, the trader works with, is determined by oracles . Oracles are exter- nal applications that gather information on values and real-world events, then transmit this data to the blockchain through transactions. Mycelium partially relies on Chainlink , which offers the advantage of decentralization. However, relying on Chainlink is not without drawbacks. Mycelium operates on Arbitrum (arbitrum.io), a fairly fast blockchain with a block time of around one second, whereas Chainlink \u2019s oracle is not fast enough to deliver accurate enough results for the protocol to function effectively. The accuracy of the Chainlink oracle utilized by Mycelium is only 2.5%, meaning that the price change would not be reported to the blockchain until it reaches at least 2.5%. This could be significant for a large position. Mycelium addressed this issue by creating their own oracle with higher accuracy and faster price updates. However, relying solely on a single company\u2019s oracle can raise trust concerns. To mitigate this, they use both Mycelium for quick price updates and Chainlink as a backup. The protocol compares the data from both oracles and in case of a discrepancy, it adds an extra 2.5% safety spread and prioritizes the data from Chainlink . This approach reduces the dependence on the protocol owner. We found out that Mycelium ob- tains its price information from centralized exchanges like Binance , FTX , and Bitfinex . The Mycelium oracle tracks the prices on these exchanges and calculates the median, which is then published on the blockchain for the protocol to use. 3) Mycelium approach vulnerability: The reliance on centralized exchanges for price information leaves the system open to vulnerability. There can be a lag before the oracle publishes the price change on the blockchain. This delay could potentially be exploited by fast-acting robotic traders who can quickly open a position on Arbitrum if the delay exceeds one second (the block time of Arbitrum ). For example, if the robot detects a price drop, it may quickly open a short position with high leverage. However, when the information reaches the protocol, it can close the position with a guaranteed profit. To prevent such scenarios, the protocol developers have implemented a three-way median system, so that any local fluctuations on one exchange will not impact the resulting price. The Mycelium oracle is designed to quickly display such changes.\n\nWhen a trader takes a short position by borrowing a token, selling it and then buying it back at a later time to return it, the profit or loss is determined by comparing the sale price ( p 0 at time t 0 ) with the purchase price ( p 1 at time t 1 ). If the price has dropped, the trader profits ( p 0 \u2212 p 1 ), otherwise they suffer a loss. While opening the position the trader sets a margin, which the protocol continuously checks to ensure it is enough to cover potential losses in case the position is closed. In case the market value of the collateral falls below the required margin, a \u201cmargin call\u201d is issued, leading the Mycelium Perpetual Swaps protocol to automatically close the position, known as liquidation. In the subsequent section, we present our data set which includes the prices of five widely used and valuable crypto assets during periods of high and low volatility. We share our data set in [1].\n\nIII. DATA SETThe price recording process took place over the course of nearly 2 weeks in November 2022. We obtained prices every 0.77 seconds from centralized exchanges ( FTX , Bitfinex , and Binance ), and twice a second from the oracles to ensure compliance with their rate limits. We utilized the official APIs from the centralized exchanges as our data source. For Chainlink and Mycelium , we utilized the contracts provided by their official sources on Arbitrum . 1) Crypto Assets: To evaluate the volatility of popular and valuable crypto assets, we compare the prices of the following: Frax Share FXS is used for governance, minting, staking, and redeeming the FRAX stablecoin (frax.finance); Chainlink LINK en- ables non-blockchain enterprises to securely connect with blockchain platforms and external data; Bal- ancer BAL provides a protocol for creating or adding liquidity to trading pools and earning trading fees (balancer.fi); Curve CRV is a decentralized exchange and automated market maker protocol, designed to make it easy to swap between Ethereum ERC-20 and Ethereum-based Bitcoin tokens (curve.fi); Uniswap UNI is an automated liquidity provider that makes exchanging Ethereum tokens easy (uniswap.org). In this study, we analyze the prices of these as- sets for two Tuesdays with varying volatility levels, November 1st and 8th, 2022. The price ranges are listed in Table I and plotted in Figure 2. We note that the FXS data for Bitfinex is not available. To assess the correlation between different assets, we calculate the Pearson Correlation Coefficient for pairs of prices for each hour as in [2]. Table II displays the coefficients for November 1st on Chainlink . On this day, LINK , FXS and BAL exhibit a high degree of correlation. Similar values can be obtained for Mycelium (not shown here) on the same day. On November 8th, however, all coins exhibit a high degree of correlation with each other, around 0 . 98 . 2) Magnitudes comparison: Let p bnc t , p ftx t and p bfx t to be price at Binance , FTX and Bitfinex , correspond- ingly. We would call as a magnitude at time t , the\n\n3\n\nsource symbol min 11/1 max 11/1 std 11/1 min 11/8 max 11/8 std 11/8\n\nmycellium FXS/USDT 6.543 6.902 0.1 5.379 6.713 0.37\n\nmycellium LINK/USDT 7.631 7.921 0.072 6.584 9.468 0.547\n\nmycellium CRV/USDT 0.876 0.903 0.005 0.691 1.019 0.073\n\nmycellium BAL/USDT 6.623 6.914 0.076 5.123 6.926 0.378\n\nmycellium UNI/USDT 6.911 7.455 0.11 5.446 7.089 0.302\n\nchainlink FXS/USDT 6.548 6.867 0.1 5.473 6.7038 0.362\n\nchainlink LINK/USDT 7.637 7.911 0.071 6.773 9.4333 0.542\n\nchainlink CRV/USDT 0.882 0.899 0.005 0.724 1.0101 0.073\n\nchainlink BAL/USDT 6.641 6.9 0.078 5.239 6.9 0.374\n\nchainlink UNI/USDT 6.914 7.44 0.111 5.472 7.0843 0.3\n\nftx FXS/USDT 6.54 6.905 0.102 5.32 6.71 0.392\n\nftx LINK/USDT 7.628 7.926 0.073 6.556 9.4765 0.579\n\nftx CRV/USDT 0.877 0.904 0.005 0.692 1.0198 0.074\n\nftx BAL/USDT 6.625 6.925 0.077 5.135 6.94 0.384\n\nftx UNI/USDT 6.91 7.458 0.112 5.414 7.09 0.325\n\nbitfinex LINK/USDT 7.633 7.721 0.036 6.585 8.0581 0.55\n\nbitfinex CRV/USDT 0.876 0.878 0.001 0.696 0.9324 0.08\n\nbitfinex BAL/USDT 6.624 6.706 0.032 5.002 6.5883 0.51\n\nbitfinex UNI/USDT 6.703 6.927 0.051 5.432 6.8813 0.441\n\nbinance FXS/USDT 6.541 6.927 0.1 5.34 6.729 0.363\n\nbinance LINK/USDT 7.63 7.923 0.071 6.602 9.466 0.576\n\nbinance CRV/USDT 0.877 0.904 0.005 0.687 1.019 0.074\n\nbinance BAL/USDT 6.62 6.913 0.076 5.105 6.921 0.384\n\nbinance UNI/USDT 6.91 7.46 0.11 5.45 7.1 0.321\n\nTable I: Min, max and std prices for selected symbols and sources for November, 1 and 8 2022.\n\nSymbol BALUNI LINKFXS\n\nCRV 0.54 0.02 0.46 0.21\n\nBAL - -0.63 0.91 0.86\n\nUNI - - -0.39 -0.52\n\nLINK - - - 0.92\n\nTable II: Correlation Coefficients between pairs of crypto assect (Nov 1, on Chainlink).\n\npercentage difference between the price of an asset on some oracle p t ( Chainlink or Mycelium ) and the median price from the centralized exchanges:\n\nm t = p t \u2212 median ( p bnc t , p ftx t , p bfx t )\n\nmedian ( p bnc t , p ftx t , p bfx t ) \u00b7 100% .\n\nIn Table III we report the highest magnitudes for both days. We observe that Mycelium is more stable in comparison to Chainlink . In Figure 1 we plot distribution of the magnitudes for the selected accets.\n\nSymbol Mycelium Chainlink\n\nCRV/USDT 0.28 / 5.7 0.6 / 10.62\n\nBAL/USDT 0.29 / 4.5 0.67 / 5.33\n\nUNI/USDT 0.51 / 4.74 0.51 / 4.67\n\nLINK/USDT 0.16 / 8.05 0.41 / 7.72\n\nTable III: The highest magnitudes for Mycelium and Chainlink from our dataset (Nov1/ Nov8).\n\nMycelium \u2019s high magnitude periods ( m t > 2 . 5% ) occur only during high volatility on November 8th. We compare the time difference between consecutive periods for all crypto assets and find that on average, they update every 0.32 seconds, with the maximum update interval ranging from 0.76 seconds on Novem- ber 1st to 1.20 seconds on November 8th. When we only consider high magnitude periods, the maximum time difference is still below 1 second (0.4 seconds). Thus, there are no opportunities to use Mycelium for long-term gains.\n\nIV. RELATED ANDFUTURE WORKIn this work-in-progress, we have analyzed the stability and resilience of Decentralized Exchanges\n\nduring dramatic market events using Mycelium and FTX market crash as a case study. Our initial analysis indicates that using a three-way median system can protect against local fluctuations in one Centralized Exchange. However, the vulnerability of this approach is that if one of the sources becomes unavailable (due to low update rates of prices, for instance), the average will be used instead. This could create an arbitrage op- portunity during periods of high volatility on one of the exchanges, as long as it does not exceed the Chainlink cutoff. As a result, the protocol may experience losses. This scenario 3 occurred in January 2023. In [3] authors found evidences of frequent and significant arbitrage opportunities across exchanges, and these price deviations are more pronounced across countries than within them. It would be valuable to conduct a similar analysis for Decentralized Exchanges in other regions. In future work, we aim to study the performance of various forecasting models during crypto market crashes, e.g. using ANIMA or Deep Learning for price prediction [2], [4], [5]. We make our data set accessible through [1] to encourage further exploration.\n\nREFERENCES\n\n[1] I. Vakhmyanin and Y. Volkovich, \u201cCrypto price monitoring dataset for on-chain derivatives research,\u201d 2023. [Online]. Available: https://doi.org/10.5281/zenodo.7749159\n\n[2] Z. Zhang, H.-N. Dai, J. Zhou, S. K. Mondal, M. M. Garc\u00b4\u0131a, and H. Wang, \u201cForecasting cryptocurrency price using convolutional neural networks with weighted and attentive memory channels,\u201d Expert Systems with Applications , vol. 183, 2021.\n\n[3] I. Makarov and A. Schoar, \u201cTrading and arbitrage in cryptocur- rency markets,\u201d Journal of Financial Economics , vol. 135, no. 2, 2020.\n\n[4] J. Rebane, \u201cSeq2seq RNNs and ARIMA models for cryptocur- rency prediction : A comparative study,\u201d 2018.\n\n[5] A. Azari, \u201cBitcoin price prediction: An ARIMA approach,\u201d arXiv: 1904.05315 , 2019.\n\n3 mycelium.xyz/blog/post-mortem-of-recent-mlp-impact.\n\n4\n\n(a) Magnitudes (Nov1)\n\n(b) Magnitudes (Nov8)\n\nFigure 1: Magnitudes distributions for crypto assets on Mycelium (starting 3pm each day).\n\n(a) CRV prices vs median (Nov1)\n\n(b) CRV prices vs median (Nov8)\n\n(c) BAL prices vs median (Nov1)\n\n(d) BAL prices vs median (Nov8)\n\n(e) UNI prices vs median (Nov1)\n\n(f) UNI prices vs median (Nov8)\n\n(g) LINK prices vs median (Nov1)\n\n(h) LINK prices vs median (Nov8)\n\nFigure 2: Crypto assets prices from CEXs, DEX and Chainlink oracle (starting 3pm each day)."
    },
    {
        "number": 1570887112,
        "title": "Rational Ponzi Games in Algorithmic Stablecoin",
        "abstract": "Algorithmic stablecoins (AS) are one special type of stablecoins that are not backed by any asset. They stand to revolutionize the way a sovereign fiat operates. As implemented, these coins are poorly stabilized in most cases, easily deviating from the price target or even falling into a catastrophic collapse, and are as a result dismissed as a Ponzi scheme. However, is this the whole picture? In this paper, we try to reveal the truth and clarify such a deceptive concept. We find that Ponzi is basically a financial protocol that pays existing investors with funds collected from new ones. Running a Ponzi, however, does not necessarily imply that any participant is in any sense losing out, as long as the game can be perpetually rolled over. Economists call such realization as a rational Ponzi game. We thereby propose a rational model in the context of AS and draw its holding conditions. We apply the model to examine: whether or not the algorithmic stablecoin is a rational Ponzi game. Accordingly, we discuss two types of algorithmic stablecoins (Rebase & Seigniorage shares) and dig into the historical market performance of a number of impactful projects to demonstrate the effectiveness of our model.",
        "review": {
            "strength": [
                "- The entire work is clearly explained in the manuscript.\n- Categories of stablecoins and the definition of Rational Ponzi Game is clear",
                "Comprehensive analyses of the effects of investors\u2019 utilities on price target stability that reflects the Ponzi game.",
                "The paper discusses algorithmic stablecoins, a type of stablecoin that is not backed by any asset, and their potential to revolutionize fiat currency. While they have been dismissed as a Ponzi scheme due to poor stabilization and catastrophic collapses, the paper proposes a rational model for algorithmic stablecoins and examines whether they are a rational Ponzi game. The paper discusses two types of algorithmic stablecoins and analyzes the historical market performance of various projects to demonstrate the effectiveness of the proposed model.\n\nThe study applies the rational Ponzi game model to algorithmic stablecoins and evaluates three mainstream projects (Ampleforth, TerraUSD, and Basis Cash) as instances. The study finds that the rebase approach has the potential to realize a rational Ponzi game as long as it exists in an active trading market, while the seigniorage share method is difficult to guarantee a rational Ponzi. The study also identifies current hurdles and potential opportunities for future endeavors in algorithmic stablecoin implementations.",
                "The author of this paper conducted a comprehensive analysis of the implementation of a rational Ponzi game from various perspectives. The related work analysis is also well-structured, and the proposed model is effectively presented through comparisons with several existing AS projects. Overall, the paper is well-organized and provides a valuable contribution."
            ],
            "shortcoming": [
                "There are some typos and a wrong image for Fig. 4.",
                "Formatting, grammatical and typographical errors, and figure references. These need to be fixed accordingly.",
                "- There is a typo on page 5 right column\n- The stablecoins need to be pegged. Because by definition, it is a token representing another asset (USD in most cases).\n- It analysis needs to be run on more coins",
                "The analysis of the proposed model in this paper is somewhat insufficient. To enhance the understanding of the model proposed in this paper."
            ],
            "comment": [
                "- In the \u201cContributions\u201d paragraph, the manuscript says this work evaluate two mainstream projects, not three. (BAC is missing)\n- In the \u201cRational Ponzi Game\u201d paragraph, a superscript 2 makes readers confusing. It looks like a square of t.\n- Fig. 4 is a graph of UST, not BAC\n- There is no future work",
                "The paper presents a study on different algorithmic stablecoins (AS) implementations that are commonly being dismissed as a Ponzi scheme, due to their instability and volatility of the target price, which may lead to such catastrophic collapse. \n\nThe authors evaluate the implementations of three different decentralized algorithmic stablecoins, namely TerraUSD, Ampleforth, and Basis Cash. The Ponzi game approach is adopted as the measurement tool to indicate the effectiveness of three aforementioned schemes. Form the analyses carried out on investors\u2019 utilities perspective, the study indicates that the rebase approach has the potential to realize a rational Ponzi game as long as it always exists in an active trading market.\n\nThe paper provides an interesting study on how the investors\u2019 utility helps in stabilizing the price of algorithmic stablecoins in the trading market. \nThe contents of the paper is suitable for publication in this workshop. However, there are a number of significant changes need to be made, including:\n1. To revise the paper accordingly, to check for any typographical and grammatical errors.\n2. To check table and figures\u2019 references and citations. Figure 3 was not referred and mistakenly referred as Figure 4. \n3. It is best to provide further discussions on the investors\u2019 utilities implication on the stablecoin stability. Perhaps a simulation works may help.",
                "Great work. I learned something from your paper. \n\nSuggestions\n- The paper should address more AS coins\n- You should not have any typos in the paper\n- Try to be more focused on the topic/title of the paper",
                "It would be helpful to present its strengths and limitations and summarize any follow-up studies that have been conducted."
            ],
            "score": {
                "Relevance": 3.0,
                "Content and originality": 3.0,
                "Reference": 3.3,
                "Overall recommendation": 3.5,
                "Poster acceptance": 3.3
            }
        },
        "body": "I. INTRODUCTION\n\nPonzi is making a comeback that is used to describe the hyped algorithmic stablecoins today. The most recent critique was directed at the one called TerraUSD (UST), which crashed by almost 98% within 24 hours on May 12 th , 2022 (cf. [ 1 ]), impacting a direct of $85B market value evaporation and the collapse of entire crypto markets. This worst-hit reveals a new type of bank run and has triggered repetitive rounds of criticism and discussion about the stablecoin and its algorithmic stabilized approaches. Stablecoins are created to inherit all great features that cryptocurrencies hold (e.g., decentralization, automation, cross-border), without, however, suffering from the same volatility, making them much more applicable as a store of value, medium of exchange, and unit of account [ 2 ]\u2013[ 4 ]. In an ideal form, stablecoins are simply cryptocurrencies with stable value. Current stablecoin implementations (Tab. I ) aim to bridge external assets with the cryptocurrency space by anchoring a peg (e.g., USD) in price. Stablecoins are generally tagged as either collateralized or algorithmic stablecoins based on whether they are backed by collateral or not. The collateralized stablecoin, as the name indicates, requires collateral and thus ensures the circulating token has a redemption value. Major collateral options include fiat money, cryptocurrency, and other valuable assets. Cur- rently, stablecoins are primarily backed by fiat money (Tab. I ). USDC [ 5 ], for example, is a fully collateralized stablecoin pegged to USD. The USDC issuer claims that they store an\n\nequivalent amount of US dollars of the supply of USDC in a list of banks. It is reasonable to argue that stablecoins backed by fiat money are of a high degree of centralization in essence. Using cryptocurrency as collateral can instead circumvent this problem. However, considering its high volatility, an over - collateralization is often required if relying on cryptocurrency as collateral. One representative in this category is stablecoin DAI [ 6 ], where a user needs to deposit Ether (the native token of Ethereum blockchain) in excess of the amount of created DAIs. This way, even if the underlying crypto depreciates, each unit of the stablecoin still has enough space to be redeemed for at least the same value of its peg.\n\nAlgorithmic stablecoin, however, does NOT require any col- lateral. Its money supply is elastic and managed by algorithms (i.e., coded in smart contracts), and thus not limited in scale. As for stabilization, the par value of an algorithmic stablecoin is basically preserved by expanding supply when the price is too high and contracting supply when the price is too low. There are two major designs in algorithmic stablecoins [ 7 ], namely, Rebase and Seigniorage Shares . Rebase [ 8 ] is an algo- rithm that automatically adjusts the money supply in response to the market demand on a routine basis. A rebase protocol can add ( mint ) or remove ( burn ) coins from circulation according to the stablecoin\u2019s price deviation from the peg, and this is usually achieved by managing token balance pro rata across all wallets. Instead of rebasing one coin, seigniorage shares [ 9 ] normally has a dual (or multiple ) coin design: the price- stable coins and flexible investment shares. The shares can algorithmically adjust the supply of price-stable coins much like a central bank does with fiat currencies. Seigniorage shares model has, to varying degrees, served as a foundation for TerraUSD [ 10 ], Basis Cash [ 11 ], and Frax [ 12 ].\n\nTABLEI: An Overview of Stablecoins (Ranked by Mrk Cap)\n\nName Token Centralised Supply Peg Mrk Cap\n\nTether USDTCentralised Collateral USD $157.4BUSD Coin USDCCentralised Collateral USD $68.5BBinanceUSDBUSD Centralised Collateral USD $21.5BDai DAIDecentralised Collateral USD $6.2BFrax FRAXDecentralised Fractional Alg. USD $1.4B\n\nTerraUSDUST-LUNADecentralised Alg. (S.Share) USD $471.1MOlympus - Decentralised Collateral - $303.4MFei USDFEI Decentralised Collateral B.C. USD $57.2M\n\nAmpleforth AMPLDecentralised Alg. (Rebase) CPIUSD $45.6MEmpty Set ESDDecentralised Alg. (S.Share) USD $370.5K\n\nBasis Cash BAC-BAB-BASDecentralised Alg. (S.Share) USD $281.7K\n\nData: Fetched on 12 th Dec 2022. Abbreviation: Alg. = Algorithmic; Mrk = Market; S.Share = Seigniorage Shares; B.C. = Bonding Curve 1 . 978-8-3503-1019-1/23/$31.00 \u00a92023 IEEE\n\nContributions. However, there is no satisfactory algorithmic stablecoin that has been healthily operated as of now. Non- collateral property and non-stable performance undermine people\u2019s already fragile trust, and algorithmic stablecoins are thus often questioned as Ponzi schemes. This motivates our ob- servations towards this fancy but fuzzy concept of Ponzi. First, we review existing in-the-wild algorithmic stablecoin projects and explore the design primitives they share in common (Sec. I ). We then accordingly establish a rational Ponzi model in the context of algorithmic stablecoins (Sec. II ) and evaluate three representative projects, namely, Ampleforth (rebase), TerraUSD (seigniorage share), and Basis Cash (seigniorage share), based on six-month historical data from Mar 1 st to Oct 17 th 2022 (Sec. III ). We also find several interesting insights (Sec. IV ) that are driven by our model. At last, we deliver two taking-home messages saying:\n\n\u22c4 It is more likely to run a rational Ponzi game in decentral- ized finance (DeFi) protocols than in traditional finance. In traditional finance, default (a failure to make repay- ments on a debt) is an intrinsically intractable problem as human being\u2019s financial behavior is non-controllable. DeFi, however, empowered by the automatically operated smart contracts, can run functions such as enforceable payment to ensure a Ponzi-style debt to roll over.\n\n\u22c4 Algorithmic stablecoin has a chance to achieve the defined rational Ponzi model under certain conditions. Based on our investigations, the rebase approach is rel- atively easy to implement as a rational Ponzi game as long as there always exists an active trading market for the token always exitsts. Whereas the seigniorage share method is of low probability to realize so. This is due to its inability to cope with the joint fall effect caused by the multi-coin design when a death spiral is triggered. Recent Studies. A series of papers and reports [ 4 ], [ 13 ]\u2013[ 15 ] establish and extend the taxonomies in stablecoins based on the peg type, the collateral type, and the collateral amount. They give an initial sight to demystify its assemblies and components. Besides, with in-depth analysis, a number of follow-up works has been proposed. Moin et al. [ 2 ] provide a systematical classification of existing stablecoins in terms of their design elements. Ariah et al. [ 3 ] investigate the economic structure of stablecoins and establish a risk-based functional characterization. Pernice et al. [ 16 ] research stablecoins from a monetary perspective. Salehi et al. [ 17 ] explore the liquidation process in stablecoins, and put forward a research agenda for alternatives to liquidation. Clements R. [ 18 ] studies the inherent fragility in algorithmic stablecoins and claims that they are built to fail. Zhao et al. [ 7 ] conduct an empirical analysis to explain the volatility of algorithmic stablecoins.\n\nII. MODELING RATIONAL PONZI GAME Ponzi [ 19 ] has always been such a term that is instinc- tively resented by the public. For malicious organizers, Ponzi\n\n1 A bonding curve is a mathematical concept used to describe the relation- ship between the supply of a token and its price. In its simplest form, the more token that has been issued, the higher the token price is.\n\nschemes are used to lure new investors, and leverage incoming money to pay earlier ones while keeping the rest as profit. In general, Ponzi organizers normally will promise an abnormally high return to investors within the short term. With little or no legitimate earnings, Ponzi games require a constant cash flow of new funds to survive. Once becoming difficult to recruit new participants, or whenever a large number of existing investors cash out, the game would tend to collapse. However, stemming from its origin, the substance of Ponzi is neutral yet subtle. Economists [ 20 ], [ 21 ] discuss a perfect foresight version of the Ponzi model, where games based on irrational lenders or imperfect information are ruled out. They call one possibility, in which all debts can be forever rolled over , i.e., financed by issuing new debt, a rational Ponzi game [ 22 ]. Following such narrative connotations, we develop a rational Ponzi model in the context of algorithmic stablecoins.\n\nRational Ponzi Game. An entity that plans to issue debt and roll it over the possibly infinite future is the borrowing side of a rational Ponzi game. Any plan will impose a set of net cash inflows I s from the lending side. The present value of borrower\u2019s net indebtedness DT of at any time T equals the present value of the stream of prospective incomes generated by lenders between 0 and T :\n\n\u0393( T ) DT =\n\nTX\n\ns =1 \u0393( s ) I s (1)\n\nwhere \u0393( T ) is the discount factor 2 of the borrowing side, it is calculated by the interest rate r t between periods t \u2212 1 and t , and \u0393( s ) is the discount factor applicable in period 0 to cash inflows received in the period s , where \u0393( s ) \u2261 Q s j =1 (1 + r j ) \u2212 1 . We now provide the definition of the ratio- nal Ponzi game.\n\nDefinition 1 (Rational Ponzi Game) . A rational Ponzi game is a sequence of debt transactions satisfying the following sense:\n\n(i) to the borrower, it is a positive net present indebtedness value such that lim T \u2192\u221e \u0393( T ) DT > 0 , if the limit of \u0393( T ) DT exists;\n\n(ii) to all the participants, i.e., both the borrowing and lending sides, the game enables a Pareto improvement 3 .\n\nThe first holding condition in Definition 1 implies that debts are unnecessarily fully paid off by future cash inflows if in an infinite horizon setting. The second condition imposes restrictions that no one is being worse (debt can always be redeemed at least equal to the market value of assets being deposited). Therefore, the two conditions guarantee a rational realization. We provide a general operation process of the rational Ponzi model as in Fig. 1 . The red plus sign and the green minus sign represent cash inflow and cash outflow,\n\n2 In corporate finance, a discount factor is a number that is derived from the discount rate. It is used to discount future cash flows back to their present value at a specific discount rate. Here, we assume r t are identical for all assets under a perfect foresight setting. 3 APareto improvement is an improvement to a given situation, where a change in allocation of goods harms no one and benefits at least one individual.\n\n2\n\nrespectively. The blue values in parentheses following each participant represent their corresponding utility.\n\ndebt\n\n+ \u2212 + \u2212 + \u2212\n\nentity\n\n/ protocol ( + )\n\n1st lender\n\n/ buyer ( 0 )\n\n2nd lender / buyer ( 0 )\n\n3rd lender / buyer ( 0 )\n\n+ \u2212 +\n\ninfinity ( 0 )\n\nFig. 1: How a rational Ponzi game works.\n\nScope of application. One may consider that only govern- ments are entitled to run such rational Ponzi games. However, in a world where rational Ponzi games can exist, any infinitely lived entity can issue debt and perpetually roll it over. In principle, even a finitely lived entity can issue bonds with zero coupons, i.e., fiat currency. All required is to make participants believe that there will always exist followers being willing to purchase the debt. At the same time, economists have also proven that the introduction of perpetually rolled-over debt will never make the lending market worse off relative to an economy in which no Ponzi game runs [ 22 ]\u2013[ 24 ].\n\nIII. APPLIED TOA LGORITHMICS TABLECOIN\n\nTypically, algorithmic stablecoins, based on their operating mechanisms, can be considered a Ponzi game: an on-chain protocol launches a coin (equiv. debt) claimed to be stable (investors can always get the equivalent fund back when selling the coin), and one joins the game by purchasing the coin and can quit the game if others are willing to buy his coins on the market. However, is such an algorithmic stablecoin game can being rational under our model? In this section, we investigate three representative instances, Ampleforth (rebase), TerraUSD (seigniorage shares), and Basis Cash (seigniorage shares), to answer this question. Supposing that all the lending protocols are deployed on smart contracts on a public ledger so that all steps are perfectly enforceable (equiv. no default risk). We define the notation U as the investor\u2019s utility; it is basically the product of the number of held assets Q and the market price of the token P , in symbols as\n\nU = Q \u00d7 P. (2)\n\nThen, we apply our model to three concrete instances by investigating their six-month historical data (Mar \u2013 Oct, 2022). We analyze the utility of investors based on extracted data covering price, quantity, and market cap. Ampleforth (Rebase). Rebasing is a process applied by several algorithmic stablecoins to maintain their peg to a certain value, such as the US dollar. When a stablecoin rebases, it adjusts the supply of tokens in circulation in response to changes in the value of the underlying asset or assets. It\u2019s important to note that rebasing can be a complex process, and different algorithmic stablecoins may use different algorithms to determine when and how to rebase. Ampleforth (AMPL) [ 25 ] is one representative protocol that applies the design of rebase. AMPL is pegged to the CPI-adjusted USD, and\n\nits rebase procedure occurs at 02:00 UTC on a daily basis. The quantity of AMPL tokens in user accounts automatically expands or contracts based on everyday price. According to Ampleforth whitepaper [ 26 ], the absolute supplyDelta of AMPL is equal to ( price \u2212 target ) \u2217 totalSupply\n\ntarget . For example, at the time of rebase, if the price of AMPL is $1.1, 10% greater than the standard 1 USD peg, a wallet with a balance of 100 AMPL will be rebased as 110 accordingly. In contrast, when the AMPL price is less than 1 USD, the protocol will proportionally decrease the quantity of tokens in wallets, aiming to bring the price up to its anchor. Investor\u2019s utility analysis. Considering an investor who partic- ipates in the Ampleforth game at any time by purchasing one unit of AMPL, we analyze the utility changes over time. At each rebase time (cf. Fig. 2 ), the investor\u2019s utility (green line) stays the same 4 , meaning that the investor can always redeem (trade) the identical value of his investment back. However, the price of AMPL (blue line) is unstable, and the AMPL balance (brown line) 5 is in the investor\u2019s wallet. In terms of a rational Ponzi model, AMPL has the potential to satisfy all listed conditions as long as there exists an lively traded market. Since any investor can retain at least the same utility when participating in the AMPL game, regardless of the token price, one may wonder why the rebase is not being adopted on a larger scale. The most obvious reason is due to its highly volatile price, resulting in holding AMPL being no different than holding a regular cryptocurrency. At the same time, one\u2019s balance varies proportionally to the price every day, making the holder fall into passive and anxious emotions. Besides, AMPL, as an ERC-20 token that works natively on Ethereum blockchain, cannot perform its rebase implementation smoothly in a centralized exchange or other blockchain platforms, significantly restricting its use scenar- ios. Ampleforth mitigates this constraint with the release of Wrapped-AMPL, a token that wraps AMPL similar to wrapped ETH. Wrapped-AMPL facilitates ecosystem integrations on both centralized and decentralized platforms. TerraUSD (Seiniorage Shares). Seniorage Shares is a mon- etary system design that is well-established in traditional finance. The term \u201cseigniorage\u201d refers to the profits that are generated by a central bank through the creation of new money. In the case of \u201cseigniorage\u201d shares stablecoins, this profit is generated by an algorithm that controls the supply of the stablecoin. The seigniorage shares stablecoin model is designed to be self-regulating and can utilize a dual coin system to stabilize the value of one token. The two coins are known as the \u201cshares\u201d and the \u201cprice-stable coin\u201d. The share is designed to have a fluctuating value, much like a typical cryptocurrency. Its value is determined by market demand and supply. The price-stable coin, on the other hand, is pegged to a specific value. The price-stable coin is used to stabilize the\n\n4 Except for the rebase time in a day, the number of AMPL in wallets will not change. If the coin price rises and the investor selects to sell, his or her utility can be even greater than his original investment. 5 To better demonstrate the nature of rebase, we calculate daily AMPL numbers applying a simplest setting based on its 1st version whitepaper [ 26 ].\n\n3\n\n(a) AMPL price\n\n(b) AMPL amounts\n\n(c) Investor\u2019s utility\n\nFig. 2: AMPL status over time.\n\n(a) UST price\n\n(b) UST amounts\n\n(c) Investor\u2019s utility\n\nFig. 3: UST status over time.\n\n(a) BAC price\n\n(b) BAC amounts\n\n(c) Investor\u2019s utility\n\nFig. 4: BAC status over time.\n\nvalue of the shares, and it can be redeemed for the underlying asset at any time. The two coins work together to provide a stable and flexible monetary system. When the value of the shares starts to rise too fast, the price-stable coin is sold on the market, creating more supply and reducing the value of the shares. When the value of the shares starts to fall too fast, the price-stable coin is redeemed for the underlying asset, reducing the supply and increasing the value of the share. This dual coin design is intended to provide the benefits of a cryptocurrency while also providing the stability of a traditional currency. It allows for market-based pricing of the shares while ensuring\n\nthat the overall value of the currency remains relatively stable. TerraUSD (UST) [ 10 ] is a seiniorage shares style stablecoin pegging to the USD on top of Terra\u2019s blockchain. LUNA is the native staking token of the Terra blockchain, and it absorbs the volatility of UST as the token of shares. Aibitrage can help making UST price stable: when the UST\u2019s price is < 1 USD, arbitragers can send 1 UST to the system and receive 1 USD\u2019s worth of LUNA; whereas the UST\u2019s price becomes > 1 USD, arbitragers will send 1 USD\u2019s worth of LUNA to the system and receive 1 UST.\n\nInvestor\u2019s utility analysis. We also consider an investor who\n\n4\n\nparticipates in the UST game at any time by purchasing one unit of UST. For simplicity, we assume that the investor will always hold UST without converting it to LUNA in the mid- run before exiting the game. A chart of UST price (blue line), the number of UST in the wallet (brown line), and the investor\u2019s utility (green line) over time are presented in Fig. 3 . The practice proves the ineffectiveness of UST\u2019s stabilization as the UST eventually collapsed. Investors suffered a signifi- cant loss from their initial investments, making UST unlikely to become a rational Ponzi game. As a matter of fact, current dual-coin designs in the scope of seigniorage shares are practically difficult in realizing a rational model. These stablecoins are not substantially secured by anything, other than the expectation that the price-stable coin will eventually appreciate in value. Hence, a necessary condition for the seigniorage shares to work healthy is that the shares, or the secondary coin, must have some values. LUNA, as the secondary coin, should have, at least, trading values in this case, as people do use Terra blockchain every day. However, in extreme scenarios, investors may still lose confidence in it, and the massive sell-off has accelerated both two types of coins into a death spiral faster.\n\nBasis Cash (Seiniorage Shares). Seiniorage Shares systems in algorithmic stablecoin are not necessarily limited to dual- coin designs. Basis Cash [ 11 ] is also a seigniorage shares style protocol but with three tokens in the system, namely Basis Cash (BAC), Basis Bonds (BAB), and Basis Shares (BAS). The protocol is designed to expand and contract supply similar to the way central banks trade fiscal debt to stabilize purchasing power. Basis Cash (BAC), in this case, serves as the price-stable coin that maintains its peg to the MakerDAOMulti-Collateral Dai token. In the previous examples, issuers either use one coin such as AMPL to rebase the user accounts, or apply a secondary token such as LUNA to absorb the volatility of the price-stable token of UST. In the Basis Cash system, Basis Bonds (BAB) and Basis Shares (BAS) are both non-stable tokens that are designed to help stabilize the value of Basis Cash (BAC) by controlling its supply. BAB are debt securities that can be minted and redeemed to incentivize changes in the BAC supply. Bonds are always on sale to BAC holders. The price of a Basis Bond is determined by market forces and can fluctuate based on demand. When the price of BAC is below its peg, BAB can be purchased for less than the face value. The bondholders can then redeem the bonds for the face value at a later date, earning a profit. BAS are share tokens that loosely represent the value of the Basis Cash network. When the price of BAC is above its peg, new Basis Shares are minted and sold to users, increasing the supply of BAS. Conversely, when the price of BAC is below its target price, existing BAS can be burned, reducing the supply of BAS. This mechanism helps to stabilize the price of BAC over time.\n\nInvestor\u2019s utility analysis. Due to the three-token design in Ba- sis Cash, the complexity of the investor\u2019s possible operations increases dramatically. For simplicity, we also apply the same setup as the previous examples. An investor can participate\n\nin the Basis cash game at any time by purchasing one unit of BAC. We assume that the investor will always hold BAC without converting it to BAB, and will not consider purchasing BAS in the mid-run before exiting the game. Accordingly, a chart of price (blue line), the number of BAC in the wallet (brown line), and the investor\u2019s utility (green line) over time are presented in Fig. 4 . In practice, BAC, BAB, and BAS have all failed to maintain their coin prices and eventually went to almost zero in value. Similar to the collapse of UST, BAC, as a more sophisticated seigniorage shares design, did not achieve a Rational Ponzi model result. One thing worth noting is that BAC and BAS tokens are distributed through yield farming [ 11 ]. Yield farming, also referred to as liquidity mining, is a way to generate additional rewards by depositing your cryptocurrency into a pool. In Basis cash, providing liquidity to BAC-DAI and BAS-DAI pairs result in additional BAS tokens being distributed. This allows the participants in the game, to some extent, to gain tokens (utility) at no cost, and also can act as an incentive mechanism against lack of liquidity and bond death spirals. In general, seigniorage shares designs are without any rebase or collateral risk, and there are theoretically infinite ways to split the volatility of the price-stable coin across multiple tokens. This provides many possibilities to the algorithmic stablecoin practitioners with different expectations and risk preferences to design their customized monetary system. However, seignior- age shares is inherently difficult to maintain the price stability, as the cases of UST and BAC have already demonstrated.\n\nIV. DISCUSSION\n\nWe now provide several additional thinking under the scope of this study in this section.\n\nMarket cap vs price stability. Investors involved in stablecoin markets may often have an intuitive feeling that the larger the market cap of the stablecoin, the better stability the stablecoin can achieve with regard to its peg. However, according to the price and market cap data from CoinGecko [ 1 ], this conjecture may not be valid as imagined for the case algorithmic stable- coins. The statement of ineffective application to the rebase design is explicit, as its market capitalization will vary as the supply of the currency is adjusted. For the seigniorage share design, this statement will be invalid as well. Due to its relative complexity, there are a lot of possibilities resulting in this situation, one of which is the loss of confidence. The recent joint collapse of LUNA/UST was a loop in which the market lost confidence and entered a death spiral, pushing them out of the market cap top-10 within merely several hours. Thus, a larger market cap of an algorithmic stablecoin does not necessarily guarantee a better stability.\n\nPrice oracle risk. Price oracle provides the price feed for on-chain DeFi protocols [ 27 ], and it is crucial to the secure operation of an algorithmic stablecoin. Algorithmic stable- coins may have special price-feeding needs according to their different algorithms, which may require the establishment of customized oracles. Constructing an internal oracle is one\n\n5\n\nway, but this may lead to an additional layer with potential centralization and incentivize the stakeholder to update the price in his favor. Opting for an external price oracle can mitigate this problem, but it is still vulnerable to external price attacks include flash loan price manipulation attack, pump, and dump [ 28 ]. Selecting a trustworthy price oracle is not easy for an algorithmic stablecoin, and a comprehensive ex-ante risk assessment is required.\n\nReconsider the necessity of a peg. Stablecoins are designed to be pegged to some underlying assets, with the USD being a popular choice. Anchoring a benchmark is an effective way to achieve stability in stablecoins. People may thus generally assume a fact that the stablecoin is perfectly fungible for its peg. However, this is not the full truth. Stablecoins can be, in fact, rather considered as their own free-floating assets that closely track the value of a peg. Besides, it is also possible that stablecoins could provide the desired stability without pegging to an asset. In one possible future, once the economy develops surrounding the stablecoin itself, and such stablecoins have also been widely used as a medium of exchange, maintaining a perfect peg becomes unnecessary.\n\nRational Ponzi in DeFi. At a high level, DeFi naturally has an advantage in realizing a rational Ponzi game. In traditional finance, default has always been a tough problem to deal with. Default is a situation in which a borrower is unable to meet their financial obligations to a lender, such as failing to make scheduled loan payments. In other words, default occurs when a borrower cannot pay back their debt as agreed. However, DeFi protocols are built on top of blockchain technology and are designed to be trustless, meaning they do not rely on intermediaries such as banks or other financial institutions to manage transactions. Instead, of leveraging automated smart contracts, DeFi has many advanced and innovative financial tools such as automated market makers (AMM), flash loans, and enforceable payment. This ensures all parties involved in a game adhere to the terms of the agreement and thus provides more possibility to run a rational Ponzi in DeFi successfully.\n\nV. CONCLUSION\n\nThis study applies O\u2019Connell & Zeldes\u2019s model (1988, cf. [ 22 ]) for rational Ponzi games to the context of algorithmic stablecoins. Following its connotation, we establish a rational Ponzi model as the measurement and accordingly evaluate three mainstream algorithmic stablecoin projects (Ampleforth, TerraUSD, and Basis Cash) as instances. Our investor utility analysis indicates that the rebase design has the potential to realize a rational Ponzi game. However, the seigniorage share approach seems hard to do so. It is seldom possible to run a rational Ponzi in seigniorage share styled algorithmic stablecoins, as once entering a death spiral, the selling pressure in the case of a multi-coin design is intrinsically uncontrol- lable. But in general, implementing rational models in DeFi is always easier than in traditional finance. Beyond that, we also point out the hurdles existing in current algorithmic stablecoin implementations and identify directions for future endeavors.\n\nREFERENCES\n\n[1] Coingecko, \u201cCoingecko,\u201d Online; accessed 17-Oct-2022. https://www. coingecko.com/ , 2022.\n\n[2] A. Moin, K. Sekniqi, and E. G. Sirer, \u201cSoK: A classification frame- work for stablecoin designs,\u201d in International Conference on Financial Cryptography and Data Security (FC) . Springer, 2020, pp. 174\u2013197.\n\n[3] A. Klages-Mundt, D. Harz, L. Gudgeon, J.-Y. Liu, and A. Minca, \u201cStablecoins 2.0: Economic foundations and risk-based models,\u201d in Proceedings of the 2nd ACMConference on Advances in Financial Technologies (AFT) . ACM, 2020, pp. 59\u201379.\n\n[4] J. Clark, D. Demirag, and S. Moosavi, \u201cDemystifying stablecoins: Cryptography meets monetary policy,\u201d Queue , vol. 18, no. 1, pp. 39\u201360, 2020.\n\n[5] USDC, \u201cUSDC,\u201d Online; accessed 17-Oct-2022. https://www.circle. com/en/usdc , 2022.\n\n[6] DAI, \u201cDai,\u201d Online; accessed Oct-2022. https://makerdao.com/ , 2022. [7] W. Zhao, H. Li, and Y. Yuan, \u201cUnderstand volatility of algorithmic stablecoin: Modeling, verification and empirical analysis,\u201d in Interna- tional Conference on Financial Cryptography and Data Security (FC) . Springer, 2021, pp. 97\u2013108.\n\n[8] F. M. Ametrano, \u201cHayek money: The cryptocurrency price stability solution,\u201d Available at SSRN 2425270 , 2016.\n\n[9] R. Sams, \u201cA note on cryptocurrency stabilisation: Seigniorage shares,\u201d Brave New Coin , pp. 1\u20138, 2015.\n\n[10] Terra, \u201cTerra.money,\u201d Online; accessed 19-Aug-2022. https://www.terra. money/ , 2022.\n\n[11] Basis.cash, \u201cBasis Cash - Basis.io without Regulatory Risk,\u201d Online; accessed 17-Oct-2022. https://basis.cash/ , 2022.\n\n[12] Frax, \u201cFrax,\u201d Online; accessed 17-Oct-2022. https://frax.finance/ , 2022. [13] Q. Qureshi, \u201cStablecoins: designing a price-stable cryptocurrency,\u201d Hackernoon (accessed 11 January 2020) https://hackernoon. com/stablecoins-designing-a-price-stable-cryptocurrency- 6bf24e2689e5 , 2018.\n\n[14] M. Mita, K. Ito, S. Ohsawa, and H. Tanaka, \u201cWhat is stablecoin?: A survey on price stabilization mechanisms for decentralized payment sys- tems,\u201d in 8th International Congress on Advanced Applied Informatics (IIAI-AAI) . IEEE, 2019, pp. 60\u201366.\n\n[15] S. Kyle, \u201cMulticoin: An overview of stablecoins,\u201d Online; accessed 17-Oct-2022. https://multicoin.capital/2018/01/17/ an-overview-of-stablecoins , 2022.\n\n[16] I. G. Pernice, S. Henningsen, R. Proskalovich, M. Florian, H. Elend- ner, and B. Scheuermann, \u201cMonetary stabilization in cryptocurrencies\u2013 design approaches and open questions,\u201d in Crypto Valley Conference on Blockchain Technology (CVCBT) . IEEE, 2019, pp. 47\u201359.\n\n[17] M. Salehi, J. Clark, and M. Mannan, \u201cRed-black coins: Dai without liquidations,\u201d in International Conference on Financial Cryptography and Data Security (FC) . Springer, 2021, pp. 136\u2013145.\n\n[18] R. Clements, \u201cBuilt to fail: The inherent fragility of algorithmic stable- coins,\u201d Wake Forest L. Rev. Online , vol. 11, p. 131, 2021.\n\n[19] Wikipedia, \u201cPonzi scheme \u2014 Wikipedia, The Free Encyclopedia,\u201d https: //en.wikipedia.org/wiki/Ponzi scheme , 2022.\n\n[20] H. Minsky, Can it happen again?: Essays on instability and finance . Routledge, 2016.\n\n[21] R. Z. Aliber and C. P. Kindleberger, Manias, panics, and crashes: A history of financial crises . Springer, 2015.\n\n[22] S. A. O\u2019Connell and S. P. Zeldes, \u201cRational Ponzi games,\u201d International Economic Review , pp. 431\u2013450, 1988.\n\n[23] J. Tirole, \u201cAsset bubbles and overlapping generations,\u201d Econometrica: Journal of the Econometric Society , pp. 1499\u20131528, 1985.\n\n[24] I. G. Pernice, S. Henningsen, R. Proskalovich, M. Florian, H. Elend- ner, and B. Scheuermann, \u201cMonetary stabilization in cryptocurrencies\u2013 design approaches and open questions,\u201d in Crypto Valley Conference on Blockchain Technology (CVCBT) . IEEE, 2019, pp. 47\u201359.\n\n[25] Ampleforth.org, \u201cAMPLPowering Innovations in Money,\u201d 2022. [26] E. Kuo, B. Iles, and M. R. Cruz, \u201cAmpleforth: A new synthetic commodity,\u201d Ampleforth White Paper , 2019.\n\n[27] S. M. Werner, D. Perez, L. Gudgeon, A. Klages-Mundt, D. Harz, and W. J. Knottenbelt, \u201cSoK: Decentralized finance (DeFi),\u201d Proceedings of the 4th ACMAdvances in Financial Technologies (AFT) , 2022.\n\n[28] K. Qin, L. Zhou, B. Livshits, and A. Gervais, \u201cAttacking the DeFi ecosystem with flash loans for fun and profit,\u201d in International Con- ference on Financial Cryptography and Data Security (FC) . Springer, 2021, pp. 3\u201332.\n\n6"
    }
]